#!/usr/bin/env python3
# coding: utf-8
"""
QIIME2 Local AI Agent
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆOllamaï¼‰ã‚’ä½¿ã£ãŸãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ è§£ææ”¯æ´ãƒ„ãƒ¼ãƒ«

ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: Python æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ï¼ˆå¤–éƒ¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸è¦ï¼‰
å¿…è¦ãƒ„ãƒ¼ãƒ«   : Ollama (setup.sh ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«), Docker Desktop
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import json
import os
import re
import shutil
import subprocess
import sys
import urllib.error
import urllib.request
from pathlib import Path

# ======================================================================
# è¨­å®š
# ======================================================================
OLLAMA_URL = "http://localhost:11434/api/chat"
DEFAULT_MODEL = os.environ.get("QIIME2_AI_MODEL", "qwen2.5-coder:7b")
SCRIPT_DIR = Path(__file__).parent.resolve()

# ======================================================================
# ANSI ã‚«ãƒ©ãƒ¼
# ======================================================================
RESET = "\033[0m"
BOLD = "\033[1m"
GREEN = "\033[32m"
CYAN = "\033[36m"
YELLOW = "\033[33m"
RED = "\033[31m"
BLUE = "\033[34m"
MAGENTA = "\033[35m"
DIM = "\033[2m"


def c(text, color):
    return f"{color}{text}{RESET}"


# ======================================================================
# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆQIIME2 ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’åŸ‹ã‚è¾¼ã¿ï¼‰
# ======================================================================
SYSTEM_PROMPT = """ã‚ãªãŸã¯ QIIME2ï¼ˆQuantitative Insights Into Microbial Ecology 2ï¼‰ã®å°‚é–€ AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã€æœ€é©ãª QIIME2 ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’è‡ªå‹•æ§‹ç¯‰ã—ã¾ã™ã€‚

â”â”â” ã‚ãªãŸã®å½¹å‰² â”â”â”
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’èª¿æŸ»ã™ã‚‹
2. ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ï¼ˆFASTQãƒ»ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç­‰ï¼‰ã‚’è‡ªå‹•åˆ¤å®šã™ã‚‹
3. ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ãŸæœ€é©ãª QIIME2 è§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã™ã‚‹
4. å®Ÿè¡Œå¯èƒ½ãªã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹
5. è§£æçµæœã®å¯è¦–åŒ–æ–¹æ³•ã‚’èª¬æ˜ã™ã‚‹ README.md ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹

â”â”â” è¡Œå‹•åŸå‰‡ â”â”â”
- å¿…ãšãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿéš›ã«ç¢ºèªã—ã¦ã‹ã‚‰è¨ˆç”»ã‚’ç«‹ã¦ã‚‹
- FASTQãƒ•ã‚¡ã‚¤ãƒ«ã®å‘½åãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¦‹ã¦ãƒšã‚¢ã‚¨ãƒ³ãƒ‰/ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ã‚’åˆ¤å®šã™ã‚‹
- æ—¢å­˜ã® .qza ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°é€”ä¸­ã‹ã‚‰å†é–‹ã§ãã‚‹ã“ã¨ã‚’ä¼ãˆã‚‹
- ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã¯è©³ç´°ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’ä»˜ã‘ã‚‹ï¼ˆæ—¥æœ¬èªã§ï¼‰
- Docker ã‚³ãƒãƒ³ãƒ‰ã¯å¿…ãš `--rm` ã¨ `-v` ãƒã‚¦ãƒ³ãƒˆã‚’å«ã‚ã‚‹

â”â”â” QIIME2 è§£æã®å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ â”â”â”

## ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®åˆ¤å®šåŸºæº–
- `*_R1*.fastq.gz` + `*_R2*.fastq.gz` â†’ ãƒšã‚¢ã‚¨ãƒ³ãƒ‰FASTQ
- `*.fastq.gz` ã®ã¿ â†’ ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰FASTQ
- `*.qza` â†’ æ—¢å­˜ã® QIIME2 ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆé€”ä¸­å†é–‹å¯èƒ½ï¼‰
- `manifest.tsv` / `manifest.csv` â†’ ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
- `metadata.tsv` / `sample_info.tsv` â†’ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
- ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ â†’ ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿

## STEP 1: ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

### ãƒšã‚¢ã‚¨ãƒ³ãƒ‰ FASTQï¼ˆãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆæ–¹å¼ã€æ¨å¥¨ï¼‰
```bash
qiime tools import \
  --type 'SampleData[PairedEndSequencesWithQuality]' \
  --input-path manifest.tsv \
  --output-path paired-end-demux.qza \
  --input-format PairedEndFastqManifestPhred33V2
```

ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ï¼ˆmanifest.tsvï¼‰:
```
sample-id	forward-absolute-filepath	reverse-absolute-filepath
sample1	/data/output/raw/sample1_R1.fastq.gz	/data/output/raw/sample1_R2.fastq.gz
```

### ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ FASTQ
```bash
qiime tools import \
  --type 'SampleData[SequencesWithQuality]' \
  --input-path manifest.tsv \
  --output-path single-end-demux.qza \
  --input-format SingleEndFastqManifestPhred33V2
```

ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ï¼ˆã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ï¼‰:
```
sample-id	absolute-filepath
sample1	/data/output/raw/sample1_R1.fastq.gz
```

### ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆæœªãƒ‡ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹ï¼‰
```bash
qiime tools import \
  --type EMPPairedEndSequences \
  --input-path raw-sequences/ \
  --output-path emp-paired-end-sequences.qza
```

## STEP 2: ã‚¯ã‚ªãƒªãƒ†ã‚£ç¢ºèª
```bash
qiime demux summarize \
  --i-data paired-end-demux.qza \
  --o-visualization demux-summary.qzv
```
â†’ demux-summary.qzv ã‚’ https://view.qiime2.org ã§é–‹ãã€
  ã‚¯ã‚ªãƒªãƒ†ã‚£ãŒæ€¥è½ã™ã‚‹ä½ç½®ã‚’ç¢ºèªã—ã¦ DADA2 ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ±ºå®šã™ã‚‹

## STEP 3: DADA2 ã«ã‚ˆã‚‹ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ï¼ˆãƒã‚¤ã‚ºé™¤å»ãƒ»OTU/ASV ç”Ÿæˆï¼‰

### ãƒšã‚¢ã‚¨ãƒ³ãƒ‰ã®å ´åˆ
```bash
# --p-trim-left-f/r: ãƒ—ãƒ©ã‚¤ãƒãƒ¼é•·ï¼ˆV1-V3: 19ã€V3-V4: 17ï¼‰
# --p-trunc-len-f/r: demux-summary.qzv ã§ã‚¯ã‚ªãƒªãƒ†ã‚£ãŒè½ã¡ã‚‹ä½ç½®ã‚’ç¢ºèªã—ã¦è¨­å®š
qiime dada2 denoise-paired \
  --i-demultiplexed-seqs paired-end-demux.qza \
  --p-trim-left-f 19 \
  --p-trim-left-r 20 \
  --p-trunc-len-f 260 \
  --p-trunc-len-r 200 \
  --p-n-threads 4 \
  --o-table table.qza \
  --o-representative-sequences rep-seqs.qza \
  --o-denoising-stats denoising-stats.qza
```

### ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ã®å ´åˆ
```bash
qiime dada2 denoise-single \
  --i-demultiplexed-seqs single-end-demux.qza \
  --p-trim-left 19 \
  --p-trunc-len 250 \
  --p-n-threads 4 \
  --o-table table.qza \
  --o-representative-sequences rep-seqs.qza \
  --o-denoising-stats denoising-stats.qza
```

é ˜åŸŸåˆ¥æ¨å¥¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç›®å®‰ï¼‰:
- V1-V3 (27F/338R): f_primer=19bp, r_primer=20bp, trunc-f=260, trunc-r=200
- V3-V4 (341F/806R): f_primer=17bp, r_primer=21bp, trunc-f=270, trunc-r=220
- V4   (515F/806R) : f_primer=19bp, r_primer=20bp, trunc-f=250, trunc-r=220

## STEP 4: ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
```bash
qiime feature-table summarize \
  --i-table table.qza \
  --m-sample-metadata-file metadata.tsv \
  --o-visualization table.qzv

qiime feature-table tabulate-seqs \
  --i-data rep-seqs.qza \
  --o-visualization rep-seqs.qzv
```

## STEP 5: ç³»çµ±æ¨¹ã®æ§‹ç¯‰ï¼ˆå¤šæ§˜æ€§è§£æã«å¿…é ˆï¼‰
```bash
qiime phylogeny align-to-tree-mafft-fasttree \
  --i-sequences rep-seqs.qza \
  --o-alignment aligned-rep-seqs.qza \
  --o-masked-alignment masked-aligned-rep-seqs.qza \
  --o-tree unrooted-tree.qza \
  --o-rooted-tree rooted-tree.qza \
  --p-n-threads 4
```

## STEP 6: åˆ†é¡å­¦çš„è§£æï¼ˆSILVA 138ï¼‰

### åˆ†é¡å™¨ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆåˆå›ã®ã¿ã€ç´„2-5æ™‚é–“ï¼‰

V1-V3 é ˜åŸŸå°‚ç”¨ï¼ˆæ¨å¥¨ï¼‰:
```bash
# å‚ç…§é…åˆ—ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
wget https://data.qiime2.org/2024.10/common/silva-138-99-seqs.qza
wget https://data.qiime2.org/2024.10/common/silva-138-99-tax.qza

# V1-V3 é ˜åŸŸã®æŠ½å‡ºï¼ˆ27F/338R ãƒ—ãƒ©ã‚¤ãƒãƒ¼ã€1-2æ™‚é–“ï¼‰
qiime feature-classifier extract-reads \
  --i-sequences silva-138-99-seqs.qza \
  --p-f-primer AGAGTTTGATCMTGGCTCAG \
  --p-r-primer TGCTGCCTCCCGTAGGAGT \
  --p-min-length 100 --p-max-length 400 --p-n-jobs 4 \
  --o-reads silva-138-99-seqs-V1-V3.qza

# Naive Bayes åˆ†é¡å™¨ã®å­¦ç¿’ï¼ˆ1-3æ™‚é–“ï¼‰
qiime feature-classifier fit-classifier-naive-bayes \
  --i-reference-reads silva-138-99-seqs-V1-V3.qza \
  --i-reference-taxonomy silva-138-99-tax.qza \
  --o-classifier silva-138-99-classifier-V1-V3.qza
```

å…¨é•·åˆ†é¡å™¨ï¼ˆæœ€é€Ÿã€ç²¾åº¦ã¯ä½ã‚ï¼‰:
```bash
wget https://data.qiime2.org/classifiers/sklearn-1.4.2/silva/silva-138-99-nb-classifier.qza
```

### åˆ†é¡ã®å®Ÿè¡Œ
```bash
qiime feature-classifier classify-sklearn \
  --i-classifier silva-138-99-classifier-V1-V3.qza \
  --i-reads rep-seqs.qza \
  --p-n-jobs 4 \
  --o-classification taxonomy.qza

# åˆ†é¡ãƒ©ãƒ™ãƒ«ä¸€è¦§
qiime metadata tabulate \
  --m-input-file taxonomy.qza \
  --o-visualization taxonomy.qzv

# åˆ†é¡çµ„æˆãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼ˆæœ€é‡è¦å¯è¦–åŒ–ï¼‰
qiime taxa barplot \
  --i-table table.qza \
  --i-taxonomy taxonomy.qza \
  --m-metadata-file metadata.tsv \
  --o-visualization taxa-bar-plots.qzv
```

## STEP 7: å¤šæ§˜æ€§è§£æ

```bash
# Î±ãƒ»Î²å¤šæ§˜æ€§ï¼ˆsampling-depth ã¯ table.qzv ã§æœ€å°ãƒªãƒ¼ãƒ‰æ•°ã‚’ç¢ºèªå¾Œã«è¨­å®šï¼‰
qiime diversity core-metrics-phylogenetic \
  --i-phylogeny rooted-tree.qza \
  --i-table table.qza \
  --p-sampling-depth 1000 \
  --m-metadata-file metadata.tsv \
  --output-dir core-metrics-results/

# Î±å¤šæ§˜æ€§ã®çµ±è¨ˆæ¤œå®šï¼ˆShannon å¤šæ§˜æ€§ï¼‰
qiime diversity alpha-group-significance \
  --i-alpha-diversity core-metrics-results/shannon_vector.qza \
  --m-metadata-file metadata.tsv \
  --o-visualization core-metrics-results/shannon-significance.qzv

# Î²å¤šæ§˜æ€§ã® PERMANOVAï¼ˆUnweighted UniFracï¼‰
qiime diversity beta-group-significance \
  --i-distance-matrix core-metrics-results/unweighted_unifrac_distance_matrix.qza \
  --m-metadata-file metadata.tsv \
  --m-metadata-column <ã‚°ãƒ«ãƒ¼ãƒ—åˆ—å> \
  --o-visualization core-metrics-results/unweighted-unifrac-significance.qzv
```

## STEP 8: å·®æ¬¡è§£æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
```bash
# ANCOM-BCï¼ˆã‚°ãƒ«ãƒ¼ãƒ—é–“ã®å·®æ¬¡è±Šå¯Œç¨®ï¼‰
qiime composition ancombc \
  --i-table table.qza \
  --m-metadata-file metadata.tsv \
  --p-formula <ã‚°ãƒ«ãƒ¼ãƒ—åˆ—å> \
  --o-differentials ancombc-results.qza

qiime composition da-barplot \
  --i-data ancombc-results.qza \
  --o-visualization ancombc-results.qzv
```

## Docker ã§ã®å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰é››å½¢
```bash
docker run --rm \
  -v <ãƒ›ã‚¹ãƒˆå´è§£æãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª>:/data/output \
  quay.io/qiime2/amplicon:2026.1 \
  qiime <ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰> \
    --i-<å…¥åŠ›å¼•æ•°> /data/output/<ãƒ•ã‚¡ã‚¤ãƒ«å> \
    --o-<å‡ºåŠ›å¼•æ•°> /data/output/results/<ãƒ•ã‚¡ã‚¤ãƒ«å>
```

## ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ï¼ˆmetadata.tsvï¼‰
```
sample-id	group	age	treatment
#q2:types	categorical	numeric	categorical
sample1	control	25	placebo
sample2	treatment	30	drug_A
```
- 1è¡Œç›®: ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆå¿…ãš `sample-id` ã‹ã‚‰å§‹ã‚ã‚‹ï¼‰
- 2è¡Œç›®: ãƒ‡ãƒ¼ã‚¿å‹ï¼ˆ`categorical` ã¾ãŸã¯ `numeric`ï¼‰çœç•¥å¯

## SILVA 138 åˆ†é¡éšå±¤
```
d__Bacteria; p__Firmicutes; c__Bacilli; o__Lactobacillales; f__Lactobacillaceae; g__Lactobacillus; s__Lactobacillus_acidophilus
```
ãƒ¬ãƒ™ãƒ«1: d__(ãƒ‰ãƒ¡ã‚¤ãƒ³), 2: p__(é–€), 3: c__(ç¶±), 4: o__(ç›®), 5: f__(ç§‘), 6: g__(å±), 7: s__(ç¨®)
â€» ç¨®ãƒ¬ãƒ™ãƒ«ã¯ç²¾åº¦ãŒä½ã„å ´åˆãŒå¤šã„ãŸã‚å±ãƒ¬ãƒ™ãƒ«(g__)æ¨å¥¨

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
- extract-reads ã§é…åˆ—ãŒæ®‹ã‚‰ãªã„ â†’ ãƒ—ãƒ©ã‚¤ãƒãƒ¼é…åˆ—ç¢ºèªï¼ˆç¸®é‡å¡©åŸº M, R, W ç­‰ï¼‰
- classify-sklearn ã§ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ â†’ Docker ãƒ¡ãƒ¢ãƒªä¸Šé™ã‚’ 8GB ä»¥ä¸Šã«ã€--p-n-jobs 1 ã«
- å…¨ã¦ Unassigned â†’ ãƒªãƒãƒ¼ã‚¹ã‚³ãƒ³ãƒ—ãƒªãƒ¡ãƒ³ãƒˆç¢ºèªã€--p-confidence 0.5 ã«ä¸‹ã’ã‚‹
- DADA2 å¾Œã®ãƒªãƒ¼ãƒ‰æ•°ãŒæ¿€æ¸› â†’ trunc-len ã‚’çŸ­ãï¼ˆå“è³ªãŒä½ã„ä½ç½®ã‚’é¿ã‘ã‚‹ï¼‰

â”â”â” å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®èª¬æ˜ â”â”â”
- `*.qza` = QIIME2 ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆå†…éƒ¨ãƒ‡ãƒ¼ã‚¿ï¼‰
- `*.qzv` = QIIME2 ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ â†’ https://view.qiime2.org ã§é–‹ã
- `results/` = ã™ã¹ã¦ã®å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- `taxa-bar-plots.qzv` = åˆ†é¡çµ„æˆã®ç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ï¼ˆæœ€ã‚‚ã‚ˆãä½¿ã‚ã‚Œã‚‹å¯è¦–åŒ–ï¼‰
- `core-metrics-results/` = å¤šæ§˜æ€§è§£æã®å…¨å‡ºåŠ›"""

# ======================================================================
# ãƒ„ãƒ¼ãƒ«å®šç¾©ï¼ˆOllama function calling å½¢å¼ï¼‰
# ======================================================================
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "inspect_directory",
            "description": "æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ã‚’èª¿æŸ»ã™ã‚‹ã€‚ãƒ•ã‚¡ã‚¤ãƒ«åãƒ»ã‚µã‚¤ã‚ºãƒ»ç¨®é¡ã‚’ä¸€è¦§è¡¨ç¤ºã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "èª¿æŸ»ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹"
                    },
                    "recursive": {
                        "type": "boolean",
                        "description": "ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚å«ã‚ã¦å†å¸°çš„ã«èª¿æŸ»ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: falseï¼‰"
                    }
                },
                "required": ["path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆTSV, CSV, TXT, MD ç­‰ï¼‰ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å†’é ­ 100 è¡Œã¾ã§è¡¨ç¤ºã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹"
                    },
                    "max_lines": {
                        "type": "integer",
                        "description": "æœ€å¤§èª­ã¿è¾¼ã¿è¡Œæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ï¼‰"
                    }
                },
                "required": ["path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "check_system",
            "description": "Dockerãƒ»Ollamaãƒ»QIIME2 ã®åˆ©ç”¨å¯å¦ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèªã™ã‚‹",
            "parameters": {
                "type": "object",
                "properties": {}
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "write_file",
            "description": "è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ»READMEãƒ»ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãªã©ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãå‡ºã™",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "æ›¸ãè¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹"
                    },
                    "content": {
                        "type": "string",
                        "description": "æ›¸ãè¾¼ã‚€å†…å®¹ï¼ˆã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€Markdown ç­‰ï¼‰"
                    }
                },
                "required": ["path", "content"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "generate_manifest",
            "description": "FASTQãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰QIIME2ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆTSVã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹",
            "parameters": {
                "type": "object",
                "properties": {
                    "fastq_dir": {
                        "type": "string",
                        "description": "FASTQãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥ã£ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹"
                    },
                    "output_path": {
                        "type": "string",
                        "description": "ç”Ÿæˆã™ã‚‹ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹"
                    },
                    "paired_end": {
                        "type": "boolean",
                        "description": "ãƒšã‚¢ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‹ï¼ˆtrue: ãƒšã‚¢ã‚¨ãƒ³ãƒ‰, false: ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ï¼‰"
                    },
                    "container_data_dir": {
                        "type": "string",
                        "description": "Docker ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã®ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: /data/outputï¼‰"
                    }
                },
                "required": ["fastq_dir", "output_path", "paired_end"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "run_command",
            "description": "ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèªã‚’æ±‚ã‚ã¦ã‹ã‚‰å®Ÿè¡Œã™ã‚‹ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "command": {
                        "type": "string",
                        "description": "å®Ÿè¡Œã™ã‚‹ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰"
                    },
                    "description": {
                        "type": "string",
                        "description": "ã“ã®ã‚³ãƒãƒ³ãƒ‰ãŒä½•ã‚’ã™ã‚‹ã‹ã®èª¬æ˜ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¡¨ç¤ºï¼‰"
                    },
                    "working_dir": {
                        "type": "string",
                        "description": "ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆçœç•¥æ™‚ã¯ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰"
                    }
                },
                "required": ["command", "description"]
            }
        }
    }
]

# ======================================================================
# ãƒ„ãƒ¼ãƒ«å®Ÿè£…
# ======================================================================

def tool_inspect_directory(path: str, recursive: bool = False) -> str:
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹ã‚’èª¿æŸ»"""
    p = Path(path).expanduser()
    if not p.exists():
        return f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{path}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"
    if not p.is_dir():
        return f"ã‚¨ãƒ©ãƒ¼: '{path}' ã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

    lines = [f"ğŸ“‚ {p} ã®å†…å®¹:\n"]
    total_files = 0

    def scan(dirpath: Path, depth: int = 0):
        nonlocal total_files
        indent = "  " * depth
        try:
            entries = sorted(dirpath.iterdir(), key=lambda x: (x.is_file(), x.name))
        except PermissionError:
            lines.append(f"{indent}  [æ¨©é™ã‚¨ãƒ©ãƒ¼: ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯]")
            return
        for entry in entries:
            if entry.name.startswith("."):
                continue
            if entry.is_dir():
                lines.append(f"{indent}ğŸ“ {entry.name}/")
                if recursive and depth < 3:
                    scan(entry, depth + 1)
            else:
                size = entry.stat().st_size
                size_str = f"{size:,} B" if size < 1024 else \
                           f"{size/1024:.1f} KB" if size < 1024**2 else \
                           f"{size/1024**2:.1f} MB" if size < 1024**3 else \
                           f"{size/1024**3:.1f} GB"
                ext = entry.suffix.lower()
                icon = {"": "ğŸ“„", ".fastq": "ğŸ§¬", ".gz": "ğŸ—œï¸",
                        ".qza": "ğŸ”µ", ".qzv": "ğŸŸ¢", ".tsv": "ğŸ“Š",
                        ".csv": "ğŸ“Š", ".md": "ğŸ“", ".sh": "âš™ï¸",
                        ".py": "ğŸ", ".r": "ğŸ“ˆ", ".pdf": "ğŸ“•"}.get(ext, "ğŸ“„")
                lines.append(f"{indent}{icon} {entry.name}  [{size_str}]")
                total_files += 1

    scan(p)
    lines.append(f"\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")

    # QIIME2 ãƒ‡ãƒ¼ã‚¿åˆ¤å®šã®ãƒ’ãƒ³ãƒˆ
    all_text = "\n".join(lines)
    hints = []
    if "_R1_" in all_text or "_R1." in all_text:
        hints.append("âœ… ãƒšã‚¢ã‚¨ãƒ³ãƒ‰FASTQã‚’æ¤œå‡ºï¼ˆ_R1_/_R2_ ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰")
    elif ".fastq" in all_text:
        hints.append("âœ… FASTQãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º")
    if ".qza" in all_text:
        hints.append("âœ… æ—¢å­˜ã® QIIME2 ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ (.qza) ã‚’æ¤œå‡º â€” é€”ä¸­ã‹ã‚‰å†é–‹å¯èƒ½")
    if "metadata" in all_text.lower() or "sample_info" in all_text.lower():
        hints.append("âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º")
    if "manifest" in all_text.lower():
        hints.append("âœ… ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º")

    if hints:
        lines.append("\nğŸ” è‡ªå‹•åˆ¤å®šãƒ’ãƒ³ãƒˆ:")
        lines.extend(hints)

    return "\n".join(lines)


def tool_read_file(path: str, max_lines: int = 50) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã‚€"""
    p = Path(path).expanduser()
    if not p.exists():
        return f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« '{path}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"
    if not p.is_file():
        return f"ã‚¨ãƒ©ãƒ¼: '{path}' ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

    suffix = p.suffix.lower()
    if suffix in [".gz", ".bz2", ".qza", ".qzv"]:
        return f"'{p.name}' ã¯ãƒã‚¤ãƒŠãƒª/åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãŸã‚å†…å®¹ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚\nãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {p.stat().st_size / 1024**2:.2f} MB"

    try:
        with open(p, encoding="utf-8", errors="replace") as f:
            lines = []
            for i, line in enumerate(f):
                if i >= max_lines:
                    lines.append(f"\n... ï¼ˆ{max_lines} è¡Œä»¥é™ã¯çœç•¥ï¼‰")
                    break
                lines.append(line.rstrip())
        return f"ğŸ“„ {p} ã®å†…å®¹ï¼ˆæœ€å¤§ {max_lines} è¡Œï¼‰:\n\n" + "\n".join(lines)
    except Exception as e:
        return f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"


def tool_check_system() -> str:
    """ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒã®ç¢ºèª"""
    results = ["ğŸ–¥ï¸  ã‚·ã‚¹ãƒ†ãƒ ç¢ºèªçµæœ:\n"]

    # Docker
    docker_path = "/Applications/Docker.app/Contents/Resources/bin/docker"
    if Path(docker_path).exists():
        try:
            result = subprocess.run([docker_path, "--version"],
                                    capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                results.append(f"âœ… Docker: {result.stdout.strip()}")
                # Docker ãƒ‡ãƒ¼ãƒ¢ãƒ³èµ·å‹•ç¢ºèª
                ping = subprocess.run([docker_path, "info"],
                                      capture_output=True, text=True, timeout=10)
                if ping.returncode == 0:
                    results.append("âœ… Docker ãƒ‡ãƒ¼ãƒ¢ãƒ³: èµ·å‹•ä¸­")
                else:
                    results.append("âš ï¸  Docker ãƒ‡ãƒ¼ãƒ¢ãƒ³: åœæ­¢ä¸­ â†’ Docker Desktop ã‚’èµ·å‹•ã—ã¦ãã ã•ã„")
            else:
                results.append("âš ï¸  Docker: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“")
        except Exception:
            results.append("âš ï¸  Docker: ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸ")
    elif shutil.which("docker"):
        try:
            result = subprocess.run(["docker", "--version"],
                                    capture_output=True, text=True, timeout=5)
            results.append(f"âœ… Docker: {result.stdout.strip()}")
        except Exception:
            results.append("âŒ Docker: è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        results.append("âŒ Docker: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ â†’ Docker Desktop ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")

    # Ollama
    try:
        req = urllib.request.Request("http://localhost:11434/api/tags")
        with urllib.request.urlopen(req, timeout=3) as resp:
            data = json.loads(resp.read())
            models = [m["name"] for m in data.get("models", [])]
            results.append(f"âœ… Ollama: èµ·å‹•ä¸­")
            if models:
                results.append(f"   åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«: {', '.join(models)}")
            else:
                results.append("   âš ï¸  ãƒ¢ãƒ‡ãƒ«ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« â†’ 'ollama pull qwen2.5-coder:7b' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    except Exception:
        results.append("âŒ Ollama: èµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ â†’ 'ollama serve' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

    # Python
    results.append(f"âœ… Python: {sys.version.split()[0]}")

    # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡
    import shutil as _shutil
    usage = _shutil.disk_usage(Path.home())
    free_gb = usage.free / 1024**3
    results.append(f"ğŸ’¾ ãƒ‡ã‚£ã‚¹ã‚¯ç©ºãå®¹é‡: {free_gb:.1f} GB {'âœ…' if free_gb > 30 else 'âš ï¸  (æ¨å¥¨: 30GB ä»¥ä¸Š)'}")

    return "\n".join(results)


def tool_write_file(path: str, content: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã«å†…å®¹ã‚’æ›¸ãè¾¼ã‚€"""
    p = Path(path).expanduser()
    try:
        p.parent.mkdir(parents=True, exist_ok=True)
        with open(p, "w", encoding="utf-8") as f:
            f.write(content)
        # ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆãªã‚‰å®Ÿè¡Œæ¨©é™ã‚’ä»˜ä¸
        if p.suffix in [".sh", ".bash"]:
            p.chmod(p.stat().st_mode | 0o755)
            return f"âœ… '{p}' ã‚’ä½œæˆã—ã¾ã—ãŸï¼ˆå®Ÿè¡Œæ¨©é™ä»˜ãï¼‰"
        return f"âœ… '{p}' ã‚’ä½œæˆã—ã¾ã—ãŸ"
    except Exception as e:
        return f"âŒ æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"


def tool_generate_manifest(fastq_dir: str, output_path: str,
                            paired_end: bool = True,
                            container_data_dir: str = "/data/output") -> str:
    """FASTQãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’è‡ªå‹•ç”Ÿæˆ"""
    d = Path(fastq_dir).expanduser()
    if not d.exists():
        return f"ã‚¨ãƒ©ãƒ¼: '{fastq_dir}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"

    # FASTQãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
    fastq_files = sorted(d.glob("*.fastq.gz")) + sorted(d.glob("*.fastq"))

    if not fastq_files:
        return f"ã‚¨ãƒ©ãƒ¼: '{fastq_dir}' ã« FASTQ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"

    out_path = Path(output_path).expanduser()

    if paired_end:
        # R1/R2 ãƒšã‚¢ã‚’æ¤œå‡º
        r1_files = [f for f in fastq_files
                    if re.search(r'_R1[_.]|_1\.fastq|_R1\.fastq', f.name)]
        r2_files = [f for f in fastq_files
                    if re.search(r'_R2[_.]|_2\.fastq|_R2\.fastq', f.name)]

        if not r1_files:
            return "ã‚¨ãƒ©ãƒ¼: _R1_ ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

        # ã‚µãƒ³ãƒ—ãƒ«åã‚’æŠ½å‡º
        lines = ["sample-id\tforward-absolute-filepath\treverse-absolute-filepath"]
        matched = 0
        unmatched = []

        for r1 in r1_files:
            # ã‚µãƒ³ãƒ—ãƒ«åã®æ¨å®š
            sample_name = re.sub(r'_R1[_.].*$|_R1\.fastq.*$', '', r1.name)
            sample_name = re.sub(r'\.fastq.*$', '', sample_name)

            # å¯¾å¿œã™ã‚‹ R2 ã‚’æ¢ã™
            r2_pattern = r1.name.replace("_R1_", "_R2_").replace("_R1.", "_R2.")
            r2_candidates = [f for f in r2_files if f.name == r2_pattern]

            # ã‚³ãƒ³ãƒ†ãƒŠå†…ãƒ‘ã‚¹
            container_r1 = f"{container_data_dir}/{r1.name}"

            if r2_candidates:
                container_r2 = f"{container_data_dir}/{r2_candidates[0].name}"
                lines.append(f"{sample_name}\t{container_r1}\t{container_r2}")
                matched += 1
            else:
                unmatched.append(r1.name)

        content = "\n".join(lines) + "\n"
        out_path.parent.mkdir(parents=True, exist_ok=True)
        with open(out_path, "w") as f:
            f.write(content)

        result = [f"âœ… ãƒšã‚¢ã‚¨ãƒ³ãƒ‰ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ç”Ÿæˆ: '{out_path}'",
                  f"   ãƒšã‚¢æ•°: {matched}"]
        if unmatched:
            result.append(f"   âš ï¸  R2ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(unmatched)}")
        result.append(f"\nå†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:\n{content[:500]}")
        return "\n".join(result)

    else:
        # ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰
        lines = ["sample-id\tabsolute-filepath"]
        for f in fastq_files:
            sample_name = re.sub(r'\.fastq.*$', '', f.name)
            container_path = f"{container_data_dir}/{f.name}"
            lines.append(f"{sample_name}\t{container_path}")

        content = "\n".join(lines) + "\n"
        out_path.parent.mkdir(parents=True, exist_ok=True)
        with open(out_path, "w") as f:
            f.write(content)

        return (f"âœ… ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ç”Ÿæˆ: '{out_path}'\n"
                f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(fastq_files)}\n"
                f"\nå†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:\n{content[:500]}")


def tool_run_command(command: str, description: str, working_dir: str = None) -> str:
    """ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªä»˜ãï¼‰"""
    print(f"\n{c('âš¡ ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆ', YELLOW)}")
    print(f"   èª¬æ˜: {description}")
    print(f"   ã‚³ãƒãƒ³ãƒ‰:\n   {c(command, CYAN)}")
    print(f"\n{c('[y] å®Ÿè¡Œã™ã‚‹  [n] ã‚­ãƒ£ãƒ³ã‚»ãƒ«', DIM)}", end=" > ")

    try:
        answer = input().strip().lower()
    except (EOFError, KeyboardInterrupt):
        return "âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸï¼ˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å‰²ã‚Šè¾¼ã¿ï¼‰"

    if answer not in ["y", "yes", "ã¯ã„"]:
        return "âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚"

    try:
        cwd = Path(working_dir).expanduser() if working_dir else None
        proc = subprocess.run(
            command, shell=True, capture_output=True, text=True,
            timeout=3600, cwd=cwd
        )
        output_parts = []
        if proc.stdout:
            output_parts.append(f"STDOUT:\n{proc.stdout[:3000]}")
        if proc.stderr:
            output_parts.append(f"STDERR:\n{proc.stderr[:1000]}")

        if proc.returncode == 0:
            return f"âœ… æˆåŠŸï¼ˆçµ‚äº†ã‚³ãƒ¼ãƒ‰ 0ï¼‰\n" + "\n".join(output_parts)
        else:
            return f"âš ï¸  çµ‚äº†ã‚³ãƒ¼ãƒ‰ {proc.returncode}\n" + "\n".join(output_parts)
    except subprocess.TimeoutExpired:
        return "â±ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ1æ™‚é–“ã‚’è¶…ãˆã¾ã—ãŸï¼‰"
    except Exception as e:
        return f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"


def dispatch_tool(name: str, args: dict) -> str:
    """ãƒ„ãƒ¼ãƒ«åã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ãƒ„ãƒ¼ãƒ«é–¢æ•°ã‚’å‘¼ã³å‡ºã™"""
    try:
        if name == "inspect_directory":
            return tool_inspect_directory(**args)
        elif name == "read_file":
            return tool_read_file(**args)
        elif name == "check_system":
            return tool_check_system()
        elif name == "write_file":
            return tool_write_file(**args)
        elif name == "generate_manifest":
            return tool_generate_manifest(**args)
        elif name == "run_command":
            return tool_run_command(**args)
        else:
            return f"âŒ ä¸æ˜ãªãƒ„ãƒ¼ãƒ«: {name}"
    except TypeError as e:
        return f"âŒ ãƒ„ãƒ¼ãƒ«å¼•æ•°ã‚¨ãƒ©ãƒ¼ ({name}): {e}"
    except Exception as e:
        return f"âŒ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ ({name}): {e}"


# ======================================================================
# Ollama API
# ======================================================================

def call_ollama(messages: list, model: str, tools: list = None) -> dict:
    """Ollama /api/chat ã‚’å‘¼ã³å‡ºã™ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æœ‰åŠ¹ï¼‰"""
    body = {
        "model": model,
        "messages": messages,
        "stream": True,
    }
    if tools:
        body["tools"] = tools

    data = json.dumps(body).encode("utf-8")
    req = urllib.request.Request(
        OLLAMA_URL,
        data=data,
        headers={"Content-Type": "application/json"},
        method="POST"
    )

    full_content = ""
    tool_calls = []
    thinking_content = ""

    try:
        with urllib.request.urlopen(req, timeout=300) as resp:
            for raw_line in resp:
                line = raw_line.decode("utf-8").strip()
                if not line:
                    continue
                try:
                    chunk = json.loads(line)
                except json.JSONDecodeError:
                    continue

                msg = chunk.get("message", {})
                content = msg.get("content", "")

                # thinkingï¼ˆæ¨è«–ãƒ–ãƒ­ãƒƒã‚¯ã€qwen3ç­‰ï¼‰
                if msg.get("thinking"):
                    thinking_content += msg["thinking"]
                    continue

                # tool_calls ãŒå«ã¾ã‚Œã‚‹å ´åˆ
                if msg.get("tool_calls"):
                    tool_calls.extend(msg["tool_calls"])

                # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
                if content:
                    print(content, end="", flush=True)
                    full_content += content

                if chunk.get("done"):
                    break

        if full_content:
            print()  # æ”¹è¡Œ

        return {
            "content": full_content,
            "tool_calls": tool_calls,
            "thinking": thinking_content
        }

    except urllib.error.URLError as e:
        raise ConnectionError(
            f"Ollama ã«æ¥ç¶šã§ãã¾ã›ã‚“ï¼ˆ{OLLAMA_URL}ï¼‰ã€‚\n"
            f"'ollama serve' ã‚’åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\nè©³ç´°: {e}"
        )


def check_ollama_running() -> bool:
    """Ollama ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª"""
    try:
        urllib.request.urlopen("http://localhost:11434/api/tags", timeout=3)
        return True
    except Exception:
        return False


def get_available_models() -> list:
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        with urllib.request.urlopen("http://localhost:11434/api/tags", timeout=5) as resp:
            data = json.loads(resp.read())
            return [m["name"] for m in data.get("models", [])]
    except Exception:
        return []


# ======================================================================
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—
# ======================================================================

def run_agent_loop(messages: list, model: str):
    """ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å«ã‚€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œ"""
    while True:
        print(f"\n{c('ğŸ¤– AI', CYAN + BOLD)}: ", end="", flush=True)

        response = call_ollama(messages, model, tools=TOOLS)
        assistant_msg = {"role": "assistant", "content": response["content"]}

        # tool_calls ãŒã‚ã‚Œã°å®Ÿè¡Œ
        if response["tool_calls"]:
            tool_results = []
            for tc in response["tool_calls"]:
                fn = tc.get("function", {})
                tool_name = fn.get("name", "")
                tool_args = fn.get("arguments", {})
                if isinstance(tool_args, str):
                    try:
                        tool_args = json.loads(tool_args)
                    except json.JSONDecodeError:
                        tool_args = {}

                print(f"\n{c(f'ğŸ”§ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ: {tool_name}', MAGENTA)}")
                print(f"{c(json.dumps(tool_args, ensure_ascii=False, indent=2), DIM)}")

                result = dispatch_tool(tool_name, tool_args)

                print(f"\n{c('ğŸ“‹ å®Ÿè¡Œçµæœ:', GREEN)}")
                print(result)

                tool_results.append({
                    "role": "tool",
                    "content": result
                })

            # tool_calls ã‚’ assistant ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
            if response["tool_calls"]:
                assistant_msg["tool_calls"] = response["tool_calls"]

            messages.append(assistant_msg)
            messages.extend(tool_results)

            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå¾Œã€ç¶šã‘ã¦ AI ã«å¿œç­”ã•ã›ã‚‹
            continue
        else:
            # ãƒ„ãƒ¼ãƒ«ãªã— â†’ é€šå¸¸ã®å¿œç­”ã§çµ‚äº†
            messages.append(assistant_msg)
            break


# ======================================================================
# ãƒãƒŠãƒ¼ãƒ»UI
# ======================================================================

BANNER = f"""{CYAN}{BOLD}
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          QIIME2 Local AI Agent  ğŸ§¬                           â•‘
â•‘  ãƒ­ãƒ¼ã‚«ãƒ« LLM ã§ãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•è§£æã—ã¾ã™     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{RESET}
"""

INITIAL_MESSAGE = """ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯ QIIME2 è§£æã‚’æ”¯æ´ã™ã‚‹ãƒ­ãƒ¼ã‚«ãƒ« AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

ã‚ãªãŸã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã€ä»¥ä¸‹ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™:
  ğŸ“œ è§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆrun_pipeline.shï¼‰
  ğŸ§¬ åˆ†é¡å™¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆsetup_classifier.shï¼‰
  ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
  ğŸ“– æ“ä½œã‚¬ã‚¤ãƒ‰ï¼ˆREADME.mdï¼‰

ã¾ãšã€**è§£æã—ãŸã„ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹**ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
ï¼ˆä¾‹: `/Users/yourname/microbiome-data/` ã¾ãŸã¯ `~/experiment01/`ï¼‰
"""


def select_model(available_models: list) -> str:
    """ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"""
    preferred = ["qwen2.5-coder:7b", "qwen2.5-coder:3b", "llama3.2:3b",
                 "llama3.1:8b", "mistral:7b", "codellama:7b"]

    for p in preferred:
        if p in available_models:
            return p
        # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä¸€è‡´
        for m in available_models:
            if m.startswith(p.split(":")[0]):
                return m

    if available_models:
        return available_models[0]
    return DEFAULT_MODEL


# ======================================================================
# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# ======================================================================

def main():
    print(BANNER)

    # Ollama èµ·å‹•ç¢ºèª
    if not check_ollama_running():
        print(f"{c('âŒ Ollama ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚', RED)}")
        print(f"   ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„:")
        print(f"   {c('ollama serve', CYAN)}")
        print(f"\n   Ollama ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®å ´åˆ:")
        print(f"   {c('./setup.sh', CYAN)} ã‚’å®Ÿè¡Œã—ã¦ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)

    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    available = get_available_models()
    if not available:
        print(f"{c('âš ï¸  Ollama ã«ãƒ¢ãƒ‡ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚', YELLOW)}")
        print(f"   æ¨å¥¨ãƒ¢ãƒ‡ãƒ«: {c('ollama pull qwen2.5-coder:7b', CYAN)}")
        print(f"   è»½é‡ç‰ˆ    : {c('ollama pull llama3.2:3b', CYAN)}")
        sys.exit(1)

    model = select_model(available)
    print(f"{c(f'âœ… ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {model}', GREEN)}")
    print(f"{c('ãƒ’ãƒ³ãƒˆ: çµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚', DIM)}\n")

    # ä¼šè©±å±¥æ­´ã‚’åˆæœŸåŒ–
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "assistant", "content": INITIAL_MESSAGE}
    ]

    print(f"{c('ğŸ¤– AI', CYAN + BOLD)}: {INITIAL_MESSAGE}")

    # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
    while True:
        try:
            user_input = input(f"\n{c('ã‚ãªãŸ', BOLD + GREEN)} > ").strip()
        except (EOFError, KeyboardInterrupt):
            print(f"\n\n{c('ğŸ‘‹ çµ‚äº†ã—ã¾ã™ã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼', CYAN)}")
            break

        if not user_input:
            continue

        if user_input.lower() in ["quit", "exit", "çµ‚äº†", "q"]:
            print(f"\n{c('ğŸ‘‹ çµ‚äº†ã—ã¾ã™ã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼', CYAN)}")
            break

        messages.append({"role": "user", "content": user_input})

        try:
            run_agent_loop(messages, model)
        except ConnectionError as e:
            print(f"\n{c(str(e), RED)}")
            break
        except Exception as e:
            print(f"\n{c(f'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}', RED)}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()
