#!/usr/bin/env python3
# coding: utf-8
"""
seq2pipe  â€”  sequence â†’ pipeline
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼ˆOllamaï¼‰ã‚’ä½¿ã£ãŸãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ è§£æ AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
ç”Ÿé…åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Šã€QIIME2 ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™

ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: Python æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ï¼ˆå¤–éƒ¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸è¦ï¼‰
å¿…è¦ãƒ„ãƒ¼ãƒ«   : Ollama (setup.sh ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«), Docker Desktop
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import datetime
import json
import os
import re
import shutil
import subprocess
import sys
import tempfile
import urllib.error
import urllib.request
from pathlib import Path
from typing import Optional

# ======================================================================
# è¨­å®š
# ======================================================================
OLLAMA_URL = "http://localhost:11434/api/chat"
DEFAULT_MODEL = os.environ.get("QIIME2_AI_MODEL", "qwen2.5-coder:7b")
SCRIPT_DIR = Path(__file__).parent.resolve()

# ======================================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ï¼ˆãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ è§£æãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ï¼‰
# ======================================================================
ANALYSIS_LOG: list = []       # å®Ÿè¡Œã—ãŸè§£æã®è¨˜éŒ²
SESSION_FIGURE_DIR: str = ""  # å›³ã®å‡ºåŠ›å…ˆï¼ˆåˆå› execute_python å‘¼ã³å‡ºã—æ™‚ã«è¨­å®šï¼‰
PLOT_CONFIG: dict = {         # å›³ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
    "style": "seaborn-v0_8-whitegrid",
    "palette": "Set2",
    "figsize": [10, 6],
    "dpi": 150,
    "font_size": 12,
    "title_font_size": 14,
    "format": "pdf",           # ä¿å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: pdf / png / svg
}

# ======================================================================
# è¨€èªè¨­å®šï¼ˆselect_language() ã§èµ·å‹•æ™‚ã«è¨­å®šï¼‰
# ======================================================================
LANG: str = "ja"  # "ja" | "en"

_UI: dict = {
    "ja": {
        "model_selected": "âœ… ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {}",
        "hint_exit":      "ãƒ’ãƒ³ãƒˆ: çµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚",
        "prompt":         "ã‚ãªãŸ",
        "tool_exec":      "ğŸ”§ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ: {}",
        "tool_result":    "ğŸ“‹ å®Ÿè¡Œçµæœ:",
        "goodbye":        "ğŸ‘‹ çµ‚äº†ã—ã¾ã™ã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼",
        "ollama_error":   "âŒ Ollama ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ã€‚",
        "ollama_hint":    "ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„:",
        "ollama_hint2":   "Ollama ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã®å ´åˆ:",
        "no_model":       "âš ï¸  Ollama ã«ãƒ¢ãƒ‡ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "no_model_hint":  "æ¨å¥¨ãƒ¢ãƒ‡ãƒ«: {}",
        "no_model_hint2": "è»½é‡ç‰ˆ    : {}",
        "runtime_error":    "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {}",
        "cmd_request":      "âš¡ ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆ",
        "cmd_desc":         "èª¬æ˜",
        "cmd_cmd":          "ã‚³ãƒãƒ³ãƒ‰",
        "cmd_confirm":      "[y] å®Ÿè¡Œã™ã‚‹  [n] ã‚­ãƒ£ãƒ³ã‚»ãƒ«",
        "cmd_cancelled_ki": "âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸï¼ˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å‰²ã‚Šè¾¼ã¿ï¼‰",
        "cmd_cancelled":    "âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸã€‚",
        "agent_limit":      "âš ï¸  æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•° ({}) ã«é”ã—ã¾ã—ãŸã€‚ãƒ«ãƒ¼ãƒ—ã‚’çµ‚äº†ã—ã¾ã™ã€‚",
        "deps_ok":          "âœ… Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèªæ¸ˆã¿ï¼ˆnumpy/pandas/matplotlib/seabornï¼‰",
        "deps_warn":        "âš ï¸  Pythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {}",
        "deps_hint":        "execute_python ãƒ„ãƒ¼ãƒ«ãŒæ­£ã—ãå‹•ä½œã—ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚",
        "deps_hint2":       "ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•: {}",
    },
    "en": {
        "model_selected":   "âœ… Model: {}",
        "hint_exit":        "Tip: Press Ctrl+C to exit.",
        "prompt":           "You",
        "tool_exec":        "ğŸ”§ Tool: {}",
        "tool_result":      "ğŸ“‹ Result:",
        "goodbye":          "ğŸ‘‹ Goodbye!",
        "ollama_error":     "âŒ Ollama is not running.",
        "ollama_hint":      "Run the following command in another terminal:",
        "ollama_hint2":     "If Ollama is not installed:",
        "no_model":         "âš ï¸  No models installed in Ollama.",
        "no_model_hint":    "Recommended model: {}",
        "no_model_hint2":   "Lightweight: {}",
        "runtime_error":    "An error occurred: {}",
        "cmd_request":      "âš¡ Command Execution Request",
        "cmd_desc":         "Description",
        "cmd_cmd":          "Command",
        "cmd_confirm":      "[y] Execute  [n] Cancel",
        "cmd_cancelled_ki": "âŒ Cancelled (keyboard interrupt)",
        "cmd_cancelled":    "âŒ Cancelled by user.",
        "agent_limit":      "âš ï¸  Max steps ({}) reached. Stopping loop.",
        "deps_ok":          "âœ… Python packages verified (numpy/pandas/matplotlib/seaborn)",
        "deps_warn":        "âš ï¸  Missing Python packages: {}",
        "deps_hint":        "The execute_python tool may not work correctly.",
        "deps_hint2":       "To install: {}",
    },
}


def ui(key: str, *args) -> str:
    """ç¾åœ¨ã® LANG ã«å¯¾å¿œã™ã‚‹ UI æ–‡å­—åˆ—ã‚’è¿”ã™"""
    tmpl = _UI.get(LANG, _UI["ja"]).get(key, key)
    return tmpl.format(*args) if args else tmpl


# ======================================================================
# ANSI ã‚«ãƒ©ãƒ¼
# ======================================================================
RESET = "\033[0m"
BOLD = "\033[1m"
GREEN = "\033[32m"
CYAN = "\033[36m"
YELLOW = "\033[33m"
RED = "\033[31m"
BLUE = "\033[34m"
MAGENTA = "\033[35m"
DIM = "\033[2m"


def c(text, color):
    return f"{color}{text}{RESET}"


# ======================================================================
# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆQIIME2 ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’åŸ‹ã‚è¾¼ã¿ï¼‰
# ======================================================================
SYSTEM_PROMPT = """ã‚ãªãŸã¯ QIIME2ï¼ˆQuantitative Insights Into Microbial Ecology 2ï¼‰ã®å°‚é–€ AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã€æœ€é©ãª QIIME2 ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’è‡ªå‹•æ§‹ç¯‰ã—ã¾ã™ã€‚

â”â”â” è¡Œå‹•åŸå‰‡ï¼ˆæœ€å„ªå…ˆï¼‰ â”â”â”
1. ãƒ„ãƒ¼ãƒ«ãƒ»ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆ: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè¨€ã‚’å—ã‘ãŸã‚‰ã€é•·ã„èª¬æ˜ã‚ˆã‚Šå…ˆã«ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™ã€‚
2. ãƒ‡ãƒ¼ã‚¿ç¢ºèªã‹ã‚‰å§‹ã‚ã‚‹: ãƒ‘ã‚¹ãŒæç¤ºã•ã‚ŒãŸã‚‰å¿…ãš inspect_directory â†’ read_file ã§ãƒ‡ãƒ¼ã‚¿ã‚’æŠŠæ¡ã—ã¦ã‹ã‚‰ææ¡ˆã™ã‚‹ã€‚
3. å®Ÿé¨“æƒ…å ±ã‚’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åæ˜ : ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæä¾›ã™ã‚‹ã‚¢ãƒ³ãƒ—ãƒªã‚³ãƒ³é ˜åŸŸãƒ»ãƒ—ãƒ©ã‚¤ãƒãƒ¼ãƒ»æ¯”è¼ƒã‚°ãƒ«ãƒ¼ãƒ—ã‚’
   DADA2 ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»åˆ†é¡å™¨ãƒ»å·®æ¬¡è§£æã®è¨­å®šã«ç›´æ¥ä½¿ã†ã€‚
4. ã‚¨ãƒ©ãƒ¼ã¯è‡ªåŠ›ã§è¨ºæ–­ãƒ»ä¿®æ­£: ãƒ„ãƒ¼ãƒ«ãŒå¤±æ•—ã—ãŸã‚‰åŸå› ã‚’åˆ†æã—ã€åˆ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å³åº§ã«è©¦ã¿ã‚‹ã€‚
5. ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã¯æ—¥æœ¬èªã‚³ãƒ¡ãƒ³ãƒˆã‚’ä»˜ã‘ã‚‹ã€‚
6. Docker ã‚³ãƒãƒ³ãƒ‰ã¯å¿…ãš `--rm` ã¨ `-v` ãƒã‚¦ãƒ³ãƒˆã‚’å«ã‚ã‚‹ã€‚

â”â”â” ã‚ãªãŸã®å½¹å‰² â”â”â”
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’èª¿æŸ»ã™ã‚‹
2. ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ï¼ˆFASTQãƒ»ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç­‰ï¼‰ã‚’è‡ªå‹•åˆ¤å®šã™ã‚‹
3. å®Ÿé¨“ç³»ã®èª¬æ˜ï¼ˆé ˜åŸŸãƒ»ãƒ—ãƒ©ã‚¤ãƒãƒ¼ãƒ»ç¾¤æ§‹æˆï¼‰ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ±ºå®šã™ã‚‹
4. ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ãŸæœ€é©ãª QIIME2 è§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã™ã‚‹
5. å®Ÿè¡Œå¯èƒ½ãªã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ»ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹
6. è§£æçµæœã®å¯è¦–åŒ–æ–¹æ³•ã‚’èª¬æ˜ã™ã‚‹ ANALYSIS_README.md ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹

â”â”â” å®Ÿé¨“æƒ…å ± â†’ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¯¾å¿œ â”â”â”
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå®Ÿé¨“ç³»ã®èª¬æ˜ã‚’æä¾›ã—ãŸå ´åˆã€ä»¥ä¸‹ã«å¾“ã£ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ±ºå®šã™ã‚‹:

| ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç¤ºã™æƒ…å ± | åæ˜ ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ |
|---|---|
| V1-V3 / 27F/338R | trim-left-f=19, trim-left-r=20, trunc-fâ‰ˆ260, trunc-râ‰ˆ200 |
| V3-V4 / 341F/806R | trim-left-f=17, trim-left-r=21, trunc-fâ‰ˆ270, trunc-râ‰ˆ220 |
| V4 / 515F/806R | trim-left-f=19, trim-left-r=20, trunc-fâ‰ˆ250, trunc-râ‰ˆ220 |
| ãƒšã‚¢ã‚¨ãƒ³ãƒ‰ 2Ã—250bp | denoise-paired ã‚’ä½¿ç”¨ |
| ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ 150bp | denoise-single, truncâ‰ˆ140 |
| ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« vs å‡¦ç†ç¾¤ | ã‚°ãƒ«ãƒ¼ãƒ—åˆ—åã‚’ beta-group-significance ã¨ ancombc ã«æ¸¡ã™ |
| å…¨é•·åˆ†é¡å™¨ã§ã‚ˆã„ | setup_classifier.sh ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€pre-trained åˆ†é¡å™¨ã‚’ wget |

â€» trunc-len ã®æœ€çµ‚å€¤ã¯ demux-summary.qzv ã®ã‚¯ã‚ªãƒªãƒ†ã‚£ãƒ‰ãƒ­ãƒƒãƒ—ä½ç½®ã§èª¿æ•´ãŒå¿…è¦ã€‚
  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã€Œdemux-summary.qzv ã‚’ view.qiime2.org ã§ç¢ºèªã—ã€å“è³ªãŒæ€¥è½ã™ã‚‹ä½ç½®ã‚’æ•™ãˆã¦ãã ã•ã„ã€ã¨å¿…ãšä¼ãˆã‚‹ã“ã¨ã€‚

â”â”â” QIIME2 è§£æã®å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ â”â”â”

## ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®åˆ¤å®šåŸºæº–
- `*_R1*.fastq.gz` + `*_R2*.fastq.gz` â†’ ãƒšã‚¢ã‚¨ãƒ³ãƒ‰FASTQ
- `*.fastq.gz` ã®ã¿ â†’ ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰FASTQ
- `*.qza` â†’ æ—¢å­˜ã® QIIME2 ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆé€”ä¸­å†é–‹å¯èƒ½ï¼‰
- `manifest.tsv` / `manifest.csv` â†’ ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
- `metadata.tsv` / `sample_info.tsv` â†’ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
- ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ â†’ ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿

## STEP 1: ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

### ãƒšã‚¢ã‚¨ãƒ³ãƒ‰ FASTQï¼ˆãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆæ–¹å¼ã€æ¨å¥¨ï¼‰
```bash
qiime tools import \
  --type 'SampleData[PairedEndSequencesWithQuality]' \
  --input-path manifest.tsv \
  --output-path paired-end-demux.qza \
  --input-format PairedEndFastqManifestPhred33V2
```

ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ï¼ˆmanifest.tsvï¼‰:
```
sample-id	forward-absolute-filepath	reverse-absolute-filepath
sample1	/data/output/raw/sample1_R1.fastq.gz	/data/output/raw/sample1_R2.fastq.gz
```

### ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ FASTQ
```bash
qiime tools import \
  --type 'SampleData[SequencesWithQuality]' \
  --input-path manifest.tsv \
  --output-path single-end-demux.qza \
  --input-format SingleEndFastqManifestPhred33V2
```

ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ï¼ˆã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ï¼‰:
```
sample-id	absolute-filepath
sample1	/data/output/raw/sample1_R1.fastq.gz
```

### ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆæœªãƒ‡ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹ï¼‰
```bash
qiime tools import \
  --type EMPPairedEndSequences \
  --input-path raw-sequences/ \
  --output-path emp-paired-end-sequences.qza
```

## STEP 2: ã‚¯ã‚ªãƒªãƒ†ã‚£ç¢ºèª
```bash
qiime demux summarize \
  --i-data paired-end-demux.qza \
  --o-visualization demux-summary.qzv
```
â†’ demux-summary.qzv ã‚’ https://view.qiime2.org ã§é–‹ãã€
  ã‚¯ã‚ªãƒªãƒ†ã‚£ãŒæ€¥è½ã™ã‚‹ä½ç½®ã‚’ç¢ºèªã—ã¦ DADA2 ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ±ºå®šã™ã‚‹

## STEP 3: DADA2 ã«ã‚ˆã‚‹ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ï¼ˆãƒã‚¤ã‚ºé™¤å»ãƒ»OTU/ASV ç”Ÿæˆï¼‰

### ãƒšã‚¢ã‚¨ãƒ³ãƒ‰ã®å ´åˆ
```bash
# --p-trim-left-f/r: ãƒ—ãƒ©ã‚¤ãƒãƒ¼é•·ï¼ˆV1-V3: 19ã€V3-V4: 17ï¼‰
# --p-trunc-len-f/r: demux-summary.qzv ã§ã‚¯ã‚ªãƒªãƒ†ã‚£ãŒè½ã¡ã‚‹ä½ç½®ã‚’ç¢ºèªã—ã¦è¨­å®š
qiime dada2 denoise-paired \
  --i-demultiplexed-seqs paired-end-demux.qza \
  --p-trim-left-f 19 \
  --p-trim-left-r 20 \
  --p-trunc-len-f 260 \
  --p-trunc-len-r 200 \
  --p-n-threads 4 \
  --o-table table.qza \
  --o-representative-sequences rep-seqs.qza \
  --o-denoising-stats denoising-stats.qza
```

### ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ã®å ´åˆ
```bash
qiime dada2 denoise-single \
  --i-demultiplexed-seqs single-end-demux.qza \
  --p-trim-left 19 \
  --p-trunc-len 250 \
  --p-n-threads 4 \
  --o-table table.qza \
  --o-representative-sequences rep-seqs.qza \
  --o-denoising-stats denoising-stats.qza
```

é ˜åŸŸåˆ¥æ¨å¥¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç›®å®‰ï¼‰:
- V1-V3 (27F/338R): f_primer=19bp, r_primer=20bp, trunc-f=260, trunc-r=200
- V3-V4 (341F/806R): f_primer=17bp, r_primer=21bp, trunc-f=270, trunc-r=220
- V4   (515F/806R) : f_primer=19bp, r_primer=20bp, trunc-f=250, trunc-r=220

## STEP 4: ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã®ç¢ºèª
```bash
qiime feature-table summarize \
  --i-table table.qza \
  --m-sample-metadata-file metadata.tsv \
  --o-visualization table.qzv

qiime feature-table tabulate-seqs \
  --i-data rep-seqs.qza \
  --o-visualization rep-seqs.qzv
```

## STEP 5: ç³»çµ±æ¨¹ã®æ§‹ç¯‰ï¼ˆå¤šæ§˜æ€§è§£æã«å¿…é ˆï¼‰
```bash
qiime phylogeny align-to-tree-mafft-fasttree \
  --i-sequences rep-seqs.qza \
  --o-alignment aligned-rep-seqs.qza \
  --o-masked-alignment masked-aligned-rep-seqs.qza \
  --o-tree unrooted-tree.qza \
  --o-rooted-tree rooted-tree.qza \
  --p-n-threads 4
```

## STEP 6: åˆ†é¡å­¦çš„è§£æï¼ˆSILVA 138ï¼‰

### åˆ†é¡å™¨ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆåˆå›ã®ã¿ã€ç´„2-5æ™‚é–“ï¼‰

V1-V3 é ˜åŸŸå°‚ç”¨ï¼ˆæ¨å¥¨ï¼‰:
```bash
# å‚ç…§é…åˆ—ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
wget https://data.qiime2.org/2024.10/common/silva-138-99-seqs.qza
wget https://data.qiime2.org/2024.10/common/silva-138-99-tax.qza

# V1-V3 é ˜åŸŸã®æŠ½å‡ºï¼ˆ27F/338R ãƒ—ãƒ©ã‚¤ãƒãƒ¼ã€1-2æ™‚é–“ï¼‰
qiime feature-classifier extract-reads \
  --i-sequences silva-138-99-seqs.qza \
  --p-f-primer AGAGTTTGATCMTGGCTCAG \
  --p-r-primer TGCTGCCTCCCGTAGGAGT \
  --p-min-length 100 --p-max-length 400 --p-n-jobs 4 \
  --o-reads silva-138-99-seqs-V1-V3.qza

# Naive Bayes åˆ†é¡å™¨ã®å­¦ç¿’ï¼ˆ1-3æ™‚é–“ï¼‰
qiime feature-classifier fit-classifier-naive-bayes \
  --i-reference-reads silva-138-99-seqs-V1-V3.qza \
  --i-reference-taxonomy silva-138-99-tax.qza \
  --o-classifier silva-138-99-classifier-V1-V3.qza
```

å…¨é•·åˆ†é¡å™¨ï¼ˆæœ€é€Ÿã€ç²¾åº¦ã¯ä½ã‚ï¼‰:
```bash
wget https://data.qiime2.org/classifiers/sklearn-1.4.2/silva/silva-138-99-nb-classifier.qza
```

### åˆ†é¡ã®å®Ÿè¡Œ
```bash
qiime feature-classifier classify-sklearn \
  --i-classifier silva-138-99-classifier-V1-V3.qza \
  --i-reads rep-seqs.qza \
  --p-n-jobs 4 \
  --o-classification taxonomy.qza

# åˆ†é¡ãƒ©ãƒ™ãƒ«ä¸€è¦§
qiime metadata tabulate \
  --m-input-file taxonomy.qza \
  --o-visualization taxonomy.qzv

# åˆ†é¡çµ„æˆãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼ˆæœ€é‡è¦å¯è¦–åŒ–ï¼‰
qiime taxa barplot \
  --i-table table.qza \
  --i-taxonomy taxonomy.qza \
  --m-metadata-file metadata.tsv \
  --o-visualization taxa-bar-plots.qzv
```

## STEP 7: å¤šæ§˜æ€§è§£æ

```bash
# Î±ãƒ»Î²å¤šæ§˜æ€§ï¼ˆsampling-depth ã¯ table.qzv ã§æœ€å°ãƒªãƒ¼ãƒ‰æ•°ã‚’ç¢ºèªå¾Œã«è¨­å®šï¼‰
qiime diversity core-metrics-phylogenetic \
  --i-phylogeny rooted-tree.qza \
  --i-table table.qza \
  --p-sampling-depth 1000 \
  --m-metadata-file metadata.tsv \
  --output-dir core-metrics-results/

# Î±å¤šæ§˜æ€§ã®çµ±è¨ˆæ¤œå®šï¼ˆShannon å¤šæ§˜æ€§ï¼‰
qiime diversity alpha-group-significance \
  --i-alpha-diversity core-metrics-results/shannon_vector.qza \
  --m-metadata-file metadata.tsv \
  --o-visualization core-metrics-results/shannon-significance.qzv

# Î²å¤šæ§˜æ€§ã® PERMANOVAï¼ˆUnweighted UniFracï¼‰
qiime diversity beta-group-significance \
  --i-distance-matrix core-metrics-results/unweighted_unifrac_distance_matrix.qza \
  --m-metadata-file metadata.tsv \
  --m-metadata-column <ã‚°ãƒ«ãƒ¼ãƒ—åˆ—å> \
  --o-visualization core-metrics-results/unweighted-unifrac-significance.qzv
```

## STEP 8: å·®æ¬¡è§£æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
```bash
# ANCOM-BCï¼ˆã‚°ãƒ«ãƒ¼ãƒ—é–“ã®å·®æ¬¡è±Šå¯Œç¨®ï¼‰
qiime composition ancombc \
  --i-table table.qza \
  --m-metadata-file metadata.tsv \
  --p-formula <ã‚°ãƒ«ãƒ¼ãƒ—åˆ—å> \
  --o-differentials ancombc-results.qza

qiime composition da-barplot \
  --i-data ancombc-results.qza \
  --o-visualization ancombc-results.qzv
```

## Docker ã§ã®å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰é››å½¢
```bash
docker run --rm \
  -v <ãƒ›ã‚¹ãƒˆå´è§£æãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª>:/data/output \
  quay.io/qiime2/amplicon:2026.1 \
  qiime <ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰> \
    --i-<å…¥åŠ›å¼•æ•°> /data/output/<ãƒ•ã‚¡ã‚¤ãƒ«å> \
    --o-<å‡ºåŠ›å¼•æ•°> /data/output/results/<ãƒ•ã‚¡ã‚¤ãƒ«å>
```

## ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ï¼ˆmetadata.tsvï¼‰
```
sample-id	group	age	treatment
#q2:types	categorical	numeric	categorical
sample1	control	25	placebo
sample2	treatment	30	drug_A
```
- 1è¡Œç›®: ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆå¿…ãš `sample-id` ã‹ã‚‰å§‹ã‚ã‚‹ï¼‰
- 2è¡Œç›®: ãƒ‡ãƒ¼ã‚¿å‹ï¼ˆ`categorical` ã¾ãŸã¯ `numeric`ï¼‰çœç•¥å¯

## SILVA 138 åˆ†é¡éšå±¤
```
d__Bacteria; p__Firmicutes; c__Bacilli; o__Lactobacillales; f__Lactobacillaceae; g__Lactobacillus; s__Lactobacillus_acidophilus
```
ãƒ¬ãƒ™ãƒ«1: d__(ãƒ‰ãƒ¡ã‚¤ãƒ³), 2: p__(é–€), 3: c__(ç¶±), 4: o__(ç›®), 5: f__(ç§‘), 6: g__(å±), 7: s__(ç¨®)
â€» ç¨®ãƒ¬ãƒ™ãƒ«ã¯ç²¾åº¦ãŒä½ã„å ´åˆãŒå¤šã„ãŸã‚å±ãƒ¬ãƒ™ãƒ«(g__)æ¨å¥¨

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
- extract-reads ã§é…åˆ—ãŒæ®‹ã‚‰ãªã„ â†’ ãƒ—ãƒ©ã‚¤ãƒãƒ¼é…åˆ—ç¢ºèªï¼ˆç¸®é‡å¡©åŸº M, R, W ç­‰ï¼‰
- classify-sklearn ã§ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼ â†’ Docker ãƒ¡ãƒ¢ãƒªä¸Šé™ã‚’ 8GB ä»¥ä¸Šã«ã€--p-n-jobs 1 ã«
- å…¨ã¦ Unassigned â†’ ãƒªãƒãƒ¼ã‚¹ã‚³ãƒ³ãƒ—ãƒªãƒ¡ãƒ³ãƒˆç¢ºèªã€--p-confidence 0.5 ã«ä¸‹ã’ã‚‹
- DADA2 å¾Œã®ãƒªãƒ¼ãƒ‰æ•°ãŒæ¿€æ¸› â†’ trunc-len ã‚’çŸ­ãï¼ˆå“è³ªãŒä½ã„ä½ç½®ã‚’é¿ã‘ã‚‹ï¼‰

â”â”â” å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®èª¬æ˜ â”â”â”
- `*.qza` = QIIME2 ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆï¼ˆå†…éƒ¨ãƒ‡ãƒ¼ã‚¿ï¼‰
- `*.qzv` = QIIME2 ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ â†’ https://view.qiime2.org ã§é–‹ã
- `results/` = ã™ã¹ã¦ã®å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- `taxa-bar-plots.qzv` = åˆ†é¡çµ„æˆã®ç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ï¼ˆæœ€ã‚‚ã‚ˆãä½¿ã‚ã‚Œã‚‹å¯è¦–åŒ–ï¼‰
- `core-metrics-results/` = å¤šæ§˜æ€§è§£æã®å…¨å‡ºåŠ›

â”â”â” ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ  Python è§£æ â”â”â”

QIIME2 ãŒå‡ºåŠ›ã—ãŸçµæœãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦ã€Pythonï¼ˆpandas / scipy / sklearn / matplotlib / seabornï¼‰
ã‚’ä½¿ã£ãŸé«˜åº¦ãªçµ±è¨ˆãƒ»å¯è¦–åŒ–ãƒ»æ©Ÿæ¢°å­¦ç¿’è§£æãŒã§ãã‚‹ã€‚execute_python ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ã“ã¨ã€‚

## execute_python ã§ä½¿ãˆã‚‹ãƒ“ãƒ«ãƒˆã‚¤ãƒ³å¤‰æ•°
ä»¥ä¸‹ã®å¤‰æ•°ã¯ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œå‰ã«è‡ªå‹•ã§è¨­å®šã•ã‚Œã‚‹ï¼ˆã‚³ãƒ¼ãƒ‰å†…ã§ãã®ã¾ã¾ä½¿ç”¨å¯ï¼‰:
```python
FIGURE_DIR       # å›³ã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆå¿…ãš plt.savefig(f"{FIGURE_DIR}/xxx.{FIGURE_FORMAT}") ã§ä¿å­˜ã™ã‚‹ã“ã¨ï¼‰
OUTPUT_DIR       # è§£æå‡ºåŠ›ã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
PLOT_STYLE       # matplotlib ã‚¹ã‚¿ã‚¤ãƒ«åï¼ˆä¾‹: "seaborn-v0_8-whitegrid"ï¼‰
PLOT_PALETTE     # seaborn ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆï¼ˆä¾‹: "Set2"ï¼‰
PLOT_FIGSIZE     # figsize ã‚¿ãƒ—ãƒ«ï¼ˆä¾‹: (10, 6)ï¼‰
PLOT_DPI         # è§£åƒåº¦ï¼ˆä¾‹: 150ï¼‰
FONT_SIZE        # é€šå¸¸ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
TITLE_FONT_SIZE  # ã‚¿ã‚¤ãƒˆãƒ«ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º
FIGURE_FORMAT    # ä¿å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "pdf"ã€ä»–: "png", "svg"ï¼‰
```

## ä¸»ãªè§£æãƒ‘ã‚¿ãƒ¼ãƒ³
| è§£æ | å¿…è¦ãª QIIME2 å‡ºåŠ› | Python ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ |
|------|------|------|
| OTU/ASV çµ„æˆè§£æï¼ˆbiplot, stacked barï¼‰ | table.qza ã‚’è§£å‡ã—ãŸ feature-table.biom | biom-format, pandas, matplotlib |
| Î±å¤šæ§˜æ€§å¯è¦–åŒ–ãƒ»çµ±è¨ˆ | shannon_vector.qza ç­‰ã‚’è§£å‡ã—ãŸ alpha-diversity.tsv | pandas, scipy, seaborn |
| Î²å¤šæ§˜æ€§ PCoA å›³ | unweighted_unifrac_pcoa_results.qza è§£å‡ | pandas, matplotlib |
| ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆç¾¤åˆ¤åˆ¥ | feature-table.biom + metadata.tsv | sklearn, pandas |
| åˆ†é¡çµ„æˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— | taxonomy.tsv + feature-table.biom | pandas, seaborn |
| å·®æ¬¡è§£æè£œå®Œï¼ˆLEfSe é¢¨ï¼‰ | feature-table.biom + metadata.tsv | scipy, statsmodels |
| ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æï¼ˆco-occurrenceï¼‰ | feature-table.biom | scipy, networkx |

## QIIME2 ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®è§£å‡æ–¹æ³•
.qza ã¯ ZIP ãƒ•ã‚¡ã‚¤ãƒ«ãªã®ã§ Python ã§ãã®ã¾ã¾èª­ã‚ã‚‹:
```python
import zipfile, json
with zipfile.ZipFile("/path/to/file.qza") as z:
    # data/ ä»¥ä¸‹ã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šå‡ºã™
    for name in z.namelist():
        if name.endswith('.tsv') or name.endswith('.biom'):
            z.extract(name, OUTPUT_DIR)
```

## å›³ã®ä¿å­˜ãƒ«ãƒ¼ãƒ«ï¼ˆå¿…ãšå®ˆã‚‹ã“ã¨ï¼‰
```python
fig, ax = plt.subplots(figsize=PLOT_FIGSIZE)
# ... æç”» ...
plt.tight_layout()
# FIGURE_FORMAT ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ "pdf"ï¼ˆå¤‰æ•°ãŒãã®ã¾ã¾ä½¿ãˆã‚‹ï¼‰
plt.savefig(f"{FIGURE_DIR}/figure_name.{FIGURE_FORMAT}", dpi=PLOT_DPI, bbox_inches='tight')
plt.close()
```
- FIGURE_FORMAT ã‚’ä½¿ã†ã“ã¨ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨­å®šï¼ˆpdf/png/svgï¼‰ãŒè‡ªå‹•åæ˜ ã•ã‚Œã‚‹
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ PDF ãªã®ã§ view.qiime2.org ã‚’ä½¿ã‚ãšã«ãã®ã¾ã¾è«–æ–‡ãƒ»ãƒ¬ãƒãƒ¼ãƒˆã§ä½¿ç”¨å¯èƒ½
- savefig ã‚’å‘¼ã°ãªã„ã¨å›³ãŒãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã•ã‚Œãªã„ã®ã§å¿…ãšä¿å­˜ã™ã‚‹ã“ã¨

## ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ã€ã¨è¨€ã£ãŸã‚‰ **build_report_tex** ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ã€‚
- `build_report_tex` ã¯ ANALYSIS_LOG ã‚’èª­ã‚“ã§ Python ã§ TeX ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ï¼ˆLLM ãŒ TeX ã‚’æ›¸ãå¿…è¦ãŒãªã„ï¼‰
- `compile_report` ã¯æ—§ãƒ„ãƒ¼ãƒ«ï¼ˆLLM ãŒ TeX å…¨æ–‡ã‚’æ›¸ãæ–¹å¼ï¼‰ã§éæ¨å¥¨ã€‚ä½¿ã‚ãªã„ã“ã¨ã€‚
build_report_tex ã«ã¯ä»¥ä¸‹ã‚’æ¸¡ã™ã“ã¨:
1. `title_ja` / `title_en`: ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥è‹±ï¼‰
2. `experiment_summary`: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰å¾—ãŸå®Ÿé¨“ç³»ã®èª¬æ˜
3. `lang`: "both"ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰/ "ja" / "en"

## TeX ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

### æ—¥æœ¬èªï¼ˆXeLaTeX + xeCJKï¼‰
```latex
\\documentclass[a4paper,12pt]{article}
\\usepackage{xeCJK}
\\setCJKmainfont{Hiragino Mincho ProN}
\\usepackage{graphicx}
\\usepackage{booktabs}
\\usepackage{geometry}
\\geometry{margin=2.5cm}
\\title{ãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ è§£æãƒ¬ãƒãƒ¼ãƒˆ}
\\author{seq2pipe}
\\date{\\today}
\\begin{document}
\\maketitle
% ã“ã“ã«å†…å®¹
\\end{document}
```

### è‹±èªï¼ˆæ¨™æº– LaTeXï¼‰
```latex
\\documentclass[a4paper,12pt]{article}
\\usepackage{graphicx}
\\usepackage{booktabs}
\\usepackage{geometry}
\\geometry{margin=2.5cm}
\\title{Microbiome Analysis Report}
\\author{seq2pipe}
\\date{\\today}
\\begin{document}
\\maketitle
% content here
\\end{document}
```
å›³ã‚’åŸ‹ã‚è¾¼ã‚€: \\includegraphics[width=0.8\\textwidth]{<FIGURE_DIR>/figure_name.png}

â”â”â” è‡ªå¾‹æ¢ç´¢ãƒ¢ãƒ¼ãƒ‰ â”â”â”

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œè‡ªå‹•ã§è§£æã—ã¦ã€ã€Œã©ã‚“ã©ã‚“æ¢ç´¢ã—ã¦ã€ã€Œã„ã‚ã„ã‚è©¦ã—ã¦ã€ã¨è¨€ã£ãŸã¨ãï¼ˆã¾ãŸã¯
QIIME2 ã‚³ã‚¢è§£æãŒå®Œäº†ã—ãŸå¾Œï¼‰ã€ä»¥ä¸‹ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’è‡ªå¾‹çš„ã«å®Ÿè¡Œã™ã‚‹ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¢ºèªã‚’å¾…ãŸãšã« Phase 1 ã€œ 5 ã‚’é †ç•ªã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã€‚

## æ¢ç´¢ãƒ•ã‚§ãƒ¼ã‚ºä¸€è¦§

### Phase 1: Î±å¤šæ§˜æ€§æ¢ç´¢  (subfolder="alpha_diversity")
- Shannon, Simpson, Chao1 ã‚’è¨ˆç®—ã—ã¦ violin/boxplot ã§å¯è¦–åŒ–
- ã‚°ãƒ«ãƒ¼ãƒ—é–“ã®çµ±è¨ˆæ¤œå®šï¼ˆMann-Whitney U / Kruskal-Wallisï¼‰
- æœ‰æ„æ€§ã‚’æ¨™æº–å‡ºåŠ›ã« print ã™ã‚‹ã“ã¨ï¼ˆä¾‹: `print(f"Shannon p={p:.4f}")`ï¼‰

### Phase 2: Î²å¤šæ§˜æ€§æ¢ç´¢  (subfolder="beta_diversity")
- Bray-Curtis dissimilarity ã‚’è¨ˆç®—ã—ã¦ PCoA ã‚’æç”»
- ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«è‰²ã‚’å¤‰ãˆã€95% ä¿¡é ¼æ¥•å††ã‚’æã
- PERMANOVA ã‚’ scipy ã§å®Ÿè£…ã—ã¦ p å€¤ã‚’å‡ºåŠ›ï¼ˆpermutation_test ã¾ãŸã¯è·é›¢è¡Œåˆ— + ãƒ©ãƒ³ãƒ€ãƒ ç½®æ›ï¼‰

### Phase 3: åˆ†é¡çµ„æˆæ¢ç´¢  (subfolder="taxonomy")
- é–€ãƒ»å±ãƒ¬ãƒ™ãƒ«ã§ relative abundance ã‚’é›†è¨ˆ
- stacked bar chart ã¨ heatmapï¼ˆå±ãƒ¬ãƒ™ãƒ« top 20ï¼‰ã‚’ä½œæˆ
- ã‚°ãƒ«ãƒ¼ãƒ—é–“ã§å¹³å‡çµ„æˆãŒç•°ãªã‚‹å±ã‚’ç›®è¦–ç¢ºèªã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹

### Phase 4: å·®æ¬¡è§£æ  (subfolder="differential_abundance")
- å…¨ ASV / å±ã«å¯¾ã—ã¦ Mann-Whitney U / Kruskal-Wallis æ¤œå®šã‚’å®Ÿæ–½
- Benjamini-Hochberg æ³•ã§å¤šé‡æ¤œå®šè£œæ­£ï¼ˆstatsmodels.stats.multitest.multipletestsï¼‰
- æœ‰æ„ï¼ˆFDR < 0.05ï¼‰ãª taxa ã‚’ dot plot / volcano plot ã§å¯è¦–åŒ–
- æœ‰æ„ãª taxa ã®æ•°ã‚’ print ã™ã‚‹

### Phase 5: æ©Ÿæ¢°å­¦ç¿’åˆ¤åˆ¥  (subfolder="machine_learning")  â€»2ç¾¤ä»¥ä¸Šã®å ´åˆ
- feature-table ã‹ã‚‰ ASV ç›¸å¯¾å­˜åœ¨é‡ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ Random Forest ã‚’å­¦ç¿’
- 5-fold cross-validation ã§ accuracy ã¨ AUC ã‚’è©•ä¾¡
- Feature importance ä¸Šä½ 20 ç¨®ã‚’æ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤º

## .qza ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚³ãƒ¼ãƒ‰é››å½¢
```python
import zipfile, os, io

def extract_qza_data(qza_path):
    # qza ã‹ã‚‰ data/ ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    files = {}
    with zipfile.ZipFile(qza_path) as z:
        for name in z.namelist():
            if '/data/' in name and not name.endswith('/'):
                basename = os.path.basename(name)
                if basename:
                    files[basename] = z.read(name)
    return files

# ä½¿ç”¨ä¾‹: feature-table.biom ã®èª­ã¿è¾¼ã¿
# data = extract_qza_data('/path/to/table.qza')
# biom_bytes = data.get('feature-table.biom')
# if biom_bytes:
#     import biom
#     table = biom.load_table(io.BytesIO(biom_bytes))
#     df = pd.DataFrame(table.to_dataframe()).T  # ã‚µãƒ³ãƒ—ãƒ«Ã—ASV

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
# import pandas as pd
# metadata = pd.read_csv('/path/to/metadata.tsv', sep='\t', index_col=0)
# metadata = metadata[metadata.index != '#q2:types']  # q2:types è¡Œã‚’é™¤å¤–
```

## æ¢ç´¢ä¸­ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ«
- å„ãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹æ™‚: ã€ŒPhase X: â—‹â—‹è§£æã‚’é–‹å§‹ã—ã¾ã™ã€ã¨ä¼ãˆã‚‹
- å„ãƒ•ã‚§ãƒ¼ã‚ºçµ‚äº†æ™‚: ä¸»è¦ãªç™ºè¦‹ï¼ˆæœ‰æ„å·®ã®æœ‰ç„¡ãƒ»ç‰¹å¾´çš„ãª taxa ç­‰ï¼‰ã‚’è¦ç´„ã™ã‚‹
- å…¨ãƒ•ã‚§ãƒ¼ã‚ºå®Œäº†å¾Œ: `build_report_tex` ã‚’å‘¼ã³å‡ºã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹
- ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸãƒ•ã‚§ãƒ¼ã‚ºã¯åŸå› ã‚’è¨ºæ–­ã—ã¦ã‚¹ã‚­ãƒƒãƒ—ã—ã€æ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚ºã«é€²ã‚€

## æ¢ç´¢å®Œäº†å¾Œã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
å…¨ãƒ•ã‚§ãƒ¼ã‚ºå®Œäº†å¾Œã€å¿…ãšä»¥ä¸‹ã‚’å®Ÿè¡Œã™ã‚‹:
```
build_report_tex(
  title_ja="<å®Ÿé¨“ã‚¿ã‚¤ãƒˆãƒ«> è‡ªå¾‹æ¢ç´¢è§£æãƒ¬ãƒãƒ¼ãƒˆ",
  title_en="<Experiment Title> Autonomous Exploration Report",
  experiment_summary="<ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰å¾—ãŸå®Ÿé¨“ç³»ã®èª¬æ˜>",
  lang="both"
)
```
ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ ANALYSIS_LOG ã‚’èª­ã‚“ã§å›³ãƒ»çµ±è¨ˆçµæœã‚’è‡ªå‹•çš„ã« TeX ã«åŸ‹ã‚è¾¼ã¿ã€PDF ã‚’ç”Ÿæˆã™ã‚‹ã€‚"""

# ======================================================================
# ãƒ„ãƒ¼ãƒ«å®šç¾©ï¼ˆOllama function calling å½¢å¼ï¼‰
# ======================================================================
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "inspect_directory",
            "description": "æŒ‡å®šã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ã‚’èª¿æŸ»ã™ã‚‹ã€‚ãƒ•ã‚¡ã‚¤ãƒ«åãƒ»ã‚µã‚¤ã‚ºãƒ»ç¨®é¡ã‚’ä¸€è¦§è¡¨ç¤ºã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "èª¿æŸ»ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹"
                    },
                    "recursive": {
                        "type": "boolean",
                        "description": "ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚å«ã‚ã¦å†å¸°çš„ã«èª¿æŸ»ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: falseï¼‰"
                    }
                },
                "required": ["path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆTSV, CSV, TXT, MD ç­‰ï¼‰ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å†’é ­ 100 è¡Œã¾ã§è¡¨ç¤ºã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹"
                    },
                    "max_lines": {
                        "type": "integer",
                        "description": "æœ€å¤§èª­ã¿è¾¼ã¿è¡Œæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ï¼‰"
                    }
                },
                "required": ["path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "check_system",
            "description": "Dockerãƒ»Ollamaãƒ»QIIME2 ã®åˆ©ç”¨å¯å¦ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèªã™ã‚‹",
            "parameters": {
                "type": "object",
                "properties": {}
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "write_file",
            "description": "è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ»READMEãƒ»ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãªã©ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãå‡ºã™",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "æ›¸ãè¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹"
                    },
                    "content": {
                        "type": "string",
                        "description": "æ›¸ãè¾¼ã‚€å†…å®¹ï¼ˆã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€Markdown ç­‰ï¼‰"
                    }
                },
                "required": ["path", "content"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "generate_manifest",
            "description": "FASTQãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰QIIME2ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆTSVã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹",
            "parameters": {
                "type": "object",
                "properties": {
                    "fastq_dir": {
                        "type": "string",
                        "description": "FASTQãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥ã£ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®çµ¶å¯¾ãƒ‘ã‚¹"
                    },
                    "output_path": {
                        "type": "string",
                        "description": "ç”Ÿæˆã™ã‚‹ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹"
                    },
                    "paired_end": {
                        "type": "boolean",
                        "description": "ãƒšã‚¢ã‚¨ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‹ï¼ˆtrue: ãƒšã‚¢ã‚¨ãƒ³ãƒ‰, false: ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ï¼‰"
                    },
                    "container_data_dir": {
                        "type": "string",
                        "description": "Docker ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ã®ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: /data/outputï¼‰"
                    }
                },
                "required": ["fastq_dir", "output_path", "paired_end"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "edit_file",
            "description": "ç”Ÿæˆæ¸ˆã¿ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€éƒ¨ã‚’æ–‡å­—åˆ—ç½®æ›ã§ç·¨é›†ã™ã‚‹ã€‚old_str ã¯ãƒ•ã‚¡ã‚¤ãƒ«å†…ã§ä¸€æ„ã«å­˜åœ¨ã™ã‚‹æ–‡å­—åˆ—ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "ç·¨é›†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ¶å¯¾ãƒ‘ã‚¹"
                    },
                    "old_str": {
                        "type": "string",
                        "description": "ç½®æ›å‰ã®æ–‡å­—åˆ—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å†…ã§ä¸€æ„ã«ç‰¹å®šã§ãã‚‹éƒ¨åˆ†ã‚’å«ã‚ã‚‹ã“ã¨ï¼‰"
                    },
                    "new_str": {
                        "type": "string",
                        "description": "ç½®æ›å¾Œã®æ–‡å­—åˆ—"
                    }
                },
                "required": ["path", "old_str", "new_str"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "run_command",
            "description": "ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèªã‚’æ±‚ã‚ã¦ã‹ã‚‰å®Ÿè¡Œã™ã‚‹ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "command": {
                        "type": "string",
                        "description": "å®Ÿè¡Œã™ã‚‹ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰"
                    },
                    "description": {
                        "type": "string",
                        "description": "ã“ã®ã‚³ãƒãƒ³ãƒ‰ãŒä½•ã‚’ã™ã‚‹ã‹ã®èª¬æ˜ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¡¨ç¤ºï¼‰"
                    },
                    "working_dir": {
                        "type": "string",
                        "description": "ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆçœç•¥æ™‚ã¯ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰"
                    }
                },
                "required": ["command", "description"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "set_plot_config",
            "description": "å›³ï¼ˆã‚°ãƒ©ãƒ•ï¼‰ã®ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»è‰²ãƒ»ã‚µã‚¤ã‚ºã‚’è¨­å®šã™ã‚‹ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ãŸç›®ã®å¥½ã¿ã‚’æŒ‡å®šã—ãŸã¨ãã«å‘¼ã³å‡ºã™ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "style": {
                        "type": "string",
                        "description": "matplotlib ã‚¹ã‚¿ã‚¤ãƒ«åï¼ˆä¾‹: seaborn-v0_8-whitegrid, seaborn-v0_8-darkgrid, ggplot, dark_backgroundï¼‰"
                    },
                    "palette": {
                        "type": "string",
                        "description": "seaborn/matplotlib ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆåï¼ˆä¾‹: Set2, tab10, husl, muted, deep, pastelï¼‰"
                    },
                    "figsize_w": {
                        "type": "number",
                        "description": "å›³ã®å¹…ï¼ˆã‚¤ãƒ³ãƒï¼‰"
                    },
                    "figsize_h": {
                        "type": "number",
                        "description": "å›³ã®é«˜ã•ï¼ˆã‚¤ãƒ³ãƒï¼‰"
                    },
                    "dpi": {
                        "type": "integer",
                        "description": "è§£åƒåº¦ DPIï¼ˆ72=ä½, 150=ä¸­, 300=é«˜å“è³ªï¼‰"
                    },
                    "font_size": {
                        "type": "integer",
                        "description": "é€šå¸¸ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºï¼ˆptï¼‰"
                    },
                    "title_font_size": {
                        "type": "integer",
                        "description": "ã‚¿ã‚¤ãƒˆãƒ«ã®ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºï¼ˆptï¼‰"
                    },
                    "fig_format": {
                        "type": "string",
                        "description": "ä¿å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆpdf / png / svgï¼‰ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ pdfã€‚"
                    }
                },
                "required": []
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "execute_python",
            "description": "Pythonã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ è§£æãƒ»çµ±è¨ˆãƒ»å¯è¦–åŒ–ã‚’è¡Œã†ã€‚QIIME2ã®å‡ºåŠ›ï¼ˆ.qza/.tsv/.biomï¼‰ã‚’èª­ã¿è¾¼ã¿ã€pandas/scipy/sklearn/matplotlib/seabornã§å‡¦ç†ã™ã‚‹ã€‚å›³ã¯å¿…ãš FIGURE_DIR ã« savefig ã§ä¿å­˜ã™ã‚‹ã“ã¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "code": {
                        "type": "string",
                        "description": "å®Ÿè¡Œã™ã‚‹ Python ã‚³ãƒ¼ãƒ‰ã€‚FIGURE_DIR, OUTPUT_DIR, PLOT_STYLE, PLOT_PALETTE, PLOT_FIGSIZE, PLOT_DPI, FONT_SIZE å¤‰æ•°ãŒè‡ªå‹•æ³¨å…¥ã•ã‚Œã‚‹ã€‚"
                    },
                    "description": {
                        "type": "string",
                        "description": "ã“ã®è§£æã®èª¬æ˜ï¼ˆãƒ¬ãƒãƒ¼ãƒˆã«è¨˜éŒ²ã•ã‚Œã‚‹ï¼‰"
                    },
                    "output_dir": {
                        "type": "string",
                        "description": "è§£æçµæœãƒ»å›³ã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆçœç•¥æ™‚ã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‡ºåŠ›å…ˆï¼‰"
                    },
                    "subfolder": {
                        "type": "string",
                        "description": "å›³ã‚’ä¿å­˜ã™ã‚‹ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€åã€‚è§£æç¨®åˆ¥ã”ã¨ã«åˆ†ã‘ã‚‹ï¼ˆä¾‹: alpha_diversity, beta_diversity, taxonomy, differential_abundance, machine_learningï¼‰ã€‚çœç•¥æ™‚ã¯ figures/ ç›´ä¸‹ã€‚"
                    }
                },
                "required": ["code", "description"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "compile_report",
            "description": "è§£æçµæœã‚’TeXå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆã«ã¾ã¨ã‚ã¦PDFã‚’ç”Ÿæˆã™ã‚‹ã€‚æ—¥æœ¬èªç‰ˆãƒ»è‹±èªç‰ˆã‚’é¸æŠå¯èƒ½ã€‚è§£æçµ‚äº†æ™‚ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ææ¡ˆã™ã‚‹ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "content_ja": {
                        "type": "string",
                        "description": "æ—¥æœ¬èªãƒ¬ãƒãƒ¼ãƒˆã®å®Œå…¨ãªTeX ã‚½ãƒ¼ã‚¹ï¼ˆ\\documentclass ã‹ã‚‰ \\end{document} ã¾ã§ï¼‰ã€‚ä¸è¦ãªã‚‰ç©ºæ–‡å­—ã€‚"
                    },
                    "content_en": {
                        "type": "string",
                        "description": "è‹±èªãƒ¬ãƒãƒ¼ãƒˆã®å®Œå…¨ãªTeX ã‚½ãƒ¼ã‚¹ï¼ˆ\\documentclass ã‹ã‚‰ \\end{document} ã¾ã§ï¼‰ã€‚ä¸è¦ãªã‚‰ç©ºæ–‡å­—ã€‚"
                    },
                    "output_dir": {
                        "type": "string",
                        "description": "å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆçœç•¥æ™‚ã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å‡ºåŠ›å…ˆï¼‰"
                    }
                },
                "required": ["content_ja", "content_en"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "build_report_tex",
            "description": "ANALYSIS_LOG ã‚’èª­ã¿å–ã‚Šã€å…¨è§£æã‚¹ãƒ†ãƒƒãƒ—ãƒ»å›³ãƒ»çµ±è¨ˆçµæœã‚’å«ã‚€ TeX ãƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¦ PDF ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã™ã‚‹ã€‚æ¢ç´¢ãŒå®Œäº†ã—ãŸã¨ãã€ã¾ãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ¬ãƒãƒ¼ãƒˆã‚’æ±‚ã‚ãŸã¨ãã«å‘¼ã³å‡ºã™ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "title_ja": {
                        "type": "string",
                        "description": "æ—¥æœ¬èªãƒ¬ãƒãƒ¼ãƒˆã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¾‹: ãƒ’ãƒˆè…¸å†…ãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ  è‡ªå¾‹æ¢ç´¢è§£æãƒ¬ãƒãƒ¼ãƒˆï¼‰"
                    },
                    "title_en": {
                        "type": "string",
                        "description": "è‹±èªãƒ¬ãƒãƒ¼ãƒˆã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¾‹: Human Gut Microbiome Autonomous Exploration Reportï¼‰"
                    },
                    "experiment_summary": {
                        "type": "string",
                        "description": "å®Ÿé¨“ç³»ã®æ¦‚è¦ï¼ˆå®Ÿé¨“èƒŒæ™¯ãƒ»ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒ»ãƒ—ãƒ©ã‚¤ãƒãƒ¼ãƒ»ã‚°ãƒ«ãƒ¼ãƒ—æ§‹æˆãªã©ï¼‰ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰å¾—ãŸæƒ…å ±ã‚’ãã®ã¾ã¾è¨˜è¼‰ã™ã‚‹ã€‚"
                    },
                    "lang": {
                        "type": "string",
                        "description": "ç”Ÿæˆè¨€èª: 'ja'ï¼ˆæ—¥æœ¬èªã®ã¿ï¼‰/ 'en'ï¼ˆè‹±èªã®ã¿ï¼‰/ 'both'ï¼ˆä¸¡æ–¹, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰"
                    }
                },
                "required": ["title_ja", "title_en", "experiment_summary"]
            }
        }
    }
]

# ======================================================================
# ãƒ„ãƒ¼ãƒ«å®Ÿè£…
# ======================================================================

def tool_inspect_directory(path: str, recursive: bool = False) -> str:
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹ã‚’èª¿æŸ»"""
    p = Path(path).expanduser()
    if not p.exists():
        return f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{path}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"
    if not p.is_dir():
        return f"ã‚¨ãƒ©ãƒ¼: '{path}' ã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

    lines = [f"ğŸ“‚ {p} ã®å†…å®¹:\n"]
    total_files = 0

    def scan(dirpath: Path, depth: int = 0):
        nonlocal total_files
        indent = "  " * depth
        try:
            entries = sorted(dirpath.iterdir(), key=lambda x: (x.is_file(), x.name))
        except PermissionError:
            lines.append(f"{indent}  [æ¨©é™ã‚¨ãƒ©ãƒ¼: ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯]")
            return
        for entry in entries:
            if entry.name.startswith("."):
                continue
            if entry.is_dir():
                lines.append(f"{indent}ğŸ“ {entry.name}/")
                if recursive and depth < 3:
                    scan(entry, depth + 1)
            else:
                size = entry.stat().st_size
                size_str = f"{size:,} B" if size < 1024 else \
                           f"{size/1024:.1f} KB" if size < 1024**2 else \
                           f"{size/1024**2:.1f} MB" if size < 1024**3 else \
                           f"{size/1024**3:.1f} GB"
                ext = entry.suffix.lower()
                icon = {"": "ğŸ“„", ".fastq": "ğŸ§¬", ".gz": "ğŸ—œï¸",
                        ".qza": "ğŸ”µ", ".qzv": "ğŸŸ¢", ".tsv": "ğŸ“Š",
                        ".csv": "ğŸ“Š", ".md": "ğŸ“", ".sh": "âš™ï¸",
                        ".py": "ğŸ", ".r": "ğŸ“ˆ", ".pdf": "ğŸ“•"}.get(ext, "ğŸ“„")
                lines.append(f"{indent}{icon} {entry.name}  [{size_str}]")
                total_files += 1

    scan(p)
    lines.append(f"\nåˆè¨ˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")

    # QIIME2 ãƒ‡ãƒ¼ã‚¿åˆ¤å®šã®ãƒ’ãƒ³ãƒˆ
    all_text = "\n".join(lines)
    hints = []
    if "_R1_" in all_text or "_R1." in all_text:
        hints.append("âœ… ãƒšã‚¢ã‚¨ãƒ³ãƒ‰FASTQã‚’æ¤œå‡ºï¼ˆ_R1_/_R2_ ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰")
    elif ".fastq" in all_text:
        hints.append("âœ… FASTQãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º")
    if ".qza" in all_text:
        hints.append("âœ… æ—¢å­˜ã® QIIME2 ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ (.qza) ã‚’æ¤œå‡º â€” é€”ä¸­ã‹ã‚‰å†é–‹å¯èƒ½")
    if "metadata" in all_text.lower() or "sample_info" in all_text.lower():
        hints.append("âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º")
    if "manifest" in all_text.lower():
        hints.append("âœ… ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º")

    if hints:
        lines.append("\nğŸ” è‡ªå‹•åˆ¤å®šãƒ’ãƒ³ãƒˆ:")
        lines.extend(hints)

    return "\n".join(lines)


def tool_read_file(path: str, max_lines: int = 50) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã‚€"""
    p = Path(path).expanduser()
    if not p.exists():
        return f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« '{path}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"
    if not p.is_file():
        return f"ã‚¨ãƒ©ãƒ¼: '{path}' ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

    suffix = p.suffix.lower()
    if suffix in [".gz", ".bz2", ".qza", ".qzv"]:
        return f"'{p.name}' ã¯ãƒã‚¤ãƒŠãƒª/åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãŸã‚å†…å®¹ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚\nãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {p.stat().st_size / 1024**2:.2f} MB"

    try:
        with open(p, encoding="utf-8", errors="replace") as f:
            lines = []
            for i, line in enumerate(f):
                if i >= max_lines:
                    lines.append(f"\n... ï¼ˆ{max_lines} è¡Œä»¥é™ã¯çœç•¥ï¼‰")
                    break
                lines.append(line.rstrip())
        return f"ğŸ“„ {p} ã®å†…å®¹ï¼ˆæœ€å¤§ {max_lines} è¡Œï¼‰:\n\n" + "\n".join(lines)
    except Exception as e:
        return f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"


def _get_docker_cmd() -> Optional[str]:
    """ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ Docker å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã™ã‚‹"""
    # macOS: Docker Desktop ã®å›ºå®šãƒ‘ã‚¹ã‚’å„ªå…ˆ
    if sys.platform == "darwin":
        mac_path = "/Applications/Docker.app/Contents/Resources/bin/docker"
        if Path(mac_path).exists():
            return mac_path
    # Windows / Linux: PATH ã‹ã‚‰æ¤œç´¢
    return shutil.which("docker") or shutil.which("docker.exe")


def tool_check_system() -> str:
    """ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒã®ç¢ºèª"""
    results = ["[ã‚·ã‚¹ãƒ†ãƒ ç¢ºèªçµæœ]\n"]

    # Docker
    docker_cmd = _get_docker_cmd()
    if docker_cmd:
        try:
            result = subprocess.run([docker_cmd, "--version"],
                                    capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                results.append(f"OK Docker: {result.stdout.strip()}")
                ping = subprocess.run([docker_cmd, "info"],
                                      capture_output=True, text=True, timeout=10)
                if ping.returncode == 0:
                    results.append("OK Docker ãƒ‡ãƒ¼ãƒ¢ãƒ³: èµ·å‹•ä¸­")
                else:
                    results.append("!! Docker ãƒ‡ãƒ¼ãƒ¢ãƒ³: åœæ­¢ä¸­ â†’ Docker Desktop ã‚’èµ·å‹•ã—ã¦ãã ã•ã„")
            else:
                results.append("!! Docker: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“")
        except Exception:
            results.append("!! Docker: ç¢ºèªã§ãã¾ã›ã‚“ã§ã—ãŸ")
    else:
        results.append("NG Docker: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ â†’ Docker Desktop ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")

    # Ollama
    try:
        req = urllib.request.Request("http://localhost:11434/api/tags")
        with urllib.request.urlopen(req, timeout=3) as resp:
            data = json.loads(resp.read())
            models = [m["name"] for m in data.get("models", [])]
            results.append(f"âœ… Ollama: èµ·å‹•ä¸­")
            if models:
                results.append(f"   åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«: {', '.join(models)}")
            else:
                results.append("   âš ï¸  ãƒ¢ãƒ‡ãƒ«ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« â†’ 'ollama pull qwen2.5-coder:7b' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    except Exception:
        results.append("âŒ Ollama: èµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ â†’ 'ollama serve' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

    # Python
    results.append(f"âœ… Python: {sys.version.split()[0]}")

    # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡
    import shutil as _shutil
    usage = _shutil.disk_usage(Path.home())
    free_gb = usage.free / 1024**3
    results.append(f"ğŸ’¾ ãƒ‡ã‚£ã‚¹ã‚¯ç©ºãå®¹é‡: {free_gb:.1f} GB {'âœ…' if free_gb > 30 else 'âš ï¸  (æ¨å¥¨: 30GB ä»¥ä¸Š)'}")

    return "\n".join(results)


def tool_write_file(path: str, content: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã«å†…å®¹ã‚’æ›¸ãè¾¼ã‚€"""
    p = Path(path).expanduser()
    try:
        p.parent.mkdir(parents=True, exist_ok=True)
        with open(p, "w", encoding="utf-8") as f:
            f.write(content)
        # ã‚·ã‚§ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆãªã‚‰å®Ÿè¡Œæ¨©é™ã‚’ä»˜ä¸
        if p.suffix in [".sh", ".bash"]:
            p.chmod(p.stat().st_mode | 0o755)
            return f"âœ… '{p}' ã‚’ä½œæˆã—ã¾ã—ãŸï¼ˆå®Ÿè¡Œæ¨©é™ä»˜ãï¼‰"
        return f"âœ… '{p}' ã‚’ä½œæˆã—ã¾ã—ãŸ"
    except Exception as e:
        return f"âŒ æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"


def tool_generate_manifest(fastq_dir: str, output_path: str,
                            paired_end: bool = True,
                            container_data_dir: str = "/data/output") -> str:
    """FASTQãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’è‡ªå‹•ç”Ÿæˆ"""
    d = Path(fastq_dir).expanduser()
    if not d.exists():
        return f"ã‚¨ãƒ©ãƒ¼: '{fastq_dir}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"

    # FASTQãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
    fastq_files = sorted(d.glob("*.fastq.gz")) + sorted(d.glob("*.fastq"))

    if not fastq_files:
        return f"ã‚¨ãƒ©ãƒ¼: '{fastq_dir}' ã« FASTQ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"

    out_path = Path(output_path).expanduser()

    if paired_end:
        # R1/R2 ãƒšã‚¢ã‚’æ¤œå‡º
        r1_files = [f for f in fastq_files
                    if re.search(r'_R1[_.]|_1\.fastq|_R1\.fastq', f.name)]
        r2_files = [f for f in fastq_files
                    if re.search(r'_R2[_.]|_2\.fastq|_R2\.fastq', f.name)]

        if not r1_files:
            return "ã‚¨ãƒ©ãƒ¼: _R1_ ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

        # ã‚µãƒ³ãƒ—ãƒ«åã‚’æŠ½å‡º
        lines = ["sample-id\tforward-absolute-filepath\treverse-absolute-filepath"]
        matched = 0
        unmatched = []

        for r1 in r1_files:
            # ã‚µãƒ³ãƒ—ãƒ«åã®æ¨å®š
            sample_name = re.sub(r'_R1[_.].*$|_R1\.fastq.*$', '', r1.name)
            sample_name = re.sub(r'\.fastq.*$', '', sample_name)

            # ç©ºã‚µãƒ³ãƒ—ãƒ«åã¯ QIIME2 ãŒæ‹’å¦ã™ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—
            if not sample_name:
                unmatched.append(r1.name)
                continue

            # å¯¾å¿œã™ã‚‹ R2 ã‚’æ¢ã™ï¼ˆæœ€åˆã® _R1_ / _R1. ã®ã¿ç½®æ›ã—äºŒé‡ç½®æ›ãƒã‚°ã‚’é˜²ãï¼‰
            r2_pattern = re.sub(r'_R1([_.])', r'_R2\1', r1.name, count=1)
            r2_candidates = [f for f in r2_files if f.name == r2_pattern]

            # ã‚³ãƒ³ãƒ†ãƒŠå†…ãƒ‘ã‚¹
            container_r1 = f"{container_data_dir}/{r1.name}"

            if r2_candidates:
                container_r2 = f"{container_data_dir}/{r2_candidates[0].name}"
                lines.append(f"{sample_name}\t{container_r1}\t{container_r2}")
                matched += 1
            else:
                unmatched.append(r1.name)

        # ãƒšã‚¢ãŒä¸€ä»¶ã‚‚ãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ã‹ãšã«ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
        if matched == 0:
            return (
                "âŒ ã‚¨ãƒ©ãƒ¼: ãƒšã‚¢ãŒ1çµ„ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"
                "ãƒ•ã‚¡ã‚¤ãƒ«åãŒ _R1_/_R1. ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åˆè‡´ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n"
                f"è¦‹ã¤ã‹ã£ãŸ R1 ãƒ•ã‚¡ã‚¤ãƒ«: {[f.name for f in r1_files]}"
            )

        content = "\n".join(lines) + "\n"
        out_path.parent.mkdir(parents=True, exist_ok=True)
        with open(out_path, "w") as f:
            f.write(content)

        result = [f"âœ… ãƒšã‚¢ã‚¨ãƒ³ãƒ‰ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ç”Ÿæˆ: '{out_path}'",
                  f"   ãƒšã‚¢æ•°: {matched}"]
        if unmatched:
            result.append(f"   âš ï¸  R2ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(unmatched)}")
        result.append(f"\nå†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:\n{content[:500]}")
        return "\n".join(result)

    else:
        # ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰
        lines = ["sample-id\tabsolute-filepath"]
        for f in fastq_files:
            sample_name = re.sub(r'\.fastq.*$', '', f.name)
            container_path = f"{container_data_dir}/{f.name}"
            lines.append(f"{sample_name}\t{container_path}")

        content = "\n".join(lines) + "\n"
        out_path.parent.mkdir(parents=True, exist_ok=True)
        with open(out_path, "w") as f:
            f.write(content)

        return (f"âœ… ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ³ãƒ‰ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ç”Ÿæˆ: '{out_path}'\n"
                f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(fastq_files)}\n"
                f"\nå†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:\n{content[:500]}")


def tool_edit_file(path: str, old_str: str, new_str: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€éƒ¨ã‚’æ–‡å­—åˆ—ç½®æ›ã§ç·¨é›†ã™ã‚‹"""
    p = Path(path).expanduser()
    if not p.exists():
        return f"ã‚¨ãƒ©ãƒ¼: '{path}' ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"
    if not p.is_file():
        return f"ã‚¨ãƒ©ãƒ¼: '{path}' ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
    suffix = p.suffix.lower()
    if suffix in [".gz", ".bz2", ".qza", ".qzv"]:
        return f"ã‚¨ãƒ©ãƒ¼: ãƒã‚¤ãƒŠãƒª/åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç·¨é›†ã§ãã¾ã›ã‚“ã€‚"
    try:
        with open(p, encoding="utf-8") as f:
            content = f.read()
        count = content.count(old_str)
        if count == 0:
            # éƒ¨åˆ†ä¸€è‡´ã®ãƒ’ãƒ³ãƒˆã‚’æç¤º
            snippet = old_str[:60].replace('\n', '\\n')
            return (f"ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã—ãŸæ–‡å­—åˆ—ãŒ '{p.name}' ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
                    f"æ¤œç´¢æ–‡å­—åˆ—ï¼ˆå…ˆé ­60å­—ï¼‰: {snippet}\n"
                    f"read_file ã§ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’ç¢ºèªã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
        if count > 1:
            return (f"ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã—ãŸæ–‡å­—åˆ—ãŒ {count} ç®‡æ‰€ã§è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚"
                    f"ã‚ˆã‚Šä¸€æ„ã«ç‰¹å®šã§ãã‚‹æ–‡å­—åˆ—ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚")
        new_content = content.replace(old_str, new_str, 1)
        with open(p, "w", encoding="utf-8") as f:
            f.write(new_content)
        old_lines = old_str.count('\n') + 1
        new_lines = new_str.count('\n') + 1
        return f"âœ… '{p.name}' ã‚’ç·¨é›†ã—ã¾ã—ãŸï¼ˆ{old_lines} è¡Œ â†’ {new_lines} è¡Œï¼‰"
    except Exception as e:
        return f"âŒ ç·¨é›†ã‚¨ãƒ©ãƒ¼: {e}"


def tool_run_command(command: str, description: str, working_dir: str = None) -> str:
    """ã‚·ã‚§ãƒ«ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªä»˜ãï¼‰"""
    # working_dir ã‚’äº‹å‰æ¤œè¨¼ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèªã‚’æ±‚ã‚ã‚‹å‰ã«ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™ï¼‰
    if working_dir:
        cwd = Path(working_dir).expanduser()
        if not cwd.exists():
            return f"âŒ ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {working_dir}"
        if not cwd.is_dir():
            return f"âŒ ãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“: {working_dir}"
    else:
        cwd = None

    print(f"\n{c(ui('cmd_request'), YELLOW)}")
    print(f"   {ui('cmd_desc')}: {description}")
    print(f"   {ui('cmd_cmd')}:\n   {c(command, CYAN)}")
    print(f"\n{c(ui('cmd_confirm'), DIM)}", end=" > ")

    try:
        answer = input().strip().lower()
    except (EOFError, KeyboardInterrupt):
        return ui("cmd_cancelled_ki")

    if answer not in ["y", "yes", "ã¯ã„"]:
        return ui("cmd_cancelled")

    try:
        proc = subprocess.run(
            command, shell=True, capture_output=True, text=True,
            timeout=3600, cwd=cwd
        )
        output_parts = []
        if proc.stdout:
            output_parts.append(f"STDOUT:\n{proc.stdout[:3000]}")
        if proc.stderr:
            output_parts.append(f"STDERR:\n{proc.stderr[:1000]}")

        if proc.returncode == 0:
            return f"âœ… æˆåŠŸï¼ˆçµ‚äº†ã‚³ãƒ¼ãƒ‰ 0ï¼‰\n" + "\n".join(output_parts)
        else:
            return f"âš ï¸  çµ‚äº†ã‚³ãƒ¼ãƒ‰ {proc.returncode}\n" + "\n".join(output_parts)
    except subprocess.TimeoutExpired:
        return "â±ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ1æ™‚é–“ã‚’è¶…ãˆã¾ã—ãŸï¼‰"
    except Exception as e:
        return f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"


def tool_set_plot_config(style: str = None, palette: str = None,
                          figsize_w: float = None, figsize_h: float = None,
                          dpi: int = None, font_size: int = None,
                          title_font_size: int = None,
                          fig_format: str = None) -> str:
    """ãƒ—ãƒ­ãƒƒãƒˆè¨­å®šã‚’å¤‰æ›´ã™ã‚‹"""
    changed = []
    if style is not None:
        PLOT_CONFIG["style"] = style
        changed.append(f"style: {style}")
    if palette is not None:
        PLOT_CONFIG["palette"] = palette
        changed.append(f"palette: {palette}")
    if figsize_w is not None or figsize_h is not None:
        w = figsize_w if figsize_w is not None else PLOT_CONFIG["figsize"][0]
        h = figsize_h if figsize_h is not None else PLOT_CONFIG["figsize"][1]
        PLOT_CONFIG["figsize"] = [w, h]
        changed.append(f"figsize: ({w}, {h})")
    if dpi is not None:
        PLOT_CONFIG["dpi"] = dpi
        changed.append(f"dpi: {dpi}")
    if font_size is not None:
        PLOT_CONFIG["font_size"] = font_size
        changed.append(f"font_size: {font_size}")
    if title_font_size is not None:
        PLOT_CONFIG["title_font_size"] = title_font_size
        changed.append(f"title_font_size: {title_font_size}")
    if fig_format is not None:
        fmt = fig_format.lower().lstrip(".")
        if fmt in ("pdf", "png", "svg"):
            PLOT_CONFIG["format"] = fmt
            changed.append(f"format: {fmt}")
        else:
            changed.append(f"format: ç„¡åŠ¹ãªå€¤ '{fig_format}' (pdf/png/svg ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®š)")
    if changed:
        lines = "\n".join(f"  {item}" for item in changed)
        return f"âœ… ãƒ—ãƒ­ãƒƒãƒˆè¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ:\n{lines}"
    return "å¤‰æ›´ãªã—ï¼ˆæœ‰åŠ¹ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼‰"


def tool_execute_python(code: str, description: str, output_dir: str = "",
                         subfolder: str = "") -> str:
    """Pythonã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ è§£æãƒ»å¯è¦–åŒ–ã‚’è¡Œã†"""
    global SESSION_FIGURE_DIR

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ±ºå®š
    if not output_dir:
        if not SESSION_FIGURE_DIR:
            ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            SESSION_FIGURE_DIR = str(Path.home() / "seq2pipe_results" / ts)
        output_dir = SESSION_FIGURE_DIR

    out_path = Path(output_dir)
    out_path.mkdir(parents=True, exist_ok=True)

    # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å¯¾å¿œï¼ˆè§£æç¨®åˆ¥ã”ã¨ã«å›³ã‚’æ•´ç†ï¼‰
    safe_sub = re.sub(r'[^\w]', '_', subfolder).strip('_') if subfolder else ""
    figures_dir = (out_path / "figures" / safe_sub) if safe_sub else (out_path / "figures")
    figures_dir.mkdir(parents=True, exist_ok=True)

    # ãƒ—ãƒªã‚¢ãƒ³ãƒ–ãƒ«: PLOT_CONFIG å¤‰æ•° + å…±é€šã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è‡ªå‹•æ³¨å…¥
    preamble = f"""import sys, os, warnings
warnings.filterwarnings('ignore')

# --- seq2pipe ãƒ“ãƒ«ãƒˆã‚¤ãƒ³å¤‰æ•° ---
FIGURE_DIR = {repr(str(figures_dir))}
OUTPUT_DIR = {repr(str(out_path))}
PLOT_STYLE = {repr(PLOT_CONFIG['style'])}
PLOT_PALETTE = {repr(PLOT_CONFIG['palette'])}
PLOT_FIGSIZE = tuple({PLOT_CONFIG['figsize']})
PLOT_DPI = {PLOT_CONFIG['dpi']}
FONT_SIZE = {PLOT_CONFIG['font_size']}
TITLE_FONT_SIZE = {PLOT_CONFIG['title_font_size']}
FIGURE_FORMAT = {repr(PLOT_CONFIG.get('format', 'pdf'))}

# --- å…±é€šã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
try:
    import numpy as np
    import pandas as pd
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    try:
        plt.style.use(PLOT_STYLE)
    except Exception:
        pass
    import seaborn as sns
    sns.set_palette(PLOT_PALETTE)
    matplotlib.rcParams['font.size'] = FONT_SIZE
    matplotlib.rcParams['axes.titlesize'] = TITLE_FONT_SIZE
    matplotlib.rcParams['figure.dpi'] = PLOT_DPI
except ImportError as _e:
    print(f"[WARNING] ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¸è¶³: {{_e}}")
    print("pip install numpy pandas matplotlib seaborn ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ¼ãƒ‰ ---
"""

    full_code = preamble + "\n" + code

    with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False,
                                     encoding='utf-8') as f:
        f.write(full_code)
        tmp_path = f.name

    try:
        # å®Ÿè¡Œå‰ã®å›³ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
        existing_figs = set(figures_dir.glob("*.png")) | \
                        set(figures_dir.glob("*.pdf")) | \
                        set(figures_dir.glob("*.svg"))

        proc = subprocess.run(
            [sys.executable, tmp_path],
            capture_output=True, text=True,
            timeout=300,
            cwd=str(out_path)
        )

        stdout = proc.stdout.strip()
        stderr = proc.stderr.strip()

        # æ–°è¦ç”Ÿæˆã•ã‚ŒãŸå›³ã‚’æ¤œå‡º
        new_figs = (set(figures_dir.glob("*.png")) |
                    set(figures_dir.glob("*.pdf")) |
                    set(figures_dir.glob("*.svg"))) - existing_figs
        new_figs = sorted(new_figs)

        # ANALYSIS_LOG ã«è¨˜éŒ²
        ANALYSIS_LOG.append({
            "step": len(ANALYSIS_LOG) + 1,
            "description": description,
            "subfolder": safe_sub,
            "figures": [str(f) for f in new_figs],
            "output_summary": stdout[:600] if stdout else "",
            "returncode": proc.returncode,
            "timestamp": datetime.datetime.now().isoformat(),
        })

        # çµæœãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        parts = []
        if proc.returncode == 0:
            parts.append(f"âœ… è§£æå®Œäº†: {description}")
        else:
            parts.append(f"âš ï¸  è§£æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {description}")
        if stdout:
            parts.append(f"\nğŸ“„ å‡ºåŠ›:\n{stdout[:2000]}")
        if stderr and proc.returncode != 0:
            parts.append(f"\n[STDERR]\n{stderr[:500]}")
        if new_figs:
            parts.append(f"\nğŸ“Š ç”Ÿæˆã•ã‚ŒãŸå›³ ({len(new_figs)} ä»¶):")
            for fig in new_figs:
                parts.append(f"   {fig}")
        else:
            parts.append("\nï¼ˆå›³ã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚savefig ã‚’å‘¼ã‚“ã§ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰")

        return "\n".join(parts)

    except subprocess.TimeoutExpired:
        return "â±ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆ5åˆ†ã‚’è¶…ãˆã¾ã—ãŸï¼‰"
    except Exception as e:
        return f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"
    finally:
        Path(tmp_path).unlink(missing_ok=True)


# ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ â†’ ã‚»ã‚¯ã‚·ãƒ§ãƒ³å ãƒãƒƒãƒ”ãƒ³ã‚°
_SECTION_JA = {
    "alpha_diversity":        "Î±å¤šæ§˜æ€§è§£æ",
    "beta_diversity":         "Î²å¤šæ§˜æ€§è§£æ",
    "taxonomy":               "åˆ†é¡çµ„æˆè§£æ",
    "differential_abundance": "å·®æ¬¡å­˜åœ¨é‡è§£æ",
    "machine_learning":       "æ©Ÿæ¢°å­¦ç¿’åˆ¤åˆ¥è§£æ",
}
_SECTION_EN = {
    "alpha_diversity":        "Alpha Diversity Analysis",
    "beta_diversity":         "Beta Diversity Analysis",
    "taxonomy":               "Taxonomic Composition Analysis",
    "differential_abundance": "Differential Abundance Analysis",
    "machine_learning":       "Machine Learning Classification",
}
_SUBFOLDER_ORDER = [
    "alpha_diversity", "beta_diversity", "taxonomy",
    "differential_abundance", "machine_learning", "",
]


def _tex_escape(s: str) -> str:
    """TeX ç‰¹æ®Šæ–‡å­—ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ï¼ˆé †åºä¾å­˜ã«æ³¨æ„ï¼‰

    å‡¦ç†é †åºã®åŸå‰‡:
    1. \\ ã‚’ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«é€€é¿ï¼ˆå¾Œç¶šãƒ«ãƒ¼ãƒ—ã§ {} ãŒå†ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã‚‹ã®ã‚’é˜²ãï¼‰
    2. { } ã‚’ ^ ~ ã‚ˆã‚Šå…ˆã«å‡¦ç†ï¼ˆ^ â†’ \\^{} ã® {} ãŒå†ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã•ã‚Œã‚‹ãƒã‚°ã‚’é˜²ãï¼‰
    3. ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ \\textbackslash{} ã«ç½®æ›ï¼ˆã‚¹ãƒ†ãƒƒãƒ—2 ã® {} ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚’å—ã‘ãªã„ï¼‰
    """
    _BS = "\x00BACKSLASH\x00"
    s = s.replace("\\", _BS)
    for ch, rep in [("&", r"\&"), ("%", r"\%"), ("#", r"\#"),
                    ("_", r"\_"), ("{", r"\{"), ("}", r"\}"),
                    ("$", r"\$"), ("^", r"\^{}"), ("~", r"\~{}")]:
        s = s.replace(ch, rep)
    s = s.replace(_BS, r"\textbackslash{}")
    return s


def _build_tex_content(lang_code: str, title_ja: str, title_en: str,
                        experiment_summary: str,
                        report_dir: Optional[Path] = None) -> str:
    """ANALYSIS_LOG ã‹ã‚‰ TeX ã‚½ãƒ¼ã‚¹ã‚’çµ„ã¿ç«‹ã¦ã‚‹"""
    from collections import defaultdict

    is_ja = (lang_code == "ja")
    title = title_ja if is_ja else title_en
    section_map = _SECTION_JA if is_ja else _SECTION_EN

    groups: dict = defaultdict(list)
    for entry in ANALYSIS_LOG:
        groups[entry.get("subfolder", "")].append(entry)

    total_figs = sum(len(e.get("figures", [])) for e in ANALYSIS_LOG)

    L = []  # lines

    # â”€â”€ ãƒ—ãƒªã‚¢ãƒ³ãƒ–ãƒ« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if is_ja:
        L += [
            r"\documentclass[a4paper,12pt]{article}",
            r"\usepackage{xeCJK}",
            r"\setCJKmainfont{Hiragino Mincho ProN}",
        ]
    else:
        L += [r"\documentclass[a4paper,12pt]{article}"]

    L += [
        r"\usepackage{graphicx}",
        r"\usepackage{booktabs}",
        r"\usepackage{longtable}",
        r"\usepackage{geometry}",
        r"\usepackage[hidelinks]{hyperref}",
        r"\geometry{margin=2.5cm}",
        f"\\title{{{_tex_escape(title)}}}",
        r"\author{seq2pipe}",
        r"\date{\today}",
        r"\begin{document}",
        r"\maketitle",
        r"\tableofcontents",
        r"\newpage",
    ]

    # â”€â”€ æ¦‚è¦ã‚»ã‚¯ã‚·ãƒ§ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if is_ja:
        L += [
            r"\section{è§£ææ¦‚è¦}",
            r"æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯ seq2pipe ã®è‡ªå¾‹æ¢ç´¢ãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦å®Ÿè¡Œã•ã‚ŒãŸè§£æã®è¨˜éŒ²ã§ã™ã€‚",
            r"LLM ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå®Ÿé¨“ç³»ã®æƒ…å ±ã‚’ã‚‚ã¨ã«è¤‡æ•°ã®è§£ææ‰‹æ³•ã‚’è‡ªå‹•ã§é¸æŠãƒ»å®Ÿè¡Œã—ã€",
            r"çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’è©•ä¾¡ã—ãªãŒã‚‰çµæœã‚’æ•´ç†ã—ã¾ã—ãŸã€‚",
            r"\vspace{1em}",
            r"\begin{tabular}{ll}",
            r"\toprule",
            f"ç·è§£æã‚¹ãƒ†ãƒƒãƒ—æ•° & {len(ANALYSIS_LOG)} \\\\",
            f"ç”Ÿæˆã•ã‚ŒãŸå›³ & {total_figs} ä»¶ \\\\",
            r"\bottomrule",
            r"\end{tabular}",
        ]
        if experiment_summary:
            L += [r"\vspace{1em}", r"\subsection{å®Ÿé¨“ç³»}", _tex_escape(experiment_summary)]
    else:
        L += [
            r"\section{Overview}",
            r"This report documents the analyses performed by seq2pipe's autonomous exploration mode.",
            r"The LLM agent automatically selected and executed multiple analysis methods",
            r"based on the experimental context, evaluating statistical significance at each step.",
            r"\vspace{1em}",
            r"\begin{tabular}{ll}",
            r"\toprule",
            f"Total analysis steps & {len(ANALYSIS_LOG)} \\\\",
            f"Figures generated & {total_figs} \\\\",
            r"\bottomrule",
            r"\end{tabular}",
        ]
        if experiment_summary:
            L += [r"\vspace{1em}", r"\subsection{Experimental Setup}",
                  _tex_escape(experiment_summary)]

    # â”€â”€ è§£æãƒ•ã‚§ãƒ¼ã‚ºã”ã¨ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for sf in _SUBFOLDER_ORDER:
        if sf not in groups:
            continue
        entries = groups[sf]
        sec_name = section_map.get(sf, (_tex_escape(sf) if sf else
                                        ("ãã®ä»–ã®è§£æ" if is_ja else "Other Analyses")))
        L.append(f"\n\\section{{{sec_name}}}")

        for entry in entries:
            desc = _tex_escape(entry.get("description", ""))
            figs = entry.get("figures", [])
            out_summary = entry.get("output_summary", "")
            ok = entry.get("returncode", 0) == 0

            L.append(f"\n\\subsection{{{desc}}}")

            # çµ±è¨ˆå‡ºåŠ›ã®æŠœç²‹
            stat_lines = [line for line in out_summary.split("\n")
                          if any(kw in line.lower() for kw in
                                 ["p =", "p=", "p-value", "pvalue", "accuracy",
                                  "auc", "significant", "æœ‰æ„", "statistic",
                                  "f1", "precision", "recall", "r2", "rmse"])]
            if stat_lines:
                L += [r"\begin{verbatim}"] + stat_lines[:12] + [r"\end{verbatim}"]
            elif not ok:
                L.append(r"\textit{(ã“ã®è§£æã¯ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šå®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸ)}"
                         if is_ja else
                         r"\textit{(This analysis did not complete due to an error)}")

            # å›³ã®æŒ¿å…¥
            for fig_path in figs:
                caption = desc
                # report_dir ã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’ä½¿ç”¨ï¼ˆtectonic ã®ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹å¯¾ç­–ï¼‰
                if report_dir is not None:
                    try:
                        fig_include = os.path.relpath(fig_path, report_dir).replace("\\", "/")
                    except ValueError:
                        fig_include = fig_path  # Windowsãƒ‰ãƒ©ã‚¤ãƒ–è·¨ãç­‰ã§å¤±æ•—ã—ãŸå ´åˆã¯çµ¶å¯¾ãƒ‘ã‚¹
                else:
                    fig_include = fig_path
                L += [
                    r"\begin{figure}[htbp]",
                    r"\centering",
                    f"\\includegraphics[width=0.85\\textwidth]{{{fig_include}}}",
                    f"\\caption{{{caption}}}",
                    r"\end{figure}",
                ]

    # â”€â”€ è§£æãƒ­ã‚°è¡¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    log_title = "è§£æãƒ­ã‚°" if is_ja else "Analysis Log"
    L += [
        f"\n\\section{{{log_title}}}",
        r"\begin{longtable}{r p{7cm} r r}",
        r"\toprule",
    ]
    if is_ja:
        L.append(r"Step & è§£æ & å›³æ•° & çŠ¶æ…‹ \\ \midrule \endhead")
    else:
        L.append(r"Step & Analysis & Figs & Status \\ \midrule \endhead")

    for entry in ANALYSIS_LOG:
        step = entry.get("step", "")
        desc = _tex_escape(entry.get("description", ""))
        n_figs = len(entry.get("figures", []))
        # âœ“/âœ— ã§ã¯ãªã ASCII æ–‡å­—ã‚’ä½¿ã†ï¼ˆãƒ•ã‚©ãƒ³ãƒˆä¾å­˜ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
        ok = r"\textbf{OK}" if entry.get("returncode", 0) == 0 else r"\textbf{NG}"
        L.append(f"{step} & {desc} & {n_figs} & {ok} \\\\")

    L += [r"\bottomrule", r"\end{longtable}", r"\end{document}"]

    return "\n".join(L)


def tool_build_report_tex(title_ja: str, title_en: str,
                            experiment_summary: str = "",
                            lang: str = "both") -> str:
    """ANALYSIS_LOG ã‹ã‚‰ TeX ã‚’è‡ªå‹•ç”Ÿæˆã—ã¦ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã™ã‚‹"""
    if not ANALYSIS_LOG:
        return "âŒ ANALYSIS_LOG ãŒç©ºã§ã™ã€‚å…ˆã« execute_python ã§è§£æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"

    # å‡ºåŠ›å…ˆ
    if SESSION_FIGURE_DIR:
        report_dir = Path(SESSION_FIGURE_DIR) / "report"
    else:
        report_dir = Path.home() / "seq2pipe_results" / "report"
    report_dir.mkdir(parents=True, exist_ok=True)

    tectonic_bin = shutil.which("tectonic")
    results = []

    tasks = []
    if lang in ("ja", "both"):
        tasks.append(("report_ja.tex", "ja", "æ—¥æœ¬èª"))
    if lang in ("en", "both"):
        tasks.append(("report_en.tex", "en", "è‹±èª"))

    for filename, lc, label in tasks:
        tex_content = _build_tex_content(lc, title_ja, title_en, experiment_summary, report_dir)
        tex_path = report_dir / filename
        with open(tex_path, "w", encoding="utf-8") as f:
            f.write(tex_content)
        results.append(f"âœ… {label} TeX ã‚’ç”Ÿæˆ: {tex_path}")

        if tectonic_bin:
            try:
                proc = subprocess.run(
                    [tectonic_bin, str(tex_path)],
                    capture_output=True, text=True,
                    timeout=120, cwd=str(report_dir)
                )
                pdf_path = tex_path.with_suffix(".pdf")
                if proc.returncode == 0 and pdf_path.exists():
                    results.append(f"âœ… {label} PDF ã‚’ç”Ÿæˆ: {pdf_path}")
                else:
                    results.append(f"âš ï¸  {label} PDF ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«å¤±æ•—")
                    if proc.stderr:
                        results.append(f"   {proc.stderr[:300]}")
            except subprocess.TimeoutExpired:
                results.append(f"â±ï¸  {label} ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            except Exception as e:
                results.append(f"âŒ {label} ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            results.append("âš ï¸  tectonic ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚brew install tectonic ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")

    results.append(f"\nğŸ“ å‡ºåŠ›å…ˆ: {report_dir}")
    results.append(f"ğŸ“Š è¨˜éŒ²ã•ã‚ŒãŸè§£æã‚¹ãƒ†ãƒƒãƒ—: {len(ANALYSIS_LOG)}")
    results.append(f"ğŸ–¼ï¸  ç·å›³æ•°: {sum(len(e.get('figures', [])) for e in ANALYSIS_LOG)}")
    return "\n".join(results)


def tool_compile_report(content_ja: str, content_en: str, output_dir: str = "") -> str:
    """TeX ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¦ PDF ã‚’ç”Ÿæˆã™ã‚‹"""
    if not output_dir:
        if SESSION_FIGURE_DIR:
            output_dir = str(Path(SESSION_FIGURE_DIR) / "report")
        else:
            output_dir = str(Path.home() / "seq2pipe_results" / "report")

    out_path = Path(output_dir)
    out_path.mkdir(parents=True, exist_ok=True)

    results = []
    tectonic = shutil.which("tectonic")

    tasks = []
    if content_ja and content_ja.strip():
        tasks.append(("report_ja.tex", content_ja, "æ—¥æœ¬èª"))
    if content_en and content_en.strip():
        tasks.append(("report_en.tex", content_en, "è‹±èª"))

    if not tasks:
        return "âŒ content_ja ã¨ content_en ã®ä¸¡æ–¹ãŒç©ºã§ã™ã€‚"

    for filename, content, label in tasks:
        tex_path = out_path / filename
        with open(tex_path, 'w', encoding='utf-8') as f:
            f.write(content)
        results.append(f"âœ… {label} TeX ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ: {tex_path}")

        if tectonic:
            try:
                proc = subprocess.run(
                    [tectonic, str(tex_path)],
                    capture_output=True, text=True,
                    timeout=120, cwd=str(out_path)
                )
                pdf_path = tex_path.with_suffix('.pdf')
                if proc.returncode == 0 and pdf_path.exists():
                    results.append(f"âœ… {label} PDF ç”Ÿæˆå®Œäº†: {pdf_path}")
                else:
                    results.append(f"âš ï¸  {label} PDF ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã«å•é¡Œ:")
                    if proc.stderr:
                        results.append(f"   {proc.stderr[:400]}")
            except subprocess.TimeoutExpired:
                results.append(f"â±ï¸  {label} ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            except Exception as e:
                results.append(f"âŒ {label} ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            results.append(f"âš ï¸  tectonic ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚brew install tectonic ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€æ‰‹å‹•ã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¦ãã ã•ã„ã€‚")

    return "\n".join(results)


def dispatch_tool(name: str, args: dict) -> str:
    """ãƒ„ãƒ¼ãƒ«åã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ãƒ„ãƒ¼ãƒ«é–¢æ•°ã‚’å‘¼ã³å‡ºã™"""
    try:
        if name == "inspect_directory":
            return tool_inspect_directory(**args)
        elif name == "read_file":
            return tool_read_file(**args)
        elif name == "check_system":
            return tool_check_system()
        elif name == "write_file":
            return tool_write_file(**args)
        elif name == "generate_manifest":
            return tool_generate_manifest(**args)
        elif name == "edit_file":
            return tool_edit_file(**args)
        elif name == "run_command":
            return tool_run_command(**args)
        elif name == "set_plot_config":
            return tool_set_plot_config(**args)
        elif name == "execute_python":
            return tool_execute_python(**args)
        elif name == "compile_report":
            return tool_compile_report(**args)
        elif name == "build_report_tex":
            return tool_build_report_tex(**args)
        else:
            return f"âŒ ä¸æ˜ãªãƒ„ãƒ¼ãƒ«: {name}"
    except TypeError as e:
        return f"âŒ ãƒ„ãƒ¼ãƒ«å¼•æ•°ã‚¨ãƒ©ãƒ¼ ({name}): {e}"
    except Exception as e:
        return f"âŒ ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ ({name}): {e}"


# ======================================================================
# Ollama API
# ======================================================================

def call_ollama(messages: list, model: str, tools: list = None) -> dict:
    """Ollama /api/chat ã‚’å‘¼ã³å‡ºã™ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æœ‰åŠ¹ï¼‰"""
    body = {
        "model": model,
        "messages": messages,
        "stream": True,
    }
    if tools:
        body["tools"] = tools
        body["temperature"] = 0.3  # ãƒ„ãƒ¼ãƒ«å¼•æ•°JSONç”Ÿæˆã®å®‰å®šæ€§å‘ä¸Š

    data = json.dumps(body).encode("utf-8")
    req = urllib.request.Request(
        OLLAMA_URL,
        data=data,
        headers={"Content-Type": "application/json"},
        method="POST"
    )

    full_content = ""
    tool_calls = []
    thinking_content = ""

    try:
        with urllib.request.urlopen(req, timeout=300) as resp:
            for raw_line in resp:
                line = raw_line.decode("utf-8").strip()
                if not line:
                    continue
                try:
                    chunk = json.loads(line)
                except json.JSONDecodeError:
                    continue

                msg = chunk.get("message", {})
                content = msg.get("content", "")

                # thinkingï¼ˆæ¨è«–ãƒ–ãƒ­ãƒƒã‚¯ã€qwen3ç­‰ï¼‰
                if msg.get("thinking"):
                    thinking_content += msg["thinking"]
                    continue

                # tool_calls ãŒå«ã¾ã‚Œã‚‹å ´åˆ
                if msg.get("tool_calls"):
                    tool_calls.extend(msg["tool_calls"])

                # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
                if content:
                    print(content, end="", flush=True)
                    full_content += content

                if chunk.get("done"):
                    break

        if full_content:
            print()  # æ”¹è¡Œ

        return {
            "content": full_content,
            "tool_calls": tool_calls,
            "thinking": thinking_content
        }

    except urllib.error.HTTPError as e:
        raise ConnectionError(
            f"Ollama HTTP ã‚¨ãƒ©ãƒ¼: {e.code} {e.reason}\n"
            f"è©³ç´°: {e}"
        )
    except urllib.error.URLError as e:
        raise ConnectionError(
            f"Ollama ã«æ¥ç¶šã§ãã¾ã›ã‚“ï¼ˆ{OLLAMA_URL}ï¼‰ã€‚\n"
            f"'ollama serve' ã‚’åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\nè©³ç´°: {e}"
        )
    except TimeoutError as e:
        raise ConnectionError(
            f"Ollama ã¸ã®æ¥ç¶šãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆtimeout=300sï¼‰ã€‚\nè©³ç´°: {e}"
        )


def check_python_deps() -> bool:
    """numpy/pandas/matplotlib/seaborn ãŒ sys.executable ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã‚‹ã‹ç¢ºèª"""
    check_code = "import numpy, pandas, matplotlib, seaborn"
    try:
        proc = subprocess.run(
            [sys.executable, "-c", check_code],
            capture_output=True, text=True, timeout=10
        )
        if proc.returncode == 0:
            print(f"   {c(ui('deps_ok'), GREEN)}")
            return True
        else:
            # ImportError ã®å ´åˆ stderr ã‹ã‚‰ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã‚’æŠ½å‡º
            missing = proc.stderr.strip().split("\n")[-1] if proc.stderr else "ä¸æ˜"
            print(f"   {c(ui('deps_warn', missing), YELLOW)}")
            print(f"   {ui('deps_hint')}")
            install_cmd = f"{sys.executable} -m pip install numpy pandas matplotlib seaborn"
            print(f"   {ui('deps_hint2', c(install_cmd, CYAN))}")
            return False
    except Exception:
        return False


def check_ollama_running() -> bool:
    """Ollama ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª"""
    try:
        urllib.request.urlopen("http://localhost:11434/api/tags", timeout=3)
        return True
    except Exception:
        return False


def get_available_models() -> list:
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    try:
        with urllib.request.urlopen("http://localhost:11434/api/tags", timeout=5) as resp:
            data = json.loads(resp.read())
            return [m["name"] for m in data.get("models", [])]
    except Exception:
        return []


# ======================================================================
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—
# ======================================================================

def run_agent_loop(messages: list, model: str, max_steps: int = 30):
    """ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å«ã‚€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œ"""
    steps = 0
    while True:
        if steps >= max_steps:
            print(f"\n{c(ui('agent_limit', max_steps), YELLOW)}")
            break
        steps += 1

        print(f"\n{c('ğŸ¤– AI', CYAN + BOLD)}: ", end="", flush=True)

        response = call_ollama(messages, model, tools=TOOLS)
        assistant_msg = {"role": "assistant", "content": response["content"]}

        # tool_calls ãŒã‚ã‚Œã°å®Ÿè¡Œ
        if response["tool_calls"]:
            tool_results = []
            for tc in response["tool_calls"]:
                fn = tc.get("function", {})
                tool_name = fn.get("name", "")
                tool_args = fn.get("arguments", {})
                if isinstance(tool_args, str):
                    try:
                        tool_args = json.loads(tool_args)
                    except json.JSONDecodeError:
                        tool_args = {}

                print(f"\n{c(ui('tool_exec', tool_name), MAGENTA)}")
                print(f"{c(json.dumps(tool_args, ensure_ascii=False, indent=2), DIM)}")

                result = dispatch_tool(tool_name, tool_args)

                print(f"\n{c(ui('tool_result'), GREEN)}")
                print(result)

                tool_results.append({
                    "role": "tool",
                    "content": result
                })

            # tool_calls ã‚’ assistant ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä¸è¦ â€” å¤–å´ã® if ã§ç¢ºèªæ¸ˆã¿ï¼‰
            assistant_msg["tool_calls"] = response["tool_calls"]

            messages.append(assistant_msg)
            messages.extend(tool_results)

            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå¾Œã€ç¶šã‘ã¦ AI ã«å¿œç­”ã•ã›ã‚‹
            continue
        else:
            # ãƒ„ãƒ¼ãƒ«ãªã— â†’ é€šå¸¸ã®å¿œç­”ã§çµ‚äº†
            messages.append(assistant_msg)
            break


# ======================================================================
# ãƒãƒŠãƒ¼ãƒ»UI
# ======================================================================

# ãƒãƒŠãƒ¼æ–‡å­—åˆ—ï¼ˆ"2" ã‚’æ­£ã—ã„ã‚·ãƒ³ã‚°ãƒ«æ–œã‚ã§ä¿®æ­£æ¸ˆã¿ï¼‰
BANNER_LINES = [
    " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—",
    " â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â•šâ•â•â•â•â–ˆâ–ˆâ•—",
    " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•”â•â•",
    " â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â–„â–„ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•",
    " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—",
    " â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â–€â–€â•â• â•šâ•â•â•â•â•â•",
    " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—",
    " â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•",
    " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—",
    " â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•”â•â•â•",
    " â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—",
    " â•šâ•â•     â•šâ•â•â•šâ•â•     â•šâ•â•â•â•â•â•â•",
    "      sequence -> pipeline",
]

# ã‚·ã‚¢ãƒ³ç³»ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆ256è‰²ï¼‰
_GRAD = [
    "\033[38;5;23m",   # dark teal
    "\033[38;5;30m",
    "\033[38;5;37m",
    "\033[38;5;44m",
    "\033[38;5;51m",   # bright cyan
    "\033[1;36m",      # bold cyan
    "\033[38;5;87m",
    "\033[38;5;123m",  # pale cyan
    "\033[38;5;87m",
    "\033[1;36m",
    "\033[38;5;51m",
    "\033[38;5;44m",
    "\033[38;5;37m",
]


def print_banner():
    """ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‹ã‚¹ãƒ‘ãƒ¼ã‚¯ãƒ«ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã§ãƒãƒŠãƒ¼ã‚’è¡¨ç¤º"""
    import time
    import random

    n = len(BANNER_LINES)
    is_tty = sys.stdout.isatty()

    if not is_tty:
        for line in BANNER_LINES:
            print(f"{CYAN}{BOLD}{line}{RESET}")
        return

    try:
        # Phase 1: æš—ã„ã‚·ã‚¢ãƒ³ã§ä¸€ç¬è¡¨ç¤º
        for line in BANNER_LINES:
            sys.stdout.write(f"\033[38;5;23m{line}\033[0m\n")
        sys.stdout.flush()
        time.sleep(0.04)

        # Phase 2: ã‚«ãƒ¼ã‚½ãƒ«ã‚’å…ˆé ­ã¸æˆ»ã™
        sys.stdout.write(f"\033[{n}A\r")
        sys.stdout.flush()

        # Phase 3: ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚«ãƒ©ãƒ¼ã§ä¸‹ã‚¹ã‚¤ãƒ¼ãƒ—
        for i, line in enumerate(BANNER_LINES):
            color = _GRAD[i % len(_GRAD)]
            sys.stdout.write(f"\033[2K{color}\033[1m{line}\033[0m\n")
            sys.stdout.flush()
            time.sleep(0.03)

        # Phase 4: ã‚¹ãƒ‘ãƒ¼ã‚¯ãƒ«ï¼ˆãƒ©ãƒ³ãƒ€ãƒ è¡ŒãŒç™½ãå…‰ã‚‹ Ã— 3æ³¢ï¼‰
        for _ in range(3):
            sparks = set(random.sample(range(n), k=min(4, n)))
            sys.stdout.write(f"\033[{n}A\r")
            for i, line in enumerate(BANNER_LINES):
                color = "\033[1;97m" if i in sparks else _GRAD[i % len(_GRAD)]
                sys.stdout.write(f"\033[2K{color}\033[1m{line}\033[0m\n")
            sys.stdout.flush()
            time.sleep(0.09)

        # Phase 5: ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«è½ã¡ç€ã
        sys.stdout.write(f"\033[{n}A\r")
        for i, line in enumerate(BANNER_LINES):
            color = _GRAD[i % len(_GRAD)]
            sys.stdout.write(f"\033[2K{color}\033[1m{line}\033[0m\n")
        sys.stdout.flush()
        print()

    except Exception:
        # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—æ™‚ã¯é™çš„è¡¨ç¤ºã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        for line in BANNER_LINES:
            print(f"{CYAN}{BOLD}{line}{RESET}")

INITIAL_MESSAGE = """ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯ QIIME2 + Python ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ è§£æã‚’æ”¯æ´ã™ã‚‹ãƒ­ãƒ¼ã‚«ãƒ« AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

å¯¾å¿œã—ã¦ã„ã‚‹è§£æ:
  [QIIME2] ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â†’ DADA2 ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚° â†’ åˆ†é¡ â†’ å¤šæ§˜æ€§è§£æ â†’ å·®æ¬¡è§£æ
  [Python] çµ„æˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— / PCoA å›³ / ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆåˆ¤åˆ¥ / ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è§£æ
  [ãƒ¬ãƒãƒ¼ãƒˆ] è§£æçµ‚äº†å¾Œã« TeX / PDF ãƒ¬ãƒãƒ¼ãƒˆã‚’æ—¥æœ¬èªãƒ»è‹±èªã§è‡ªå‹•ç”Ÿæˆ

å§‹ã‚ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã‚’æ•™ãˆã¦ãã ã•ã„:

  1. ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
     ä¾‹: /Users/yourname/microbiome-data/

  2. å®Ÿé¨“ç³»ã®èª¬æ˜
     ä¾‹: ãƒ’ãƒˆè…¸å†…ç´°èŒã€16S V3-V4 é ˜åŸŸï¼ˆ341F/806Rï¼‰ã€Illumina MiSeq ãƒšã‚¢ã‚¨ãƒ³ãƒ‰ 2Ã—250bp
         ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« 5 ã‚µãƒ³ãƒ—ãƒ« vs å‡¦ç†ç¾¤ 5 ã‚µãƒ³ãƒ—ãƒ«

  3. è¡Œã„ãŸã„è§£æ
     ä¾‹: åˆ†é¡çµ„æˆã®å¯è¦–åŒ– / Î±ãƒ»Î² å¤šæ§˜æ€§è§£æ / ã‚°ãƒ«ãƒ¼ãƒ—é–“ã®å·®æ¬¡è§£æ / æ©Ÿæ¢°å­¦ç¿’åˆ¤åˆ¥

  4. å›³ã®ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆçœç•¥å¯ï¼‰
     ä¾‹: ç™½èƒŒæ™¯ãƒ»è‰²ã¯é’ç³» / ãƒ€ãƒ¼ã‚¯ç³» / è«–æ–‡å‘ã‘é«˜è§£åƒåº¦ï¼ˆ300 DPIï¼‰

ä¸€åº¦ã«ã¾ã¨ã‚ã¦æ•™ãˆã¦ã‚‚ã‚‰ã†ã¨ã€ã‚ˆã‚Šçš„ç¢ºãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã§ãã¾ã™ã€‚
"""

INITIAL_MESSAGE_EN = """Hello! I am a local AI agent specialized in QIIME2 + Python downstream microbiome analysis.

Supported analyses:
  [QIIME2] Import â†’ DADA2 denoising â†’ Taxonomy classification â†’ Diversity analysis â†’ Differential analysis
  [Python] Composition heatmap / PCoA plot / Random forest classification / Network analysis
  [Report] Auto-generate TeX / PDF reports in Japanese or English after analysis

To get started, please provide:

  1. Path to your data directory
     e.g. /Users/yourname/microbiome-data/

  2. Description of your experiment
     e.g. Human gut microbiome, 16S V3-V4 (341F/806R), Illumina MiSeq paired-end 2Ã—250bp
          5 control samples vs 5 treatment samples

  3. Analyses you want to perform
     e.g. Taxonomy composition visualization / Alpha & beta diversity / Differential analysis / ML classification

  4. Figure style (optional)
     e.g. White background, blue palette / Dark theme / High-resolution for publication (300 DPI)

Providing all information at once helps generate a more accurate pipeline.
"""


def select_language() -> str:
    """èµ·å‹•æ™‚ã«æ“ä½œè¨€èªã‚’é¸æŠã™ã‚‹ï¼ˆJA / ENï¼‰ã€‚é¸æŠçµæœã‚’è¿”ã— LANG ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚’æ›´æ–°ã™ã‚‹ã€‚"""
    global LANG
    print(f"\n{CYAN}{BOLD}  Select language / è¨€èªã‚’é¸æŠã—ã¦ãã ã•ã„{RESET}")
    print(f"  {BOLD}[1]{RESET} æ—¥æœ¬èª (Japanese)")
    print(f"  {BOLD}[2]{RESET} English")
    while True:
        try:
            choice = input(f"\n  {BOLD}>{RESET} ").strip()
        except (EOFError, KeyboardInterrupt):
            print(f"\n\n{c(ui('goodbye'), CYAN)}")
            sys.exit(0)
        if choice in ("1", "ja", "JA", "japanese", "Japanese"):
            LANG = "ja"
            break
        elif choice in ("2", "en", "EN", "english", "English"):
            LANG = "en"
            break
        else:
            print(f"  {YELLOW}Please enter 1 or 2 / 1 ã‹ 2 ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„{RESET}")
    print()
    return LANG


def select_model(available_models: list) -> str:
    """ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"""
    # ç’°å¢ƒå¤‰æ•° QIIME2_AI_MODEL ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æœ€å„ªå…ˆ
    if DEFAULT_MODEL in available_models:
        return DEFAULT_MODEL

    preferred = ["qwen2.5-coder:7b", "qwen2.5-coder:3b", "qwen3:8b",
                 "llama3.2:3b", "llama3.1:8b", "mistral:7b", "codellama:7b"]

    for p in preferred:
        if p in available_models:
            return p
        # ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä¸€è‡´
        for m in available_models:
            if m.startswith(p.split(":")[0]):
                return m

    if available_models:
        return available_models[0]
    return DEFAULT_MODEL


# ======================================================================
# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# ======================================================================

def main():
    # Windows 10+ ã§ ANSI ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚³ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–
    if sys.platform == "win32":
        os.system("")

    print_banner()

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆåŒä¸€ãƒ—ãƒ­ã‚»ã‚¹ã§è¤‡æ•°å›å‘¼ã°ã‚ŒãŸå ´åˆã®æ··å…¥é˜²æ­¢ï¼‰
    global ANALYSIS_LOG, SESSION_FIGURE_DIR
    ANALYSIS_LOG = []
    SESSION_FIGURE_DIR = ""

    # è¨€èªé¸æŠ
    select_language()

    # Python ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèªï¼ˆå¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œã€è­¦å‘Šã®ã¿ï¼‰
    check_python_deps()

    # Ollama èµ·å‹•ç¢ºèª
    if not check_ollama_running():
        print(f"{c(ui('ollama_error'), RED)}")
        print(f"   {ui('ollama_hint')}")
        print(f"   {c('ollama serve', CYAN)}")
        print(f"\n   {ui('ollama_hint2')}")
        print(f"   {c('./setup.sh', CYAN)}")
        sys.exit(1)

    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    available = get_available_models()
    if not available:
        print(f"{c(ui('no_model'), YELLOW)}")
        print(f"   {ui('no_model_hint', c('ollama pull qwen2.5-coder:7b', CYAN))}")
        print(f"   {ui('no_model_hint2', c('ollama pull llama3.2:3b', CYAN))}")
        sys.exit(1)

    model = select_model(available)
    print(f"{c(ui('model_selected', model), GREEN)}")
    print(f"{c(ui('hint_exit'), DIM)}\n")

    # è¨€èªã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é¸æŠ
    if LANG == "en":
        # SYSTEM_PROMPT ã®æœ«å°¾ã«è¿½è¨˜ã™ã‚‹ã“ã¨ã§ã€Œæœ€å¾Œã®æŒ‡ç¤ºã€ã¨ã—ã¦æ©Ÿèƒ½ã•ã›ã‚‹
        # ï¼ˆLLM ã¯å¾Œæ–¹ã®æŒ‡ç¤ºã‚’å„ªå…ˆã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ãŸã‚ã€å…ˆé ­è¿½è¨˜ã‚ˆã‚Šç¢ºå®Ÿï¼‰
        lang_suffix = (
            "\n\nâ”â”â” LANGUAGE OVERRIDE (highest priority) â”â”â”\n"
            "The user has selected English as the interface language.\n"
            "You MUST respond in English for ALL subsequent messages.\n"
            "This includes explanations, shell scripts, Python code comments, and reports.\n"
            "Do NOT use Japanese in any output."
        )
        initial_msg = INITIAL_MESSAGE_EN
    else:
        lang_suffix = ""
        initial_msg = INITIAL_MESSAGE

    # ä¼šè©±å±¥æ­´ã‚’åˆæœŸåŒ–
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT + lang_suffix},
        {"role": "assistant", "content": initial_msg}
    ]

    print(f"{c('ğŸ¤– AI', CYAN + BOLD)}: {initial_msg}")

    # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
    while True:
        try:
            user_input = input(f"\n{c(ui('prompt'), BOLD + GREEN)} > ").strip()
        except (EOFError, KeyboardInterrupt):
            print(f"\n\n{c(ui('goodbye'), CYAN)}")
            break

        if not user_input:
            continue

        if user_input.lower() in ["quit", "exit", "çµ‚äº†", "q"]:
            print(f"\n{c(ui('goodbye'), CYAN)}")
            break

        messages.append({"role": "user", "content": user_input})

        try:
            run_agent_loop(messages, model)
        except ConnectionError as e:
            print(f"\n{c(str(e), RED)}")
            break
        except Exception as e:
            print(f"\n{c(ui('runtime_error', e), RED)}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()
