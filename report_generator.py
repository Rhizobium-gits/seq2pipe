#!/usr/bin/env python3
"""
report_generator.py
===================
QIIME2 è§£æçµæœã‚’ HTML ãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦å‡ºåŠ›ã™ã‚‹ã€‚

- ç”Ÿæˆã•ã‚ŒãŸå›³ï¼ˆJPG/PNGï¼‰ã‚’ base64 ã§åŸ‹ã‚è¾¼ã¿
- LLM ãŒå„å›³ã®è§£é‡ˆæ–‡ã¨ç·åˆã‚µãƒãƒªãƒ¼ã‚’æ—¥æœ¬èªã§ç”Ÿæˆ
- è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»æ‰‹æ³•ãƒ»å®Œäº†ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¨˜éŒ²
"""

import base64
import datetime
import shutil
import subprocess
from pathlib import Path
from typing import Callable, Optional

import sys
sys.path.insert(0, str(Path(__file__).parent))
import qiime2_agent as _agent


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å›³ãƒ•ã‚¡ã‚¤ãƒ«å â†’ æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_FIG_TITLE_MAP = {
    # analysis.py æ±ºå®šè«–çš„è§£æ (fig01-fig25)
    "fig01": "DADA2 ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°çµ±è¨ˆ",
    "fig02": "ã‚µãƒ³ãƒ—ãƒ«åˆ¥ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ·±åº¦",
    "fig03": "ã‚¢ãƒ«ãƒ•ã‚¡å¤šæ§˜æ€§ï¼ˆè¤‡æ•°æŒ‡æ¨™ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆï¼‰",
    "fig04": "Shannon å¤šæ§˜æ€§æŒ‡æ•°ï¼ˆã‚µãƒ³ãƒ—ãƒ«åˆ¥ï¼‰",
    "fig05": "PCoAï¼ˆBray-Curtisï¼‰",
    "fig06": "PCoAï¼ˆJaccardï¼‰",
    "fig07": "PCoAï¼ˆUnweighted UniFracï¼‰",
    "fig08": "PCoAï¼ˆWeighted UniFracï¼‰",
    "fig09": "ãƒ™ãƒ¼ã‚¿å¤šæ§˜æ€§è·é›¢è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
    "fig10": "ä¸Šä½ 30 ASV ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
    "fig11": "ã‚¢ãƒ«ãƒ•ã‚¡å¤šæ§˜æ€§æŒ‡æ¨™é–“ç›¸é–¢",
    "fig12": "ASV ãƒªãƒƒãƒãƒã‚¹ vs ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ·±åº¦",
    "fig13": "å±ãƒ¬ãƒ™ãƒ«ç›¸å¯¾å­˜åœ¨é‡ï¼ˆç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ï¼‰",
    "fig14": "é–€ãƒ¬ãƒ™ãƒ«ç›¸å¯¾å­˜åœ¨é‡ï¼ˆç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ï¼‰",
    "fig15": "å±ãƒ¬ãƒ™ãƒ«ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
    "fig16": "ãƒ©ãƒ¬ãƒ•ã‚¡ã‚¯ã‚·ãƒ§ãƒ³ã‚«ãƒ¼ãƒ–",
    "fig17": "NMDSï¼ˆBray-Curtisï¼‰",
    "fig18": "Rank-Abundance ã‚«ãƒ¼ãƒ–",
    "fig19": "åˆ†é¡å­¦çš„ Alluvial ãƒ—ãƒ­ãƒƒãƒˆï¼ˆé–€â†’ç¶±â†’ç›®ï¼‰",
    "fig20": "å±é–“å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯",
    "fig21": "ç§‘ãƒ¬ãƒ™ãƒ«ç›¸å¯¾å­˜åœ¨é‡ï¼ˆç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ï¼‰",
    "fig22": "ã‚³ã‚¢ãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ ï¼ˆå‡ºç¾é »åº¦ vs å­˜åœ¨é‡ï¼‰",
    "fig23": "å·®æ¬¡çš„å­˜åœ¨é‡ãƒœãƒ«ã‚±ãƒ¼ãƒãƒ—ãƒ­ãƒƒãƒˆ",
    "fig24": "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ³ãƒ‰ãƒ­ã‚°ãƒ©ãƒ ï¼ˆUPGMAï¼‰",
    "fig25": "å±é–“ Spearman ç›¸é–¢ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãƒãƒƒãƒ—",
    "fig26": "ç¶±ãƒ¬ãƒ™ãƒ«ç›¸å¯¾å­˜åœ¨é‡ï¼ˆç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ï¼‰",
    "fig27": "ç›®ãƒ¬ãƒ™ãƒ«ç›¸å¯¾å­˜åœ¨é‡ï¼ˆç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ï¼‰",
    "fig28": "Simpson å¤šæ§˜æ€§ + Pielou å‡ç­‰åº¦",
    "fig29": "ã‚µãƒ³ãƒ—ãƒ«é–“ ASV å…±æœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³",
    # 1ã‚·ãƒ§ãƒƒãƒˆç”Ÿæˆã®ä»£è¡¨çš„ãªãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆcode_agent ç”¨ï¼‰
    "genus_stacked_bar": "å±ãƒ¬ãƒ™ãƒ«ç›¸å¯¾å­˜åœ¨é‡ï¼ˆç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ï¼‰",
    "phylum_bar": "é–€ãƒ¬ãƒ™ãƒ«ç›¸å¯¾å­˜åœ¨é‡",
    "shannon": "Shannon Î±å¤šæ§˜æ€§",
    "shannon_boxplot": "Shannon Î±å¤šæ§˜æ€§ï¼ˆç®±ã²ã’å›³ï¼‰",
    "alpha": "Î±å¤šæ§˜æ€§",
    "pcoa": "ä¸»åº§æ¨™åˆ†æ (PCoA)",
    "pcoa_plot": "ä¸»åº§æ¨™åˆ†æ (PCoA)",
    "pca": "ä¸»æˆåˆ†åˆ†æ (PCA)",
    "nmds": "NMDS ã‚ªãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚·ãƒ§ãƒ³",
    "beta": "Î²å¤šæ§˜æ€§",
    "heatmap": "ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
    "rarefaction": "ãƒ©ãƒ¬ãƒ•ã‚¡ã‚¯ã‚·ãƒ§ãƒ³ã‚«ãƒ¼ãƒ–",
    "denoising": "DADA2 ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°çµ±è¨ˆ",
    "read_depth": "ã‚µãƒ³ãƒ—ãƒ«åˆ¥ãƒªãƒ¼ãƒ‰æ·±åº¦",
    "taxonomy": "åˆ†é¡å­¦çš„çµ„æˆ",
    "corr": "ã‚µãƒ³ãƒ—ãƒ«é–“ç›¸é–¢",
    "pie": "åˆ†é¡ç¾¤ãƒ‘ã‚¤ãƒãƒ£ãƒ¼ãƒˆ",
    "volcano": "ãƒœãƒ«ã‚±ãƒ¼ãƒãƒ—ãƒ­ãƒƒãƒˆ",
    "network": "å…±èµ·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯",
    "alluvial": "Alluvial ãƒ—ãƒ­ãƒƒãƒˆ",
    "dendrogram": "ãƒ‡ãƒ³ãƒ‰ãƒ­ã‚°ãƒ©ãƒ ",
    "core": "ã‚³ã‚¢ãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ ",
    "rank_abundance": "Rank-Abundance ã‚«ãƒ¼ãƒ–",
    "family": "ç§‘ãƒ¬ãƒ™ãƒ«çµ„æˆ",
    "adaptive": "é©å¿œå‹è§£æ",
    "simpson": "Simpson å¤šæ§˜æ€§",
    "pielou": "Pielou å‡ç­‰åº¦",
    "overlap": "ASV å…±æœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³",
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è§£æã‚«ãƒ†ã‚´ãƒªãƒ»æ‰‹æ³•æƒ…å ±ï¼ˆHTML ãƒ¬ãƒãƒ¼ãƒˆç”¨ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_ANALYSIS_CATEGORIES = [
    {
        "id": "qc",
        "title": "å“è³ªç®¡ç†ãƒ»ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ·±åº¦",
        "description": (
            "ç”Ÿã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒªãƒ¼ãƒ‰ã‚’ DADA2 ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ã—ã€"
            "ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚¨ãƒ©ãƒ¼ã‚’é™¤å»ã—ã¦æ­£ç¢ºãª ASV (Amplicon Sequence Variant) ã‚’æ¨å®šã™ã‚‹ã€‚"
            "ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ·±åº¦ã¨ãƒ©ãƒ¬ãƒ•ã‚¡ã‚¯ã‚·ãƒ§ãƒ³è§£æã«ã‚ˆã‚Šã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒç¾¤é›†å¤šæ§˜æ€§ã‚’"
            "ååˆ†ã«æ‰ãˆã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã™ã‚‹ã€‚"
        ),
        "figures": ["fig01", "fig02", "fig12", "fig16", "fig18"],
        "methods": [
            {
                "name": "DADA2 Denoising",
                "equation": None,
                "description": (
                    "ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ©ãƒ³ã”ã¨ã®ã‚¨ãƒ©ãƒ¼ç‡ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€"
                    "ãƒã‚¤ã‚ºãƒªãƒ¼ãƒ‰ã‹ã‚‰æ­£ç¢ºãª ASV ã‚’æ¨å®šã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚"
                    "å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ã€ã‚­ãƒ¡ãƒ©é™¤å»ã‚’çµ±åˆçš„ã«è¡Œã†ã€‚"
                ),
                "reveals": (
                    "å„ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°åŠ¹ç‡ï¼ˆå…¥åŠ›ãƒªãƒ¼ãƒ‰æ•° vs å‡ºåŠ› ASV æ•°ï¼‰ã€"
                    "ã‚­ãƒ¡ãƒ©é™¤å»ç‡ã€å…¨ä½“çš„ãªãƒ‡ãƒ¼ã‚¿å“è³ªã‚’è©•ä¾¡ã§ãã‚‹ã€‚"
                ),
            },
            {
                "name": "Rarefaction Analysis",
                "equation": "E[S<sub>n</sub>] = S &minus; &Sigma;<sub>i</sub> C(N &minus; N<sub>i</sub>, n) / C(N, n)",
                "description": (
                    "ãƒªãƒ¼ãƒ‰æ•°ã‚’æ®µéšçš„ã«ã‚µãƒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€å„æ·±åº¦ã§ã®ç¨®æ•°ï¼ˆASV æ•°ï¼‰ã‚’æ¨å®šã™ã‚‹ã€‚"
                    "æ›²ç·šãŒãƒ—ãƒ©ãƒˆãƒ¼ã«é”ã™ã‚Œã°ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯ååˆ†ã¨åˆ¤æ–­ã§ãã‚‹ã€‚"
                ),
                "reveals": (
                    "å„ã‚µãƒ³ãƒ—ãƒ«ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ·±åº¦ãŒç¾¤é›†å¤šæ§˜æ€§ã‚’ååˆ†ã«æ•æ‰ã—ã¦ã„ã‚‹ã‹ã€"
                    "è¿½åŠ ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãŒå¿…è¦ã‹ã‚’åˆ¤æ–­ã§ãã‚‹ã€‚"
                ),
            },
            {
                "name": "Rank-Abundance Curve",
                "equation": None,
                "description": (
                    "ASV ã‚’ç›¸å¯¾å­˜åœ¨é‡ã®é™é †ã«ãƒ©ãƒ³ã‚¯ä»˜ã‘ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã€‚"
                    "æ›²ç·šã®å‚¾ããŒç¾¤é›†ã®å‡ç­‰åº¦ã‚’åæ˜ ã™ã‚‹ã€‚"
                ),
                "reveals": (
                    "ç¾¤é›†ãŒå°‘æ•°ã®å„ªå ç¨®ã«æ”¯é…ã•ã‚Œã¦ã„ã‚‹ã‹ï¼ˆæ€¥å‚¾æ–œï¼‰ã€"
                    "å‡ç­‰ã«åˆ†å¸ƒã—ã¦ã„ã‚‹ã‹ï¼ˆç·©å‚¾æ–œï¼‰ã‚’è¦–è¦šçš„ã«è©•ä¾¡ã§ãã‚‹ã€‚"
                ),
            },
        ],
    },
    {
        "id": "alpha",
        "title": "ã‚¢ãƒ«ãƒ•ã‚¡å¤šæ§˜æ€§",
        "description": (
            "ã‚¢ãƒ«ãƒ•ã‚¡å¤šæ§˜æ€§ã¯å€‹ã€…ã®ã‚µãƒ³ãƒ—ãƒ«å†…ã®å¤šæ§˜æ€§ã‚’å®šé‡åŒ–ã™ã‚‹ã€‚"
            "ç¨®æ•°ï¼ˆãƒªãƒƒãƒãƒã‚¹ï¼‰ã€åˆ†å¸ƒã®å‡ç­‰æ€§ï¼ˆã‚¤ãƒ¼ãƒ–ãƒ³ãƒã‚¹ï¼‰ã€æƒ…å ±é‡ï¼ˆã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰ãªã©ã€"
            "ç›¸è£œçš„ãªè¤‡æ•°ã®æŒ‡æ¨™ã§ç¾¤é›†æ§‹é€ ã®ç•°ãªã‚‹å´é¢ã‚’æ‰ãˆã‚‹ã€‚"
        ),
        "figures": ["fig03", "fig04", "fig11", "fig28"],
        "methods": [
            {
                "name": "Shannon Entropy",
                "equation": "H&prime; = &minus;&Sigma;<sub>i=1</sub><sup>S</sup> p<sub>i</sub> ln(p<sub>i</sub>)",
                "description": (
                    "æƒ…å ±ç†è«–ã«åŸºã¥ãå¤šæ§˜æ€§æŒ‡æ¨™ã€‚ãƒªãƒƒãƒãƒã‚¹ã¨ã‚¤ãƒ¼ãƒ–ãƒ³ãƒã‚¹ã®ä¸¡æ–¹ã‚’è€ƒæ…®ã™ã‚‹ã€‚"
                    "å€¤ãŒå¤§ãã„ã»ã©å¤šæ§˜æ€§ãŒé«˜ã„ã€‚å¸Œå°‘ç¨®ã«æ•æ„Ÿã€‚"
                ),
                "reveals": "ç¾¤é›†å…¨ä½“ã®è¤‡é›‘ã•ã€‚å¸Œå°‘ç¨®ã®å­˜åœ¨ãŒæŒ‡æ¨™å€¤ã«å¤§ããå½±éŸ¿ã™ã‚‹ã€‚",
            },
            {
                "name": "Simpson's Diversity Index",
                "equation": "D = 1 &minus; &Sigma;<sub>i=1</sub><sup>S</sup> p<sub>i</sub><sup>2</sup>",
                "description": (
                    "ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã‚“ã  2 å€‹ä½“ãŒç•°ãªã‚‹ç¨®ã«å±ã™ã‚‹ç¢ºç‡ã€‚"
                    "0ï¼ˆå¤šæ§˜æ€§ãªã—ï¼‰ã‹ã‚‰ 1ï¼ˆç„¡é™å¤šæ§˜æ€§ï¼‰ã®ç¯„å›²ã‚’ã¨ã‚‹ã€‚"
                    "Shannon ã‚ˆã‚Šå„ªå ç¨®ã®å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ã€‚"
                ),
                "reveals": "ç¾¤é›†ã®å„ªå æ§‹é€ ã€‚å„ªå ç¨®ãŒå­˜åœ¨ã™ã‚‹ã¨ãå€¤ãŒä½ä¸‹ã™ã‚‹ã€‚",
            },
            {
                "name": "Pielou's Evenness",
                "equation": "J = H&prime; / ln(S)",
                "description": (
                    "Shannon ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’æœ€å¤§å¯èƒ½ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã§æ­£è¦åŒ–ã—ãŸæŒ‡æ¨™ã€‚"
                    "0ï¼ˆ1 ç¨®ãŒå®Œå…¨å„ªå ï¼‰ã‹ã‚‰ 1ï¼ˆå®Œå…¨å‡ç­‰åˆ†å¸ƒï¼‰ã®ç¯„å›²ã€‚"
                ),
                "reveals": "ãƒªãƒƒãƒãƒã‚¹ã«ä¾å­˜ã—ãªã„ã€ç¨®ã®åˆ†å¸ƒå‡ç­‰æ€§ã®è©•ä¾¡ã€‚",
            },
            {
                "name": "Observed ASVs (Richness)",
                "equation": "S = |{ASV : count &gt; 0}|",
                "description": "å„ã‚µãƒ³ãƒ—ãƒ«ã§æ¤œå‡ºã•ã‚ŒãŸå›ºæœ‰ ASV ã®å˜ç´”ã‚«ã‚¦ãƒ³ãƒˆã€‚",
                "reveals": "å­˜åœ¨é‡åˆ†å¸ƒã‚’è€ƒæ…®ã—ãªã„ã€ç”Ÿã®åˆ†é¡å­¦çš„ãƒªãƒƒãƒãƒã‚¹ã€‚",
            },
        ],
    },
    {
        "id": "beta",
        "title": "ãƒ™ãƒ¼ã‚¿å¤šæ§˜æ€§ãƒ»ã‚ªãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚·ãƒ§ãƒ³",
        "description": (
            "ãƒ™ãƒ¼ã‚¿å¤šæ§˜æ€§ã¯ã‚µãƒ³ãƒ—ãƒ«é–“ã®çµ„æˆçš„å·®ç•°ã‚’å®šé‡åŒ–ã™ã‚‹ã€‚"
            "è·é›¢è¡Œåˆ—ã‚’ã‚ªãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚·ãƒ§ãƒ³æ‰‹æ³•ã§ 2 æ¬¡å…ƒã«æŠ•å½±ã—ã€"
            "é«˜æ¬¡å…ƒã®ç¾¤é›†ãƒ‡ãƒ¼ã‚¿ã‚’è¦–è¦šçš„ã«è§£é‡ˆå¯èƒ½ã«ã™ã‚‹ã€‚"
        ),
        "figures": ["fig05", "fig06", "fig07", "fig08", "fig09", "fig17", "fig24"],
        "methods": [
            {
                "name": "Bray-Curtis Dissimilarity",
                "equation": "BC<sub>jk</sub> = 1 &minus; 2&Sigma; min(x<sub>ij</sub>, x<sub>ik</sub>) / &Sigma;(x<sub>ij</sub> + x<sub>ik</sub>)",
                "description": (
                    "å­˜åœ¨é‡ãƒ™ãƒ¼ã‚¹ã®éé¡ä¼¼åº¦æŒ‡æ¨™ã€‚å…±æœ‰ç¨®ã®å­˜åœ¨é‡ã«é‡ã¿ã‚’ç½®ãã€‚"
                    "0ï¼ˆå®Œå…¨ä¸€è‡´ï¼‰ã‹ã‚‰ 1ï¼ˆå…±æœ‰ç¨®ãªã—ï¼‰ã®ç¯„å›²ã€‚"
                ),
                "reveals": "ç¨®ã®å­˜åœ¨é‡ã‚’é‡è¦–ã—ãŸã‚µãƒ³ãƒ—ãƒ«é–“ã®çµ„æˆçš„é¡ä¼¼æ€§ã€‚",
            },
            {
                "name": "Jaccard Distance",
                "equation": "J<sub>jk</sub> = 1 &minus; |A &cap; B| / |A &cup; B|",
                "description": (
                    "åœ¨/ä¸åœ¨ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãéé¡ä¼¼åº¦æŒ‡æ¨™ã€‚"
                    "å­˜åœ¨é‡ã‚’è€ƒæ…®ã›ãšã€å…±æœ‰ç¨®ã®æœ‰ç„¡ã®ã¿ã§è©•ä¾¡ã™ã‚‹ã€‚"
                ),
                "reveals": "å­˜åœ¨é‡ã«ä¾å­˜ã—ãªã„ã€ç¨®ã®å…±æœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚",
            },
            {
                "name": "UniFrac Distance",
                "equation": "UF<sub>w</sub> = &Sigma;<sub>i</sub> b<sub>i</sub> |p<sub>iA</sub> &minus; p<sub>iB</sub>| / &Sigma;<sub>i</sub> b<sub>i</sub>",
                "description": (
                    "ç³»çµ±æ¨¹ä¸Šã®æé•·ã‚’åˆ©ç”¨ã—ãŸç³»çµ±å­¦çš„è·é›¢ã€‚"
                    "Unweighted ã¯åœ¨/ä¸åœ¨ã€Weighted ã¯å­˜åœ¨é‡ã‚‚è€ƒæ…®ã™ã‚‹ã€‚"
                ),
                "reveals": "åˆ†é¡å­¦çš„æ‰‹æ³•ã§ã¯æ‰ãˆã‚‰ã‚Œãªã„ã€é€²åŒ–çš„é–¢ä¿‚ã«åŸºã¥ãç¾¤é›†é–“å·®ç•°ã€‚",
            },
            {
                "name": "PCoA (Principal Coordinates Analysis)",
                "equation": "maximize: &Sigma; &lambda;<sub>k</sub> / &Sigma; &lambda;<sub>i</sub>  (first k axes)",
                "description": (
                    "è·é›¢è¡Œåˆ—ã®å›ºæœ‰å€¤åˆ†è§£ã«ã‚ˆã‚Šã€ãƒšã‚¢ãƒ¯ã‚¤ã‚ºè·é›¢ã®åˆ†æ•£ã‚’"
                    "æœ€å¤§é™èª¬æ˜ã™ã‚‹è»¸ã‚’æ±‚ã‚ã‚‹ã€‚å„è»¸ã®åˆ†æ•£èª¬æ˜ç‡ (%) ãŒæœ‰åŠ¹æ€§ã‚’ç¤ºã™ã€‚"
                ),
                "reveals": "ç¾¤é›†å¤‰å‹•ã®ä¸»è¦ãªè»¸ã¨ã‚µãƒ³ãƒ—ãƒ«ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚",
            },
            {
                "name": "NMDS (Non-metric MDS)",
                "equation": "minimize: stress = &radic;(&Sigma;(d<sub>ij</sub> &minus; &delta;<sub>ij</sub>)&sup2; / &Sigma; d<sub>ij</sub>&sup2;)",
                "description": (
                    "è·é›¢ã®é †ä½é–¢ä¿‚ã‚’ä¿å­˜ã™ã‚‹åå¾©çš„ã‚ªãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚·ãƒ§ãƒ³ã€‚"
                    "Stress &lt; 0.1 ã§è‰¯å¥½ãªãƒ•ã‚£ãƒƒãƒˆã€&lt; 0.05 ã§å„ªç§€ã€‚"
                ),
                "reveals": "PCoA ã§ã¯æ‰ãˆã«ãã„éç·šå½¢çš„ãªç¾¤é›†æ§‹é€ ã€‚",
            },
            {
                "name": "UPGMA Dendrogram",
                "equation": "d<sub>UV</sub> = (d<sub>US</sub> + d<sub>VS</sub>) / 2",
                "description": (
                    "å¹³å‡é€£çµæ³•ã«ã‚ˆã‚‹éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€‚"
                    "è·é›¢è¡Œåˆ—ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã®éšå±¤çš„é¡ä¼¼é–¢ä¿‚ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚"
                ),
                "reveals": "ã‚µãƒ³ãƒ—ãƒ«é–“ã®éšå±¤çš„ã‚°ãƒ«ãƒ¼ãƒ—æ§‹é€ ã¨è‡ªç„¶ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€‚",
            },
        ],
    },
    {
        "id": "taxonomy",
        "title": "åˆ†é¡å­¦çš„çµ„æˆ",
        "description": (
            "å‚ç…§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (SILVA, Greengenes2) ã‚’ç”¨ã„ãŸ Naive Bayes åˆ†é¡å™¨ã§ "
            "ASV ã«åˆ†é¡å­¦çš„å¸°å±ï¼ˆé–€ â†’ ç¶± â†’ ç›® â†’ ç§‘ â†’ å±ï¼‰ã‚’ä»˜ä¸ã™ã‚‹ã€‚"
            "å„åˆ†é¡éšç´šã§ã®ç›¸å¯¾å­˜åœ¨é‡ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒç¾¤é›†æ§‹é€ ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚"
        ),
        "figures": ["fig14", "fig26", "fig27", "fig21", "fig13", "fig15", "fig10", "fig19"],
        "methods": [
            {
                "name": "Relative Abundance",
                "equation": "RA<sub>i</sub> = count<sub>i</sub> / &Sigma;<sub>j</sub> count<sub>j</sub> &times; 100%",
                "description": (
                    "å„åˆ†é¡ç¾¤ã®ãƒªãƒ¼ãƒ‰æ•°ã‚’ã‚µãƒ³ãƒ—ãƒ«ç·ãƒªãƒ¼ãƒ‰æ•°ã§å‰²ã£ãŸå‰²åˆã€‚"
                    "é–€ãƒ»ç¶±ãƒ»ç›®ãƒ»ç§‘ãƒ»å±ã®å„éšç´šã§ç®—å‡ºã—ã€ç¾¤é›†æ§‹é€ ã‚’å¤šè§’çš„ã«æŠŠæ¡ã™ã‚‹ã€‚"
                ),
                "reveals": "å„ã‚µãƒ³ãƒ—ãƒ«ã®å„ªå åˆ†é¡ç¾¤ã¨ã€ã‚µãƒ³ãƒ—ãƒ«é–“ã®çµ„æˆçš„å·®ç•°ã€‚",
            },
            {
                "name": "Naive Bayes Classifier",
                "equation": "P(taxon|seq) &prop; P(seq|taxon) &middot; P(taxon)",
                "description": (
                    "QIIME2 feature-classifier ã«ã‚ˆã‚‹ ASV ã®åˆ†é¡å­¦çš„å¸°å±ã€‚"
                    "å‚ç…§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸Šã§å­¦ç¿’ã—ãŸ k-mer é »åº¦åˆ†å¸ƒã‹ã‚‰äº‹å¾Œç¢ºç‡ã‚’è¨ˆç®—ã™ã‚‹ã€‚"
                ),
                "reveals": "æ¤œå‡ºã•ã‚ŒãŸé…åˆ—å¤‰ç•°ä½“ã®ç”Ÿç‰©å­¦çš„åŒå®šï¼ˆé–€ã‹ã‚‰å±ãƒ¬ãƒ™ãƒ«ã¾ã§ï¼‰ã€‚",
            },
        ],
    },
    {
        "id": "statistical",
        "title": "ç”Ÿæ…‹å­¦çš„ãƒ»çµ±è¨ˆå­¦çš„è§£æ",
        "description": (
            "ã‚³ã‚¢ç¾¤é›†ã®åŒå®šã€åˆ†é¡ç¾¤é–“ç›¸é–¢ã€å·®æ¬¡çš„å­˜åœ¨é‡è§£æã€"
            "ã‚µãƒ³ãƒ—ãƒ«é–“å…±æœ‰ ASV ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã©ã€é«˜åº¦ãªçµ±è¨ˆæ‰‹æ³•ã§"
            "ç¾¤é›†ã®ç”Ÿæ…‹å­¦çš„ç‰¹å¾´ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚"
        ),
        "figures": ["fig22", "fig20", "fig23", "fig25", "fig29"],
        "methods": [
            {
                "name": "Core Microbiome Analysis",
                "equation": "Core = {taxon : prevalence &ge; threshold}",
                "description": (
                    "å®šç¾©ã—ãŸé–¾å€¤ï¼ˆä¾‹: 80%ï¼‰ä»¥ä¸Šã®ã‚µãƒ³ãƒ—ãƒ«ã«å‡ºç¾ã™ã‚‹åˆ†é¡ç¾¤ã‚’åŒå®šã™ã‚‹ã€‚"
                    "ã‚µãƒ³ãƒ—ãƒ«æ¨ªæ–­çš„ã«å®‰å®šã—ã¦å­˜åœ¨ã™ã‚‹ç¾¤é›†ãƒ¡ãƒ³ãƒãƒ¼ã‚’ç‰¹å®šã™ã‚‹ã€‚"
                ),
                "reveals": "ç”Ÿæ…‹å­¦çš„ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å½¢æˆã™ã‚‹å®‰å®šã—ãŸç¾¤é›†æ§‹æˆå“¡ã€‚",
            },
            {
                "name": "Co-occurrence Network",
                "equation": "&rho;<sub>ij</sub> = cov(x<sub>i</sub>, x<sub>j</sub>) / (&sigma;<sub>i</sub> &sigma;<sub>j</sub>),&ensp; |&rho;| &gt; threshold",
                "description": (
                    "åˆ†é¡ç¾¤ã‚’ãƒãƒ¼ãƒ‰ã€æœ‰æ„ãªå­˜åœ¨é‡ç›¸é–¢ã‚’ã‚¨ãƒƒã‚¸ã¨ã™ã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€‚"
                    "æ­£ã®ç›¸é–¢ã¯å…±ç”Ÿãƒ»ãƒ‹ãƒƒãƒå…±æœ‰ã€è² ã®ç›¸é–¢ã¯ç«¶åˆã‚’ç¤ºå”†ã™ã‚‹ã€‚"
                ),
                "reveals": "åˆ†é¡ç¾¤é–“ã®æ½œåœ¨çš„ãªç”Ÿæ…‹å­¦çš„ç›¸äº’ä½œç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚",
            },
            {
                "name": "Differential Abundance (Volcano Plot)",
                "equation": "t<sub>i</sub> = (x&#772;<sub>A</sub> &minus; x&#772;<sub>B</sub>) / SE<sub>pooled</sub>,&ensp; q = BH-adjusted p",
                "description": (
                    "å„åˆ†é¡ç¾¤ã®ã‚°ãƒ«ãƒ¼ãƒ—é–“å­˜åœ¨é‡å·®ã‚’æ¤œå®šã—ã€"
                    "Benjamini-Hochberg æ³•ã§å¤šé‡æ¤œå®šè£œæ­£ã‚’è¡Œã† (FDR q &lt; 0.05)ã€‚"
                ),
                "reveals": "æ¡ä»¶é–“ã§æœ‰æ„ã«å¢—æ¸›ã™ã‚‹åˆ†é¡ç¾¤ï¼ˆãƒã‚¤ã‚ªãƒãƒ¼ã‚«ãƒ¼å€™è£œï¼‰ã€‚",
            },
            {
                "name": "Spearman Rank Correlation",
                "equation": "&rho;<sub>s</sub> = 1 &minus; 6&Sigma; d<sub>i</sub>&sup2; / n(n&sup2; &minus; 1)",
                "description": (
                    "åˆ†é¡ç¾¤é–“ã®å­˜åœ¨é‡ã®ãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯é †ä½ç›¸é–¢ã€‚"
                    "éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§ç›¸é–¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤ºã™ã‚‹ã€‚"
                ),
                "reveals": "å…±å­˜åœ¨é‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã€æ½œåœ¨çš„ãªæ©Ÿèƒ½çš„ã‚®ãƒ«ãƒ‰ã®åŒå®šã€‚",
            },
            {
                "name": "ASV Overlap Analysis",
                "equation": "|S<sub>A</sub> &cap; S<sub>B</sub> &cap; &hellip;| for all combinations",
                "description": (
                    "ã‚µãƒ³ãƒ—ãƒ«é–“ã§å…±æœ‰ã•ã‚Œã‚‹ ASV ã®é›†åˆè«–çš„è§£æã€‚"
                    "UpSet ãƒ—ãƒ­ãƒƒãƒˆå½¢å¼ã§çµ„ã¿åˆã‚ã›ã”ã¨ã®å…±æœ‰ãƒ»å›ºæœ‰ ASV æ•°ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"
                ),
                "reveals": "ã‚µãƒ³ãƒ—ãƒ«å›ºæœ‰ vs å…±é€š ASV ã®åˆ†å¸ƒã€ã‚³ã‚¢ç¾¤é›†ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚",
            },
        ],
    },
]


def _fig_title(path: str) -> str:
    stem = Path(path).stem.lower()
    # å®Œå…¨ä¸€è‡´
    if stem in _FIG_TITLE_MAP:
        return _FIG_TITLE_MAP[stem]
    # éƒ¨åˆ†ä¸€è‡´ï¼ˆå…ˆé ­ã‚­ãƒ¼ã‹ã‚‰æ¤œç´¢ï¼‰
    for key, title in _FIG_TITLE_MAP.items():
        if stem.startswith(key) or key in stem:
            return title
    return Path(path).stem.replace("_", " ").title()


def _encode_image(path: str) -> str:
    """ç”»åƒã‚’ base64 data URI ã«å¤‰æ›ã™ã‚‹"""
    p = Path(path)
    ext = p.suffix.lower().lstrip(".")
    mime = {
        "jpg": "image/jpeg",
        "jpeg": "image/jpeg",
        "png": "image/png",
        "gif": "image/gif",
    }.get(ext, "image/png")
    with open(p, "rb") as f:
        b64 = base64.b64encode(f.read()).decode()
    return f"data:{mime};base64,{b64}"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM ã«ã‚ˆã‚‹è§£é‡ˆç”Ÿæˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _llm_interpretations(
    fig_paths: list,
    user_prompt: str,
    model: str,
    n_samples: int,
    dada2_params: dict,
    log_callback: Optional[Callable],
) -> dict:
    """
    LLM ã«å„å›³ã®è§£é‡ˆæ–‡ã¨ç·åˆã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚

    æˆ»ã‚Šå€¤: {"SUMMARY": "...", "fig01_xxx": "...", ...}
    """
    def _log(msg):
        if log_callback:
            log_callback(msg)

    if not model or not fig_paths:
        return {}

    param_str = "  ".join(
        f"{k}={v}" for k, v in (dada2_params or {}).items()
        if k in ("trunc_len_f", "trunc_len_r", "sampling_depth")
    )
    fig_list_str = "\n".join(
        f"- {Path(f).name} ({_fig_title(f)})" for f in fig_paths
    )

    prompt = "\n".join([
        "You are a microbiome bioinformatics expert writing a results report in Japanese.",
        f"- Sample count: {n_samples}" if n_samples else "",
        f"- DADA2 parameters: {param_str}" if param_str else "",
        f"- Analysis request: {user_prompt}" if user_prompt else "",
        "",
        "The following figures were generated:",
        fig_list_str,
        "",
        "Write the following in Japanese:",
        "1. SUMMARY: A 2-3 sentence overall summary of the microbiome analysis.",
        "2. For each figure, one sentence interpretation (filename stem as key).",
        "",
        "Output format (exactly as shown, no extra lines):",
        "SUMMARY: [overall summary]",
        *[f"{Path(f).stem}: [interpretation]" for f in fig_paths],
    ])

    _log("ğŸ“ LLM ãŒãƒ¬ãƒãƒ¼ãƒˆè§£é‡ˆæ–‡ã‚’ç”Ÿæˆä¸­...")
    try:
        response = _agent.call_ollama(
            [
                {"role": "system", "content": "Microbiome expert. Write concise Japanese interpretations."},
                {"role": "user",   "content": prompt},
            ],
            model,
        )
        content = response.get("content", "")
    except Exception as e:
        _log(f"  âš ï¸  LLM å‘¼ã³å‡ºã—å¤±æ•—: {e}")
        return {}

    result = {}
    for line in content.splitlines():
        if ":" not in line:
            continue
        key, _, val = line.partition(":")
        key = key.strip()
        val = val.strip()
        if key and val:
            result[key] = val
    return result


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HTML ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_CSS = """
:root {
  --c-text: #1e293b;
  --c-muted: #64748b;
  --c-bg: #f8fafc;
  --c-card: #ffffff;
  --c-border: #e2e8f0;
  --c-accent: #2563eb;
  --c-accent-bg: #eff6ff;
  --c-heading: #0f172a;
}
* { box-sizing: border-box; margin: 0; padding: 0; }
body {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Hiragino Sans', 'Noto Sans JP', sans-serif;
  background: var(--c-bg); color: var(--c-text); line-height: 1.75; font-size: 15px;
}
header {
  background: var(--c-heading); color: #fff; padding: 2.8rem 2rem; text-align: center;
}
header h1 { font-size: 1.5rem; font-weight: 600; letter-spacing: 0.02em; }
header .sub { color: rgba(255,255,255,0.5); font-size: 0.85rem; margin-top: 0.4rem; }
.container { max-width: 1100px; margin: 0 auto; padding: 2rem 1.5rem; }
nav.toc {
  background: var(--c-card); border: 1px solid var(--c-border);
  border-radius: 8px; padding: 1.2rem 1.5rem; margin-bottom: 1.5rem;
}
nav.toc h2 {
  font-size: 0.75rem; text-transform: uppercase; letter-spacing: 0.08em;
  color: var(--c-muted); margin-bottom: 0.6rem;
}
nav.toc ol { padding-left: 1.4rem; columns: 2; column-gap: 2rem; }
nav.toc li { font-size: 0.88rem; padding: 0.15rem 0; break-inside: avoid; }
nav.toc a { color: var(--c-accent); text-decoration: none; }
nav.toc a:hover { text-decoration: underline; }
.section {
  background: var(--c-card); border: 1px solid var(--c-border);
  border-radius: 8px; padding: 1.8rem 2rem; margin-bottom: 1.5rem;
}
.section-title {
  font-size: 1.15rem; font-weight: 600; color: var(--c-heading);
  padding-bottom: 0.5rem; border-bottom: 2px solid var(--c-border); margin-bottom: 1rem;
}
.section-desc {
  font-size: 0.9rem; color: var(--c-muted); margin-bottom: 1.4rem; line-height: 1.7;
}
.summary-box {
  background: var(--c-accent-bg); border-left: 3px solid var(--c-accent);
  padding: 0.9rem 1.1rem; border-radius: 0 6px 6px 0; font-size: 0.93rem;
}
table { border-collapse: collapse; width: 100%; font-size: 0.9rem; }
th, td { text-align: left; padding: 0.55rem 0.8rem; border-bottom: 1px solid var(--c-border); }
th { background: var(--c-bg); font-weight: 600; width: 40%; }
.methods-grid { display: grid; gap: 0.8rem; margin-bottom: 1.5rem; }
.method-item {
  border: 1px solid var(--c-border); border-radius: 6px;
  padding: 1rem 1.2rem; background: var(--c-bg);
}
.method-item h4 { font-size: 0.92rem; font-weight: 600; color: var(--c-heading); margin-bottom: 0.4rem; }
.eq {
  font-family: Georgia, 'Times New Roman', serif; font-size: 1rem;
  color: var(--c-accent); background: var(--c-card);
  border: 1px solid var(--c-border); border-radius: 4px;
  padding: 0.4rem 0.7rem; margin: 0.4rem 0; display: inline-block; line-height: 1.6;
}
.method-desc { font-size: 0.86rem; color: var(--c-text); margin-bottom: 0.25rem; line-height: 1.65; }
.method-reveals { font-size: 0.84rem; color: var(--c-muted); }
.method-reveals strong { color: var(--c-text); }
.fig-grid {
  display: grid; grid-template-columns: repeat(auto-fill, minmax(460px, 1fr)); gap: 1rem;
}
.fig-card {
  border: 1px solid var(--c-border); border-radius: 6px;
  overflow: hidden; background: var(--c-card);
}
.fig-card img { width: 100%; height: auto; display: block; }
.fig-caption { padding: 0.7rem 0.9rem; }
.fig-caption strong { display: block; font-size: 0.9rem; color: var(--c-heading); margin-bottom: 0.15rem; }
.fig-caption p { font-size: 0.83rem; color: var(--c-muted); }
.step-list { list-style: none; padding: 0; }
.step-list li {
  padding: 0.3rem 0; font-size: 0.88rem; display: flex; align-items: center; gap: 0.5rem;
}
.dot {
  display: inline-block; width: 7px; height: 7px; border-radius: 50%; flex-shrink: 0;
}
.dot-ok { background: #16a34a; }
.dot-fail { background: #dc2626; }
.dot-warn { background: #d97706; }
footer { text-align: center; padding: 2rem; font-size: 0.8rem; color: var(--c-muted); }
"""

_HTML_TEMPLATE = """\
<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>seq2pipe Analysis Report â€” {date}</title>
<style>{css}</style>
</head>
<body>
<header>
  <h1>seq2pipe Analysis Report</h1>
  <p class="sub">{datetime_str} | 16S rRNA Amplicon Sequencing</p>
</header>
<div class="container">
{toc_section}
{summary_section}
{params_section}
{steps_section}
{analysis_sections}
</div>
<footer>Generated by seq2pipe | QIIME2 + {model}</footer>
</body>
</html>
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¤ãƒ³é–¢æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def generate_html_report(
    fig_dir: str,
    output_dir: str,
    fastq_dir: str = "",
    n_samples: int = 0,
    dada2_params: Optional[dict] = None,
    completed_steps: Optional[list] = None,
    failed_steps: Optional[list] = None,
    export_files: Optional[dict] = None,
    user_prompt: str = "",
    model: str = "",
    log_callback: Optional[Callable] = None,
) -> str:
    """
    HTML ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ output_dir/report.html ã«ä¿å­˜ã™ã‚‹ã€‚
    æˆ»ã‚Šå€¤: ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    def _log(msg):
        if log_callback:
            log_callback(msg)

    dada2_params   = dada2_params   or {}
    completed_steps = completed_steps or []
    failed_steps    = failed_steps    or []
    export_files    = export_files    or {}

    # â”€â”€ å›³ãƒ•ã‚¡ã‚¤ãƒ«åé›† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fig_dir_path = Path(fig_dir)
    fig_files = sorted(
        list(fig_dir_path.glob("*.jpg"))
        + list(fig_dir_path.glob("*.jpeg"))
        + list(fig_dir_path.glob("*.png")),
        key=lambda p: p.name,
    )

    # â”€â”€ LLM è§£é‡ˆç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    interpretations: dict = {}
    if model and fig_files:
        interpretations = _llm_interpretations(
            [str(f) for f in fig_files],
            user_prompt, model, n_samples, dada2_params, log_callback,
        )

    now = datetime.datetime.now()
    date_str     = now.strftime("%Y-%m-%d")
    datetime_str = now.strftime("%Y-%m-%d %H:%M")

    # â”€â”€ ã‚µãƒãƒªãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    summary_text = interpretations.get("SUMMARY", "")
    if summary_text:
        summary_section = (
            '<div class="section" id="summary">'
            '<h2 class="section-title">Summary</h2>'
            f'<div class="summary-box">{summary_text}</div>'
            '</div>'
        )
    else:
        summary_section = ""

    # â”€â”€ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _PARAM_LABELS = {
        "trim_left_f":    "trim-left-f (forward trim bases)",
        "trim_left_r":    "trim-left-r (reverse trim bases)",
        "trunc_len_f":    "trunc-len-f (forward truncation length)",
        "trunc_len_r":    "trunc-len-r (reverse truncation length)",
        "sampling_depth": "sampling-depth (diversity analysis depth)",
        "n_threads":      "Threads",
        "read_len_f":     "Forward read length",
        "read_len_r":     "Reverse read length",
    }
    rows = ""
    if fastq_dir:
        rows += f"<tr><th>FASTQ directory</th><td>{fastq_dir}</td></tr>"
    if n_samples:
        rows += f"<tr><th>Samples</th><td>{n_samples} (paired-end)</td></tr>"
    for k, v in dada2_params.items():
        label = _PARAM_LABELS.get(k, k)
        if v:
            rows += f"<tr><th>{label}</th><td>{v}</td></tr>"
    if rows:
        params_section = (
            '<div class="section" id="params">'
            '<h2 class="section-title">Parameters</h2>'
            f'<table><tbody>{rows}</tbody></table>'
            '</div>'
        )
    else:
        params_section = ""

    # â”€â”€ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ãƒ†ãƒƒãƒ—ã‚»ã‚¯ã‚·ãƒ§ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    step_items = ""
    for s in completed_steps:
        text = s.lstrip("\u2705\u26a0\ufe0f\u274c ")
        dot_cls = "dot-warn" if "\u26a0" in s else "dot-ok"
        step_items += f'<li><span class="dot {dot_cls}"></span>{text}</li>'
    for s in failed_steps:
        text = s.lstrip("\u274c ")
        step_items += f'<li><span class="dot dot-fail"></span>{text}</li>'

    if step_items:
        steps_section = (
            '<div class="section" id="steps">'
            '<h2 class="section-title">Pipeline Steps</h2>'
            '<p class="section-desc">'
            'QIIME2 (DADA2 denoising / MAFFT-FastTree phylogeny / diversity) + '
            'Python (matplotlib, seaborn, pandas, scipy, scikit-learn)'
            '</p>'
            f'<ul class="step-list">{step_items}</ul>'
            '</div>'
        )
    else:
        steps_section = ""

    # â”€â”€ ã‚«ãƒ†ã‚´ãƒªåˆ¥è§£æã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæ‰‹æ³• + å›³ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    analysis_html = ""
    categorized = set()

    for cat in _ANALYSIS_CATEGORIES:
        cat_figs = []
        for prefix in cat["figures"]:
            for fp in fig_files:
                if fp.stem.startswith(prefix):
                    cat_figs.append(fp)
                    categorized.add(fp.stem)

        if not cat_figs:
            continue

        # æ‰‹æ³•ã‚«ãƒ¼ãƒ‰
        methods_html = ""
        for m in cat["methods"]:
            eq_html = ""
            if m.get("equation"):
                eq_html = f'<div class="eq">{m["equation"]}</div>'
            methods_html += (
                '<div class="method-item">'
                f'<h4>{m["name"]}</h4>'
                f'{eq_html}'
                f'<p class="method-desc">{m["description"]}</p>'
                f'<p class="method-reveals"><strong>çŸ¥è¦‹:</strong> {m["reveals"]}</p>'
                '</div>'
            )

        # å›³ã‚«ãƒ¼ãƒ‰
        fig_html = ""
        for fp in cat_figs:
            title = _fig_title(str(fp))
            interp = interpretations.get(fp.stem, "")
            try:
                data_uri = _encode_image(str(fp))
            except Exception:
                continue
            caption_p = f"<p>{interp}</p>" if interp else ""
            fig_html += (
                '<div class="fig-card">'
                f'<img src="{data_uri}" alt="{title}" loading="lazy">'
                '<div class="fig-caption">'
                f'<strong>{title}</strong>'
                f'{caption_p}'
                '</div></div>'
            )

        analysis_html += (
            f'<div class="section" id="{cat["id"]}">'
            f'<h2 class="section-title">{cat["title"]}</h2>'
            f'<p class="section-desc">{cat["description"]}</p>'
            f'<div class="methods-grid">{methods_html}</div>'
            f'<div class="fig-grid">{fig_html}</div>'
            '</div>'
        )

    # â”€â”€ æœªåˆ†é¡å›³ï¼ˆadaptive / ã‚«ã‚¹ã‚¿ãƒ ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    remaining = [fp for fp in fig_files if fp.stem not in categorized]
    if remaining:
        fig_html = ""
        for fp in remaining:
            title = _fig_title(str(fp))
            interp = interpretations.get(fp.stem, "")
            try:
                data_uri = _encode_image(str(fp))
            except Exception:
                continue
            caption_p = f"<p>{interp}</p>" if interp else ""
            fig_html += (
                '<div class="fig-card">'
                f'<img src="{data_uri}" alt="{title}" loading="lazy">'
                '<div class="fig-caption">'
                f'<strong>{title}</strong>'
                f'{caption_p}'
                '</div></div>'
            )
        analysis_html += (
            '<div class="section" id="additional">'
            '<h2 class="section-title">Adaptive Analysis</h2>'
            '<p class="section-desc">'
            'LLM ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´ã‚’åˆ†æã—ã€è‡ªå‹•ç”Ÿæˆã—ãŸè¿½åŠ å¯è¦–åŒ–ã€‚'
            '</p>'
            f'<div class="fig-grid">{fig_html}</div>'
            '</div>'
        )

    # â”€â”€ ç›®æ¬¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    toc_items = ""
    if summary_text:
        toc_items += '<li><a href="#summary">Summary</a></li>'
    if rows:
        toc_items += '<li><a href="#params">Parameters</a></li>'
    if step_items:
        toc_items += '<li><a href="#steps">Pipeline Steps</a></li>'
    for cat in _ANALYSIS_CATEGORIES:
        has_figs = any(
            fp.stem.startswith(prefix)
            for prefix in cat["figures"]
            for fp in fig_files
        )
        if has_figs:
            toc_items += f'<li><a href="#{cat["id"]}">{cat["title"]}</a></li>'
    if remaining:
        toc_items += '<li><a href="#additional">Adaptive Analysis</a></li>'

    toc_section = (
        '<nav class="toc">'
        '<h2>Contents</h2>'
        f'<ol>{toc_items}</ol>'
        '</nav>'
    ) if toc_items else ""

    # â”€â”€ HTML çµ„ã¿ç«‹ã¦ãƒ»ä¿å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    html = _HTML_TEMPLATE.format(
        css=_CSS,
        date=date_str,
        datetime_str=datetime_str,
        toc_section=toc_section,
        summary_section=summary_section,
        params_section=params_section,
        steps_section=steps_section,
        analysis_sections=analysis_html,
        model=model or "local LLM",
    )

    report_path = Path(output_dir) / "report.html"
    report_path.write_text(html, encoding="utf-8")
    _log(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {report_path}")
    return str(report_path)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LaTeX / PDF ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _escape_latex(text: str) -> str:
    """LaTeX ç‰¹æ®Šæ–‡å­—ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã™ã‚‹ï¼ˆé€šå¸¸ãƒ†ã‚­ã‚¹ãƒˆç”¨ï¼‰"""
    conv = [
        ("\\", r"\textbackslash{}"),
        ("&",  r"\&"),
        ("%",  r"\%"),
        ("$",  r"\$"),
        ("#",  r"\#"),
        ("_",  r"\_"),
        ("{",  r"\{"),
        ("}",  r"\}"),
        ("~",  r"\textasciitilde{}"),
        ("^",  r"\textasciicircum{}"),
        ("<",  r"\textless{}"),
        (">",  r"\textgreater{}"),
    ]
    for old, new in conv:
        text = text.replace(old, new)
    return text


def _find_latex_engine() -> Optional[str]:
    """åˆ©ç”¨å¯èƒ½ãª LaTeX ã‚¨ãƒ³ã‚¸ãƒ³åã‚’è¿”ã™ã€‚ãªã‘ã‚Œã° Noneã€‚"""
    for engine in ("lualatex", "xelatex"):
        try:
            r = subprocess.run([engine, "--version"], capture_output=True, timeout=10)
            if r.returncode == 0:
                return engine
        except (FileNotFoundError, subprocess.TimeoutExpired):
            pass
    return None


def _build_latex_doc(
    engine: Optional[str],
    date_str: str,
    summary_text: str,
    fastq_dir: str,
    n_samples: int,
    dada2_params: dict,
    completed_steps: list,
    failed_steps: list,
    model: str,
    fig_paths: list,
    interpretations: dict,
) -> str:
    """LaTeX ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ–‡å­—åˆ—ã‚’è¿”ã™"""

    # â”€â”€ ãƒ—ãƒªã‚¢ãƒ³ãƒ–ãƒ« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if engine == "lualatex":
        preamble = r"""\documentclass[a4paper,12pt]{article}
\usepackage[hiragino-pron]{luatexja-preset}
"""
    elif engine == "xelatex":
        preamble = r"""\documentclass[a4paper,12pt]{article}
\usepackage{xeCJK}
\setCJKmainfont{Hiragino Mincho ProN}
\setCJKsansfont{Hiragino Kaku Gothic ProN}
"""
    else:
        # ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ä¸å¯ã®å ´åˆã‚‚æœ‰åŠ¹ãª .tex ã¨ã—ã¦å‡ºåŠ›
        preamble = r"""\documentclass[a4paper,12pt]{article}
% NOTE: Japanese support requires lualatex + luatexja-preset, or xelatex + xeCJK.
% Compile with: lualatex report.tex
"""

    preamble += r"""
\usepackage[top=25mm,bottom=25mm,left=28mm,right=28mm]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{float}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{fancyhdr}
\usepackage{tcolorbox}

\definecolor{teal}{RGB}{17,122,101}
\definecolor{navy}{RGB}{21,67,96}
\hypersetup{colorlinks=true, linkcolor=navy, urlcolor=teal, pdfborder={0 0 0}}
\captionsetup{font=small, labelfont=bf, labelsep=period, justification=centering}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small\color{navy}seq2pipe è§£æãƒ¬ãƒãƒ¼ãƒˆ}
\fancyhead[R]{\small\thepage}
\renewcommand{\headrulewidth}{0.5pt}
"""

    # â”€â”€ ã‚¿ã‚¤ãƒˆãƒ« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    title_block = r"""
\title{\textbf{seq2pipe è§£æãƒ¬ãƒãƒ¼ãƒˆ}\\[0.5em]
  \large QIIME2 ãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³}
\date{""" + _escape_latex(date_str) + r"""}
\author{è‡ªå‹•ç”Ÿæˆ --- """ + _escape_latex(model or "local LLM") + r"""}
"""

    # â”€â”€ æœ¬æ–‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    body_parts = [
        r"\begin{document}",
        r"\maketitle",
        r"\thispagestyle{fancy}",
    ]

    # ã‚µãƒãƒªãƒ¼
    if summary_text:
        body_parts += [
            r"\section*{ç·åˆã‚µãƒãƒªãƒ¼}",
            r"\begin{tcolorbox}[colback=teal!8!white, colframe=teal, boxrule=1pt, arc=4pt]",
            _escape_latex(summary_text),
            r"\end{tcolorbox}",
        ]

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¡¨
    _PARAM_LABELS = {
        "trim_left_f":    r"trim-left-fï¼ˆãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å…ˆé ­ãƒˆãƒªãƒ å¡©åŸºæ•°ï¼‰",
        "trim_left_r":    r"trim-left-rï¼ˆãƒªãƒãƒ¼ã‚¹å…ˆé ­ãƒˆãƒªãƒ å¡©åŸºæ•°ï¼‰",
        "trunc_len_f":    r"trunc-len-fï¼ˆãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒˆãƒ©ãƒ³ã‚±ãƒ¼ã‚·ãƒ§ãƒ³é•·ï¼‰",
        "trunc_len_r":    r"trunc-len-rï¼ˆãƒªãƒãƒ¼ã‚¹ãƒˆãƒ©ãƒ³ã‚±ãƒ¼ã‚·ãƒ§ãƒ³é•·ï¼‰",
        "sampling_depth": r"sampling-depthï¼ˆå¤šæ§˜æ€§è§£æã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ·±åº¦ï¼‰",
        "n_threads":      r"ã‚¹ãƒ¬ãƒƒãƒ‰æ•°",
    }
    rows = []
    if fastq_dir:
        rows.append(("FASTQãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª", fastq_dir))
    if n_samples:
        rows.append(("ã‚µãƒ³ãƒ—ãƒ«æ•°", f"{n_samples} ã‚µãƒ³ãƒ—ãƒ«ï¼ˆãƒšã‚¢ã‚¨ãƒ³ãƒ‰ï¼‰"))
    for k, v in dada2_params.items():
        if v:
            rows.append((_PARAM_LABELS.get(k, k), str(v)))

    if rows:
        tbl = "\n".join(
            r"  " + _escape_latex(k) + r" & " + _escape_latex(str(v)) + r" \\"
            for k, v in rows
        )
        body_parts += [
            r"\section*{è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿}",
            r"\begin{center}",
            r"\begin{tabular}{>{\bfseries}p{0.45\linewidth}p{0.48\linewidth}}",
            r"\toprule",
            tbl,
            r"\bottomrule",
            r"\end{tabular}",
            r"\end{center}",
        ]

    # æ‰‹æ³•ãƒ»ã‚¹ãƒ†ãƒƒãƒ—
    all_steps = [("ok", s) for s in completed_steps] + [("fail", s) for s in failed_steps]
    if all_steps:
        items = []
        for kind, s in all_steps:
            text = _escape_latex(s.lstrip("âœ…âš ï¸âŒ "))
            mark = r"\textcolor{red}{$\times$}" if kind == "fail" else r"\textcolor{teal}{$\checkmark$}"
            items.append(rf"  \item[{mark}] {text}")
        body_parts += [
            r"\section*{è§£ææ‰‹æ³•ãƒ»ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ãƒ†ãƒƒãƒ—}",
            r"\noindent\textbf{ä½¿ç”¨ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢}: QIIME2ï¼ˆDADA2 / MAFFT-FastTree / å¤šæ§˜æ€§è§£æï¼‰+ Pythonï¼ˆmatplotlib, seaborn, pandasï¼‰\\[0.5em]",
            r"\begin{description}",
        ] + items + [r"\end{description}"]

    # å›³ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if fig_paths:
        body_parts.append(
            rf"\section*{{è§£æçµæœå›³ï¼ˆ{len(fig_paths)} ä»¶ï¼‰}}"
        )
        # 2åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
        pairs = [fig_paths[i:i+2] for i in range(0, len(fig_paths), 2)]
        for pair in pairs:
            body_parts.append(r"\begin{figure}[H]")
            body_parts.append(r"  \centering")
            width = r"0.48\linewidth" if len(pair) == 2 else r"0.85\linewidth"
            for fp in pair:
                p = Path(fp)
                title = _escape_latex(_fig_title(str(fp)))
                interp_raw = interpretations.get(p.stem, "")
                interp = _escape_latex(interp_raw)
                # graphicx: ãƒ‘ã‚¹ã«ç©ºç™½ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ãƒ–ãƒ¬ãƒ¼ã‚¹å†…ã«
                safe_path = str(p).replace("\\", "/")
                caption_text = (
                    r"\textbf{" + title + r"}"
                    + (r"\\[0.2em] \small " + interp if interp else "")
                )
                body_parts += [
                    r"  \begin{minipage}{" + width + r"}",
                    r"    \centering",
                    r"    \includegraphics[width=\linewidth]{" + safe_path + r"}",
                    r"    \captionof{figure}{" + caption_text + r"}",
                    r"  \end{minipage}",
                ]
                if len(pair) == 2 and fp == pair[0]:
                    body_parts.append(r"  \hfill")
            body_parts.append(r"\end{figure}")
            body_parts.append("")

    body_parts.append(r"\end{document}")

    return preamble + title_block + "\n".join(body_parts) + "\n"


def generate_latex_report(
    fig_dir: str,
    output_dir: str,
    fastq_dir: str = "",
    n_samples: int = 0,
    dada2_params: Optional[dict] = None,
    completed_steps: Optional[list] = None,
    failed_steps: Optional[list] = None,
    export_files: Optional[dict] = None,
    user_prompt: str = "",
    model: str = "",
    log_callback: Optional[Callable] = None,
) -> str:
    """
    LaTeX ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ output_dir/report.tex ã‚’ä¿å­˜ã—ã€
    LaTeX ã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨å¯èƒ½ãªã‚‰ output_dir/report.pdf ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã™ã‚‹ã€‚
    æˆ»ã‚Šå€¤: PDF ãƒ‘ã‚¹ï¼ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æˆåŠŸæ™‚ï¼‰ã¾ãŸã¯ TEX ãƒ‘ã‚¹
    """
    def _log(msg):
        if log_callback:
            log_callback(msg)

    dada2_params    = dada2_params    or {}
    completed_steps = completed_steps or []
    failed_steps    = failed_steps    or []

    # â”€â”€ å›³ãƒ•ã‚¡ã‚¤ãƒ«åé›† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    fig_dir_path = Path(fig_dir)
    fig_files = sorted(
        list(fig_dir_path.glob("*.jpg"))
        + list(fig_dir_path.glob("*.jpeg"))
        + list(fig_dir_path.glob("*.png")),
        key=lambda p: p.name,
    )

    # â”€â”€ LLM è§£é‡ˆç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    interpretations: dict = {}
    if model and fig_files:
        interpretations = _llm_interpretations(
            [str(f) for f in fig_files],
            user_prompt, model, n_samples, dada2_params, log_callback,
        )

    now = datetime.datetime.now()
    date_str = now.strftime("%Yå¹´%mæœˆ%dæ—¥")

    # â”€â”€ LaTeX ã‚¨ãƒ³ã‚¸ãƒ³æ¤œå‡º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    engine = _find_latex_engine()
    if engine:
        _log(f"ğŸ“ LaTeX ã‚¨ãƒ³ã‚¸ãƒ³æ¤œå‡º: {engine}")
    else:
        _log("âš ï¸  lualatex / xelatex ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.tex ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ä¿å­˜ã—ã¾ã™ã€‚")
        _log("   MacTeX ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: https://tug.org/mactex/")

    # â”€â”€ .tex ç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    summary_text = interpretations.get("SUMMARY", "")
    tex_content = _build_latex_doc(
        engine=engine,
        date_str=date_str,
        summary_text=summary_text,
        fastq_dir=fastq_dir,
        n_samples=n_samples,
        dada2_params=dada2_params,
        completed_steps=completed_steps,
        failed_steps=failed_steps,
        model=model,
        fig_paths=[str(f) for f in fig_files],
        interpretations=interpretations,
    )

    out_dir = Path(output_dir)
    tex_path = out_dir / "report.tex"
    tex_path.write_text(tex_content, encoding="utf-8")
    _log(f"ğŸ“„ report.tex ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {tex_path}")

    if not engine:
        return str(tex_path)

    # â”€â”€ PDF ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ï¼ˆ2 å›å®Ÿè¡Œã§å‚ç…§è§£æ±ºï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pdf_path = out_dir / "report.pdf"
    compile_ok = False
    for pass_num in range(1, 3):
        _log(f"ğŸ”§ {engine} ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ä¸­... ({pass_num}/2)")
        try:
            proc = subprocess.run(
                [
                    engine,
                    "-interaction=nonstopmode",
                    "-halt-on-error",
                    f"-output-directory={out_dir}",
                    str(tex_path),
                ],
                capture_output=True,
                timeout=120,
                cwd=str(out_dir),
            )
            if proc.returncode != 0:
                # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è¡¨ç¤ºï¼ˆæœ€å¾Œã® 30 è¡Œï¼‰
                err_lines = proc.stdout.decode(errors="replace").splitlines()
                for ln in err_lines[-30:]:
                    if ln.strip():
                        _log(f"  [latex] {ln}")
                _log(f"âŒ {engine} ãŒã‚¨ãƒ©ãƒ¼ã§çµ‚äº†ã—ã¾ã—ãŸ (pass {pass_num})")
                break
            compile_ok = True
        except subprocess.TimeoutExpired:
            _log("âŒ LaTeX ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ120ç§’ï¼‰")
            break
        except FileNotFoundError:
            _log(f"âŒ {engine} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            break

    if compile_ok and pdf_path.exists():
        # è£œåŠ©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        for ext in (".aux", ".log", ".out", ".toc"):
            (out_dir / ("report" + ext)).unlink(missing_ok=True)
        _log(f"âœ… PDF ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {pdf_path}")
        return str(pdf_path)
    else:
        _log(f"âš ï¸  PDF ç”Ÿæˆå¤±æ•—ã€‚.tex ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‰‹å‹•ã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¦ãã ã•ã„: {tex_path}")
        return str(tex_path)
