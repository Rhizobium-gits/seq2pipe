#!/usr/bin/env python3
"""
code_agent.py
=============
LLM ã« Python è§£æã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã•ã›ã€å®Ÿè¡Œãƒ»ã‚¨ãƒ©ãƒ¼ä¿®æ­£ãƒ»ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèªã‚’è¡Œã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
"""

import json
import re
import subprocess
import tempfile
from dataclasses import dataclass, field
from pathlib import Path
from typing import Callable, Optional

import sys
sys.path.insert(0, str(Path(__file__).parent))
import qiime2_agent as _agent


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class CodeExecutionResult:
    """ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»å®Ÿè¡Œã®çµæœ"""
    success: bool
    stdout: str = ""
    stderr: str = ""
    code: str = ""
    figures: list = field(default_factory=list)
    retry_count: int = 0
    error_message: str = ""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_prompt(
    export_files: dict,
    user_prompt: str,
    figure_dir: str,
    metadata_path: str = "",
    plot_config: Optional[dict] = None,
) -> str:
    """LLM ã¸ã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿ç«‹ã¦ã‚‹"""
    cfg = plot_config or {}
    dpi     = cfg.get("dpi", 150)
    figsize = cfg.get("figsize", [10, 6])

    lines = [
        "You are a microbiome bioinformatics expert.",
        "Write a single, complete, self-contained Python script that analyzes and visualizes",
        "the QIIME2-exported data listed below.",
        "",
        "## Available files",
    ]
    for category, paths in export_files.items():
        for p in paths:
            lines.append(f"  [{category}] {p}")
    if metadata_path:
        lines.append(f"  [metadata] {metadata_path}")

    lines += [
        "",
        f"## Output directory for figures: {figure_dir}",
        f"## DPI: {dpi}",
        f"## figsize: {figsize}",
        "",
        "## User request",
        user_prompt.strip() or (
            "Generate: (1) genus-level stacked bar chart of relative abundance, "
            "(2) alpha diversity boxplot (Shannon), (3) beta diversity PCoA (Bray-Curtis)."
        ),
        "",
        "## FILE FORMAT â€” read exactly as described",
        "",
        "### [feature_table] TSV  (exported from QIIME2 via biom convert)",
        "  - First line  : '# Constructed from biom file'  â† comment, skip it",
        "  - Second line : '#OTU ID\\t<sample1>\\t<sample2>...'  â† use as header",
        "  - Remaining   : Feature ID (ASV/OTU) | per-sample read counts",
        "  - Read with   :",
        "      ft = pd.read_csv(path, sep='\\t', skiprows=1, index_col=0)",
        "      ft.index.name = 'Feature ID'",
        "",
        "### [taxonomy] taxonomy.tsv",
        "  - Columns: Feature ID (index) | Taxon | Confidence",
        "  - Taxon format: 'd__Bacteria; p__Firmicutes; c__Clostridia; o__...; f__...; g__Genus; s__species'",
        "  - Read with   : tax = pd.read_csv(path, sep='\\t', index_col=0)",
        "  - Get genus   : tax['genus'] = tax['Taxon'].str.extract(r'g__([^;]+)').fillna('Unknown').str.strip()",
        "",
        "### [alpha] alpha-diversity TSV",
        "  - Columns: sample-id (index) | metric value (shannon / observed_features / faith_pd ...)",
        "  - Read with   : alpha = pd.read_csv(path, sep='\\t', index_col=0)",
        "",
        "### [beta] distance-matrix TSV",
        "  - Square symmetric matrix; row names = column names = sample IDs",
        "  - Read with   : dm = pd.read_csv(path, sep='\\t', index_col=0)",
        "  - PCoA with sklearn :",
        "      from sklearn.manifold import MDS",
        "      coords = MDS(n_components=2, dissimilarity='precomputed', random_state=42).fit_transform(dm.values)",
        "",
        "## Code requirements",
        "1. First two lines MUST be:",
        "      import matplotlib",
        "      matplotlib.use('Agg')",
        "2. Define at the top:",
        f"      FIGURE_DIR = r'{figure_dir}'",
        f"      DPI = {dpi}",
        "      import os; os.makedirs(FIGURE_DIR, exist_ok=True)",
        "3. Save every figure:",
        "      plt.savefig(os.path.join(FIGURE_DIR, 'name.png'), dpi=DPI, bbox_inches='tight')",
        "      plt.close()",
        "4. All axis labels, titles, legend entries in English.",
        "5. Use try/except around each section so one failure does not stop the whole script.",
        "6. Output ONLY the Python code, wrapped in ```python ... ```.",
        "7. Do NOT use plt.show().",
        "",
        "## COMMON MISTAKES â€” avoid these",
        "- DO NOT: from scipy.stats import boxplot  â† scipy.stats has NO boxplot function",
        "  CORRECT: plt.boxplot(data)  or  seaborn.boxplot(data=df, ...)",
        "- DO NOT: import biom  â† use pd.read_csv() directly on .tsv files",
        "- DO NOT hardcode data values â€” always read from the file paths listed above",
        "- TAXONOMY str.extract RETURNS DataFrame, not Series:",
        "  WRONG: tax['Taxon'].str.extract(r'g__([^;]+)').fillna('Unknown').str.strip()",
        "  RIGHT: tax['Taxon'].str.extract(r'g__([^;]+)')[0].fillna('Unknown').str.strip()",
        "- DO NOT use bare 'except Exception as e: print(...)' â€” it hides real errors.",
        "  Instead: let errors propagate (no try/except) or use 'raise' inside except.",
    ]
    return "\n".join(lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_manifest_prompt(
    manifest_path: str,
    user_prompt: str,
    output_dir: str,
    figure_dir: str,
    metadata_path: str = "",
    plot_config: Optional[dict] = None,
) -> str:
    """ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
    import csv

    # ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’èª­ã‚“ã§ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒ»æ§‹é€ ã‚’ç¢ºèª
    samples = []
    try:
        with open(manifest_path, newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f, delimiter="\t")
            for row in reader:
                sid = row.get("sample-id") or row.get("sampleid") or ""
                if sid:
                    samples.append(sid)
    except Exception:
        pass

    qiime_bin = (
        str(Path(_agent.QIIME2_CONDA_BIN) / "qiime")
        if _agent.QIIME2_CONDA_BIN and Path(_agent.QIIME2_CONDA_BIN).exists()
        else "qiime"
    )
    biom_bin = (
        str(Path(_agent.QIIME2_CONDA_BIN) / "biom")
        if _agent.QIIME2_CONDA_BIN and Path(_agent.QIIME2_CONDA_BIN).exists()
        else "biom"
    )

    cfg = plot_config or {}
    sample_preview = ", ".join(samples[:5]) + ("..." if len(samples) > 5 else "")

    lines = [
        "ã‚ãªãŸã¯QIIME2ã¨Pythonã‚’ä½¿ã£ãŸãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ è§£æã®å°‚é–€å®¶ã§ã™ã€‚",
        "ä»¥ä¸‹ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰QIIME2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã€",
        "è§£æãƒ»å¯è¦–åŒ–ã¾ã§è¡Œã†å®Œå…¨ãªPythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’1ã¤æ›¸ã„ã¦ãã ã•ã„ã€‚",
        "",
        "## QIIME2 å®Ÿè¡Œç’°å¢ƒ",
        f"qiime ã‚³ãƒãƒ³ãƒ‰: {qiime_bin}",
        f"biom ã‚³ãƒãƒ³ãƒ‰: {biom_bin}",
        "",
        "## ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«",
        f"ãƒ‘ã‚¹: {manifest_path}",
        "å½¢å¼: PairedEndFastqManifestPhred33V2ï¼ˆã‚¿ãƒ–åŒºåˆ‡ã‚Šã€ãƒ˜ãƒƒãƒ€: sample-id / forward-absolute-filepath / reverse-absolute-filepathï¼‰",
        f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(samples)}",
        f"ã‚µãƒ³ãƒ—ãƒ«IDä¾‹: {sample_preview}",
        "",
    ]

    if metadata_path:
        lines += [
            "## ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«",
            f"ãƒ‘ã‚¹: {metadata_path}",
            "(sample-id åˆ—ã¨ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚’å«ã‚€ TSV)",
            "",
        ]

    lines += [
        f"## å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}",
        f"## å›³ã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {figure_dir}",
        f"## DPI: {cfg.get('dpi', 150)}",
        f"## figsize: {cfg.get('figsize', [10, 6])}",
        "",
        "## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚",
        user_prompt if user_prompt.strip() else (
            "å±ãƒ¬ãƒ™ãƒ«ç›¸å¯¾å­˜åœ¨é‡ã®ç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ã€Shannon Î±å¤šæ§˜æ€§ã€Bray-Curtis PCoA ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        ),
        "",
        "## ã‚³ãƒ¼ãƒ‰ã®è¦ä»¶",
        "- import matplotlib; matplotlib.use('Agg') ã‚’æœ€åˆã«æ›¸ã",
        "- QIIME2 ã‚³ãƒãƒ³ãƒ‰ã¯ subprocess.run([qiime_cmd, ...], check=True, capture_output=True, text=True) ã§å®Ÿè¡Œã™ã‚‹",
        "  ä¾‹: result = subprocess.run(['/path/to/qiime', 'tools', 'import', ...], check=True, capture_output=True, text=True)",
        "- å„ã‚¹ãƒ†ãƒƒãƒ—ã® returncode != 0 ã®ã¨ã stderr ã‚’è¡¨ç¤ºã—ã¦ sys.exit(1) ã§åœæ­¢ã™ã‚‹",
        "- å›³ã¯ plt.savefig() ã§ä¿å­˜ã— plt.show() ã¯ä½¿ã‚ãªã„",
        "- ã‚¿ã‚¤ãƒˆãƒ«ãƒ»ãƒ©ãƒ™ãƒ«ã¯è‹±èªã§æ›¸ãï¼ˆæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä¾å­˜ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰",
        "- ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’å‡ºåŠ›ã™ã‚‹ã€‚èª¬æ˜æ–‡ã¯ä¸è¦",
        "- ã‚³ãƒ¼ãƒ‰ã¯ ```python ... ``` ã§å›²ã‚€",
        "",
        "## QIIME2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ¨å¥¨ãƒ•ãƒ­ãƒ¼",
        "1. qiime tools import ã§ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ",
        "   --type 'SampleData[PairedEndSequencesWithQuality]'",
        "   --input-format PairedEndFastqManifestPhred33V2",
        "2. qiime dada2 denoise-paired ã§ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°",
        "   æ¨å¥¨: --p-trim-left-f 0 --p-trim-left-r 0 --p-trunc-len-f 250 --p-trunc-len-r 200 --p-n-threads 0",
        "3. qiime taxa collapse --p-level 6 ã§å±ãƒ¬ãƒ™ãƒ«ã«é›†ç´„",
        "4. qiime tools export ã§ feature-table.biom ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
        "5. biom convert -i feature-table.biom -o feature-table.tsv --to-tsv ã§TSVã«å¤‰æ›",
        "6. pandasã§TSVã‚’èª­ã¿è¾¼ã‚“ã§ç›¸å¯¾å­˜åœ¨é‡ã‚’è¨ˆç®—ãƒ»matplotlib ã§å¯è¦–åŒ–",
        "7. å¤šæ§˜æ€§è§£æãŒå¿…è¦ãªå ´åˆã¯ qiime diversity core-metrics-phylogenetic ãªã©ã‚’ä½¿ç”¨",
    ]

    return "\n".join(lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚³ãƒ¼ãƒ‰æŠ½å‡º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _extract_code(content: str) -> str:
    """LLM ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ Python ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºã™ã‚‹"""
    # ```python ... ``` ã¾ãŸã¯ ``` ... ```
    match = re.search(r'```(?:python)?\s*([\s\S]*?)```', content)
    if match:
        return match.group(1).strip()
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: import ã‹ã‚‰å§‹ã¾ã‚‹è¡Œä»¥é™
    for i, line in enumerate(content.splitlines()):
        if line.strip().startswith(("import ", "from ")):
            return "\n".join(content.splitlines()[i:]).strip()
    return content.strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _run_code(
    code: str,
    output_dir: str,
    figure_dir: str,
    log_callback: Optional[Callable[[str], None]] = None,
) -> tuple:
    """
    ã‚³ãƒ¼ãƒ‰ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚“ã§ QIIME2_PYTHON ã§å®Ÿè¡Œã™ã‚‹ã€‚
    æˆ»ã‚Šå€¤: (success: bool, stdout: str, stderr: str, new_figures: list[str])
    """
    py_exec = _agent.QIIME2_PYTHON
    if not py_exec or not Path(py_exec).exists():
        py_exec = sys.executable

    fig_dir = Path(figure_dir)
    fig_dir.mkdir(parents=True, exist_ok=True)

    # å®Ÿè¡Œå‰ã®å›³ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
    existing = set(fig_dir.glob("*.png")) | set(fig_dir.glob("*.pdf")) | set(fig_dir.glob("*.svg"))

    with tempfile.NamedTemporaryFile(
        mode='w', suffix='.py', delete=False, encoding='utf-8'
    ) as f:
        f.write(code)
        tmp_path = f.name

    try:
        proc = subprocess.run(
            [py_exec, tmp_path],
            capture_output=True,
            text=True,
            timeout=300,
            cwd=output_dir,
        )

        if log_callback:
            for line in proc.stdout.splitlines():
                log_callback(line)
            if proc.stderr:
                for line in proc.stderr.splitlines()[:20]:
                    log_callback(f"[stderr] {line}")

        new_figs = sorted(
            (set(fig_dir.glob("*.png")) | set(fig_dir.glob("*.pdf")) | set(fig_dir.glob("*.svg")))
            - existing
        )
        return (
            proc.returncode == 0,
            proc.stdout,
            proc.stderr,
            [str(f) for f in new_figs],
        )
    finally:
        try:
            Path(tmp_path).unlink()
        except Exception:
            pass


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ModuleNotFoundError æ¤œå‡º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_PIP_NAME_MAP = {
    "sklearn": "scikit-learn",
    "skbio":   "scikit-bio",
    "Bio":     "biopython",
    "cv2":     "opencv-python",
    "PIL":     "Pillow",
}

def _detect_missing_module(stderr: str) -> Optional[str]:
    """stderr ã‹ã‚‰ ModuleNotFoundError ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã‚’æŠ½å‡ºã™ã‚‹"""
    match = re.search(r"No module named '([^']+)'", stderr)
    if match:
        mod = match.group(1).split(".")[0]
        return _PIP_NAME_MAP.get(mod, mod)
    return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# pip ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def pip_install(
    package: str,
    log_callback: Optional[Callable[[str], None]] = None,
) -> bool:
    """QIIME2 conda ç’°å¢ƒã® pip ã§ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹"""
    conda_bin = _agent.QIIME2_CONDA_BIN
    if conda_bin and Path(conda_bin).exists():
        pip_exec = str(Path(conda_bin) / "pip")
    else:
        pip_exec = str(Path(sys.executable).parent / "pip")

    if log_callback:
        log_callback(f"[pip] ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­: {package}")

    proc = subprocess.run(
        [pip_exec, "install", package],
        capture_output=True, text=True, timeout=180,
    )
    if log_callback:
        for line in proc.stdout.splitlines()[-3:]:
            log_callback(f"[pip] {line}")
        if proc.returncode != 0:
            for line in proc.stderr.splitlines()[-5:]:
                log_callback(f"[pip error] {line}")
    return proc.returncode == 0


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_code_agent(
    export_files: dict,
    user_prompt: str,
    output_dir: str,
    figure_dir: str,
    metadata_path: str = "",
    model: Optional[str] = None,
    max_retries: int = 3,
    plot_config: Optional[dict] = None,
    log_callback: Optional[Callable[[str], None]] = None,
    install_callback: Optional[Callable[[str], bool]] = None,
) -> CodeExecutionResult:
    """
    LLM ã§ Python è§£æã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆãƒ»å®Ÿè¡Œã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚

    Parameters
    ----------
    export_files : dict
        pipeline_runner.get_exported_files() ã®æˆ»ã‚Šå€¤
    user_prompt : str
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è§£ææŒ‡ç¤ºï¼ˆè‡ªç„¶è¨€èªï¼‰
    output_dir : str
        ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    figure_dir : str
        å›³ã®ä¿å­˜å…ˆ
    model : str, optional
        Ollama ãƒ¢ãƒ‡ãƒ«åï¼ˆNone ãªã‚‰ DEFAULT_MODELï¼‰
    max_retries : int
        ã‚¨ãƒ©ãƒ¼æ™‚ã®æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 3ï¼‰
    install_callback : (pkg: str) -> bool, optional
        ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«è¨±å¯ã‚’æ±‚ã‚ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
        True ã‚’è¿”ã™ã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Ÿè¡Œã€‚
        None ã®å ´åˆã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãªã„ã€‚
    """
    if model is None:
        model = _agent.DEFAULT_MODEL

    def _log(msg: str):
        if log_callback:
            log_callback(msg)

    _log("LLM ã«ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚’ä¾é ¼ä¸­...")

    # â”€â”€ STEP 1: åˆå›ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    system_msg = {
        "role": "system",
        "content": (
            "You are a microbiome analysis expert. "
            "Generate only Python code without any explanation. "
            "Wrap code in ```python ... ```."
        ),
    }
    user_msg = {
        "role": "user",
        "content": _build_prompt(
            export_files, user_prompt, figure_dir, metadata_path, plot_config
        ),
    }
    messages = [system_msg, user_msg]

    try:
        response = _agent.call_ollama(messages, model)
    except Exception as e:
        return CodeExecutionResult(
            success=False,
            error_message=f"Ollama æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}",
        )

    code = _extract_code(response.get("content", ""))
    if not code:
        return CodeExecutionResult(
            success=False,
            error_message="LLM ãŒã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã›ã‚“ã§ã—ãŸ",
        )
    _log(f"ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº† ({len(code.splitlines())} è¡Œ)")

    # â”€â”€ STEP 2: å®Ÿè¡Œ + ãƒªãƒˆãƒ©ã‚¤ãƒ«ãƒ¼ãƒ— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    last_code = code
    last_stderr = ""

    for attempt in range(max_retries + 1):
        _log(f"ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œä¸­... (è©¦è¡Œ {attempt + 1}/{max_retries + 1})")

        success, stdout, stderr, new_figs = _run_code(
            last_code, output_dir, figure_dir, log_callback
        )

        if success and new_figs:
            _log(f"å®Ÿè¡ŒæˆåŠŸã€‚ç”Ÿæˆã•ã‚ŒãŸå›³: {len(new_figs)} ä»¶")
            return CodeExecutionResult(
                success=True,
                stdout=stdout,
                stderr=stderr,
                code=last_code,
                figures=new_figs,
                retry_count=attempt,
            )

        if success and not new_figs:
            # exit 0 ã ãŒå›³ãŒç”Ÿæˆã•ã‚Œã¦ã„ãªã„ â†’ try/except ã«ã‚ˆã‚‹ silent failure ã‚’ç–‘ã†
            _log("âš ï¸  exit 0 ã ãŒå›³ãŒæœªç”Ÿæˆã€‚ã‚µã‚¤ãƒ¬ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼ã¨ã—ã¦å†è©¦è¡Œã—ã¾ã™ã€‚")
            last_stderr = (
                "Script exited with code 0 but NO figures were saved to FIGURE_DIR.\n"
                "This usually means an error was silently caught by a try/except block.\n"
                f"Script stdout (look for 'Error:' lines):\n{stdout[:800]}\n\n"
                "Fix: remove broad except clauses (or re-raise), and ensure "
                "plt.savefig() is actually executed with the correct FIGURE_DIR path."
            )
        else:
            last_stderr = stderr

        # ModuleNotFoundError ã®å‡¦ç†
        missing_pkg = _detect_missing_module(stderr)
        if missing_pkg:
            _log(f"æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’æ¤œå‡º: {missing_pkg}")
            approved = install_callback(missing_pkg) if install_callback else False
            if approved:
                ok = pip_install(missing_pkg, log_callback)
                if ok:
                    _log(f"{missing_pkg} ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†ã€‚å†å®Ÿè¡Œã—ã¾ã™ã€‚")
                    continue   # åŒã˜ã‚³ãƒ¼ãƒ‰ã§å†å®Ÿè¡Œï¼ˆã‚³ãƒ¼ãƒ‰ä¿®æ­£ä¸è¦ï¼‰
            else:
                _log(f"{missing_pkg} ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

        if attempt >= max_retries:
            break

        # LLM ã«ã‚¨ãƒ©ãƒ¼ã‚’æ¸¡ã—ã¦ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã‚’ä¾é ¼
        _log(f"ã‚¨ãƒ©ãƒ¼ã‚’ LLM ã«æ¸¡ã—ã¦ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã‚’ä¾é ¼ä¸­...")
        messages.append({
            "role": "assistant",
            "content": f"```python\n{last_code}\n```",
        })
        messages.append({
            "role": "user",
            "content": (
                f"The code produced the following error:\n"
                f"```\n{stderr[:1500]}\n```\n\n"
                f"Please fix the code and output the complete corrected version "
                f"wrapped in ```python ... ```."
            ),
        })

        try:
            fix_response = _agent.call_ollama(messages, model)
        except Exception as e:
            _log(f"Ollama æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            break

        fixed = _extract_code(fix_response.get("content", ""))
        if fixed:
            last_code = fixed
            _log(f"ä¿®æ­£æ¸ˆã¿ã‚³ãƒ¼ãƒ‰å—ä¿¡ ({len(last_code.splitlines())} è¡Œ)")
        else:
            _log("ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            break

    return CodeExecutionResult(
        success=False,
        stdout="",
        stderr=last_stderr,
        code=last_code,
        figures=[],
        retry_count=max_retries,
        error_message=last_stderr[:500],
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆAuto Agentï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class AutoAgentResult:
    """è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œçµæœ"""
    rounds: list = field(default_factory=list)       # list[CodeExecutionResult]
    total_figures: list = field(default_factory=list)
    completed: bool = False                           # ANALYSIS_COMPLETE ã‚’å—ä¿¡ã—ãŸã‹


def _build_auto_initial_prompt(
    export_files: dict,
    figure_dir: str,
    metadata_path: str = "",
    plot_config: Optional[dict] = None,
) -> str:
    """è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨ã®åˆå›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡ç¤ºãªã—ãƒ»AI ãŒè¨ˆç”»ç«‹æ¡ˆï¼‰"""
    cfg     = plot_config or {}
    dpi     = cfg.get("dpi", 150)
    figsize = cfg.get("figsize", [10, 6])

    lines = [
        "You are an autonomous microbiome bioinformatics analysis agent.",
        "Analyze the QIIME2-exported data listed below, one analysis per round.",
        "",
        "## PROTOCOL",
        "- Each response: write EXACTLY ONE complete Python script in ```python ... ```.",
        "- After the script runs you receive the result and plan the next analysis.",
        "- When you have completed a comprehensive suite, respond with: ANALYSIS_COMPLETE",
        "",
        "## Recommended analysis plan (adapt to available files; skip if file unavailable):",
        "  Round 1  â€” Data quality: per-sample read depth bar + ASV frequency histogram",
        "  Round 2  â€” Denoising stats: inputâ†’filteredâ†’denoisedâ†’mergedâ†’non-chimeric (if available)",
        "  Round 3  â€” Phylum-level stacked bar chart (relative abundance)",
        "  Round 4  â€” Genus-level stacked bar chart (top 15 genera + 'Other')",
        "  Round 5  â€” Genus heatmap (top 25 genera Ã— samples, z-score, seaborn clustermap)",
        "  Round 6  â€” Top 10 genus box plots (abundance distribution across samples)",
        "  Round 7  â€” Alpha diversity: Shannon + Observed features box/violin plots",
        "  Round 8  â€” Alpha rarefaction curves (subsample feature table at 10 depths)",
        "  Round 9  â€” Beta PCoA: ALL available distance matrices (Bray-Curtis, Jaccard, UniFrac)",
        "  Round 10 â€” PCA on CLR-transformed feature table (sklearn PCA, biplot if possible)",
        "  Round 11 â€” NMDS ordination (Bray-Curtis, metric=False, print stress in title)",
        "  Round 12 â€” Sample-to-sample Spearman correlation heatmap (genus-level)",
        "",
        "## Available files",
    ]
    for category, paths in export_files.items():
        for p in paths:
            lines.append(f"  [{category}] {p}")
    if metadata_path:
        lines.append(f"  [metadata] {metadata_path}")

    lines += [
        "",
        f"## Figure output directory : {figure_dir}",
        f"## DPI: {dpi}    figsize: {figsize}",
        "",
        "## FILE FORMATS â€” read exactly as described",
        "",
        "### [feature_table] feature-table.tsv  (QIIME2 biom export)",
        "  - Line 1  : '# Constructed from biom file'  â† comment, SKIP",
        "  - Line 2  : '#OTU ID\\t<sample1>\\t<sample2>...'  â† use as header",
        "  - Read:   ft = pd.read_csv(path, sep='\\t', skiprows=1, index_col=0)",
        "  - ft shape: (n_features Ã— n_samples)",
        "",
        "### [taxonomy] taxonomy.tsv",
        "  - Columns : Feature ID (index) | Taxon | Confidence",
        "  - Phylum  : tax['phylum'] = tax['Taxon'].str.extract(r'p__([^;]+)').fillna('Unknown').str.strip()",
        "  - Genus   : tax['genus']  = tax['Taxon'].str.extract(r'g__([^;]+)').fillna('Unknown').str.strip()",
        "",
        "### [alpha] alpha-diversity TSV (one file per metric)",
        "  - Columns : sample-id (index) | metric value",
        "  - Read:   alpha = pd.read_csv(path, sep='\\t', index_col=0)",
        "  - Metric name is in the column after the index; get it with: col = alpha.columns[0]",
        "  - Multiple files may exist: shannon, observed_features, chao1, faith_pd â€” use all",
        "",
        "### [beta] distance-matrix TSV (one file per metric)",
        "  - Square symmetric matrix; row names = column names = sample IDs",
        "  - Read:   dm = pd.read_csv(path, sep='\\t', index_col=0)",
        "  - Multiple files: bray_curtis, jaccard, unweighted_unifrac, weighted_unifrac â€” use all",
        "",
        "### [denoising] denoising-stats.tsv",
        "  - Columns: sample-id (index) | input | filtered | denoised | merged | non-chimeric",
        "  - Read:   stats = pd.read_csv(path, sep='\\t', index_col=0)",
        "",
        "## ANALYSIS METHOD REFERENCE",
        "",
        "### PCA (Principal Component Analysis) on feature table",
        "  # CLR (center log-ratio) transform to handle compositional data",
        "  ra = ft.div(ft.sum(axis=0), axis=1)           # relative abundance (features Ã— samples)",
        "  clr = np.log(ra.T + 1e-6)                     # samples Ã— features, add pseudocount",
        "  clr = clr - clr.mean(axis=1).values[:,None]   # center each sample",
        "  from sklearn.decomposition import PCA",
        "  pca = PCA(n_components=2)",
        "  coords = pca.fit_transform(clr)                # shape: (n_samples, 2)",
        "  # variance explained: pca.explained_variance_ratio_",
        "",
        "### PCoA (Principle Coordinate Analysis) â€” metric MDS on distance matrix",
        "  from sklearn.manifold import MDS",
        "  pcoa = MDS(n_components=2, dissimilarity='precomputed', metric=True, random_state=42)",
        "  coords = pcoa.fit_transform(dm.values)         # shape: (n_samples, 2)",
        "",
        "### NMDS (Non-Metric Multidimensional Scaling)",
        "  nmds = MDS(n_components=2, dissimilarity='precomputed', metric=False,",
        "             random_state=42, max_iter=500, n_init=4)",
        "  coords = nmds.fit_transform(dm.values)",
        "  stress = nmds.stress_   # print in plot title (good if < 0.2)",
        "",
        "### Rarefaction curve (subsample simulation)",
        "  import numpy as np",
        "  min_depth = int(ft.sum(axis=0).min())",
        "  depths = np.linspace(100, min_depth, 10).astype(int)",
        "  mean_richness = []",
        "  for d in depths:",
        "      sub = ft.apply(lambda c: pd.Series(",
        "          np.random.multinomial(d, c/c.sum()) if c.sum() >= d else c.values,",
        "          index=c.index), axis=0)",
        "      mean_richness.append((sub > 0).sum(axis=0).mean())",
        "",
        "### Phylum / Genus aggregation from feature_table + taxonomy",
        "  # merge on Feature ID index, then groupby",
        "  merged = ft.join(tax[['genus']], how='left')",
        "  merged['genus'] = merged['genus'].fillna('Unknown')",
        "  genus_table = merged.groupby('genus').sum()   # shape: (n_genera Ã— n_samples)",
        "  rel = genus_table.div(genus_table.sum(axis=0), axis=1)  # relative abundance",
        "  top15 = rel.sum(axis=1).nlargest(15).index",
        "  plot_data = rel.loc[top15].T                  # shape: (n_samples Ã— 15)",
        "",
        "## Code requirements",
        "1. First two lines MUST be:",
        "      import matplotlib",
        "      matplotlib.use('Agg')",
        "2. Define at the top:",
        f"      FIGURE_DIR = r'{figure_dir}'",
        f"      DPI = {dpi}",
        "      import os; os.makedirs(FIGURE_DIR, exist_ok=True)",
        "3. Include the round number in every filename: e.g. 'round1_summary.png'",
        "4. Save and close every figure:",
        "      plt.savefig(os.path.join(FIGURE_DIR, 'roundN_name.png'), dpi=DPI, bbox_inches='tight')",
        "      plt.close()",
        "5. All labels, titles, legend entries in English.",
        "6. try/except around each major section â€” one failure must not stop other sections.",
        "7. No plt.show().",
        "",
        "## Begin: write code for Round 1 now.",
    ]
    return "\n".join(lines)


def run_auto_agent(
    export_files: dict,
    output_dir: str,
    figure_dir: str,
    metadata_path: str = "",
    model: Optional[str] = None,
    max_rounds: int = 6,
    plot_config: Optional[dict] = None,
    log_callback: Optional[Callable[[str], None]] = None,
    install_callback: Optional[Callable[[str], bool]] = None,
) -> AutoAgentResult:
    """
    è‡ªå¾‹çš„ã«è§£æã‚’é€²ã‚ã‚‹ AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚

    LLM ãŒè§£æè¨ˆç”»ã‚’è‡ªã‚‰ç«‹ã¦ã€ãƒ©ã‚¦ãƒ³ãƒ‰ã”ã¨ã«ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆãƒ»å®Ÿè¡Œã—ã€
    çµæœã‚’å—ã‘å–ã£ã¦æ¬¡ã®è§£æã‚’æ±ºã‚ã‚‹ã€‚
    ã€ŒANALYSIS_COMPLETEã€ã‚’å—ä¿¡ã™ã‚‹ã‹ max_rounds ã«é”ã—ãŸã‚‰çµ‚äº†ã€‚
    """
    if model is None:
        model = _agent.DEFAULT_MODEL

    def _log(msg: str):
        if log_callback:
            log_callback(msg)

    results: list = []
    all_figures: list = []

    messages = [
        {
            "role": "system",
            "content": (
                "You are an autonomous microbiome analysis agent. "
                "Each response must contain ONE complete Python script in ```python...``` "
                "OR the text ANALYSIS_COMPLETE when all analyses are done."
            ),
        },
        {
            "role": "user",
            "content": _build_auto_initial_prompt(
                export_files, figure_dir, metadata_path, plot_config
            ),
        },
    ]

    for round_n in range(1, max_rounds + 1):
        _log(f"\n{'â”€' * 44}")
        _log(f"  ğŸ¤– Round {round_n} / {max_rounds}")
        _log(f"{'â”€' * 44}")
        _log("æ¬¡ã®è§£æã‚’è¨ˆç”»ä¸­...")

        try:
            response = _agent.call_ollama(messages, model)
        except Exception as e:
            _log(f"Ollama ã‚¨ãƒ©ãƒ¼: {e}")
            break

        content = response.get("content", "")

        # çµ‚äº†å®£è¨€
        if "ANALYSIS_COMPLETE" in content:
            _log("âœ… AI ãŒå…¨è§£æå®Œäº†ã¨åˆ¤æ–­ã—ã¾ã—ãŸã€‚")
            return AutoAgentResult(
                rounds=results, total_figures=all_figures, completed=True
            )

        code = _extract_code(content)
        if not code:
            _log("ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ç¶šè¡Œã‚’ä¿ƒã—ã¾ã™ã€‚")
            messages.append({"role": "assistant", "content": content})
            messages.append({
                "role": "user",
                "content": (
                    "No Python code was found in your response. "
                    "Please write the next analysis as a complete Python script "
                    "in ```python...``` or respond with ANALYSIS_COMPLETE."
                ),
            })
            continue

        _log(f"ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº† ({len(code.splitlines())} è¡Œ)")

        # â”€â”€ å®Ÿè¡Œ + ãƒªãƒˆãƒ©ã‚¤ï¼ˆæœ€å¤§ 3 å›ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        last_code   = code
        last_stderr = ""
        round_success = False
        new_figs: list = []

        for attempt in range(3):
            _log(f"å®Ÿè¡Œä¸­... (è©¦è¡Œ {attempt + 1}/3)")
            success, stdout, stderr, figs = _run_code(
                last_code, output_dir, figure_dir, log_callback
            )

            if success:
                round_success = True
                new_figs = figs
                break

            last_stderr = stderr

            # ModuleNotFoundError å‡¦ç†
            missing_pkg = _detect_missing_module(stderr)
            if missing_pkg:
                _log(f"æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: {missing_pkg}")
                approved = install_callback(missing_pkg) if install_callback else False
                if approved and pip_install(missing_pkg, log_callback):
                    continue

            if attempt < 2:
                _log("LLM ã«ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã‚’ä¾é ¼ä¸­...")
                fix_msgs = messages + [
                    {"role": "assistant", "content": f"```python\n{last_code}\n```"},
                    {
                        "role": "user",
                        "content": (
                            f"Error:\n```\n{stderr[:1000]}\n```\n"
                            "Fix and return the complete corrected code in ```python...```."
                        ),
                    },
                ]
                try:
                    fix_resp = _agent.call_ollama(fix_msgs, model)
                    fixed = _extract_code(fix_resp.get("content", ""))
                    if fixed:
                        last_code = fixed
                        _log(f"ä¿®æ­£æ¸ˆã¿ã‚³ãƒ¼ãƒ‰å—ä¿¡ ({len(last_code.splitlines())} è¡Œ)")
                except Exception:
                    pass

        # â”€â”€ ãƒ©ã‚¦ãƒ³ãƒ‰çµæœã‚’è¨˜éŒ² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        results.append(CodeExecutionResult(
            success=round_success,
            stdout="",
            stderr=last_stderr,
            code=last_code,
            figures=new_figs,
            retry_count=0,
            error_message=last_stderr[:300] if not round_success else "",
        ))
        all_figures.extend(new_figs)

        if round_success:
            _log(f"âœ… Round {round_n} æˆåŠŸ")
            if new_figs:
                _log(f"ğŸ“Š å›³ã‚’ä¿å­˜: {[Path(f).name for f in new_figs]}")
            status_line = f"Round {round_n} succeeded."
            if new_figs:
                status_line += f" New figures saved: {[Path(f).name for f in new_figs]}."
        else:
            _log(f"âŒ Round {round_n} å¤±æ•—")
            status_line = f"Round {round_n} failed. Error: {last_stderr[:200]}"

        all_names = [Path(f).name for f in all_figures]
        messages.append({"role": "assistant", "content": content})
        messages.append({
            "role": "user",
            "content": (
                f"{status_line}\n"
                f"All figures generated so far: {all_names}\n\n"
                f"Proceed with Round {round_n + 1}, "
                f"or respond ANALYSIS_COMPLETE if done."
            ),
        })

    return AutoAgentResult(rounds=results, total_figures=all_figures, completed=False)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tool-Calling Coding Agentï¼ˆvibe-local ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â”€â”€ ãƒ„ãƒ¼ãƒ«å®šç¾©ï¼ˆOllama /api/chat ã«æ¸¡ã™ JSON ã‚¹ã‚­ãƒ¼ãƒï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_TOOL_DEFS = [
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": (
                "Read a file's contents. ALWAYS call this before writing analysis code "
                "to understand the exact column names, header structure, and data format."
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "Absolute path to the file",
                    },
                    "max_lines": {
                        "type": "integer",
                        "description": "Maximum lines to return (default 100)",
                    },
                },
                "required": ["path"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "write_file",
            "description": (
                "Write content to a file (creates or overwrites). "
                "Use to create Python analysis scripts."
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "Absolute path of the file to write",
                    },
                    "content": {
                        "type": "string",
                        "description": "Full content to write",
                    },
                },
                "required": ["path", "content"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "run_python",
            "description": (
                "Execute a Python script file. Returns stdout, stderr, and exit code. "
                "If it fails, immediately call write_file to fix the script, "
                "then call run_python again â€” repeat until exit code is 0."
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "Absolute path to the .py file to execute",
                    },
                },
                "required": ["path"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "list_files",
            "description": "List files in a directory, optionally filtered by glob pattern.",
            "parameters": {
                "type": "object",
                "properties": {
                    "directory": {
                        "type": "string",
                        "description": "Directory path to list",
                    },
                    "pattern": {
                        "type": "string",
                        "description": "Glob pattern to filter (e.g. '*.tsv', '*.png'). Defaults to '*'.",
                    },
                },
                "required": ["directory"],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "install_package",
            "description": (
                "Install a Python package via pip. "
                "Use only when run_python fails with ModuleNotFoundError."
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "package": {
                        "type": "string",
                        "description": "Package name to install (e.g. 'scikit-learn', 'seaborn')",
                    },
                },
                "required": ["package"],
            },
        },
    },
]


def _exec_tool(
    tool_name: str,
    tool_args: dict,
    output_dir: str,
    figure_dir: str,
    log_callback: Optional[Callable[[str], None]],
    install_callback: Optional[Callable[[str], bool]],
) -> tuple:
    """
    ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    æˆ»ã‚Šå€¤: (result_str: str, new_figures: list[str])
    """
    def _log(msg: str):
        if log_callback:
            log_callback(msg)

    # â”€â”€ read_file â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if tool_name == "read_file":
        path = tool_args.get("path", "")
        max_lines = int(tool_args.get("max_lines", 100))
        try:
            with open(path, encoding="utf-8", errors="replace") as f:
                lines = f.readlines()
            truncated = len(lines) > max_lines
            content = "".join(lines[:max_lines])
            if truncated:
                content += f"\n... ({len(lines) - max_lines} more lines truncated)"
            _log(f"  â† read {Path(path).name} ({len(lines)} lines)")
            return content or "(empty file)", []
        except FileNotFoundError:
            return f"ERROR: file not found: {path}", []
        except Exception as e:
            return f"ERROR reading {path}: {e}", []

    # â”€â”€ write_file â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif tool_name == "write_file":
        path = tool_args.get("path", "")
        content = tool_args.get("content", "")
        try:
            p = Path(path)
            p.parent.mkdir(parents=True, exist_ok=True)
            # ã‚¢ãƒˆãƒŸãƒƒã‚¯æ›¸ãè¾¼ã¿ï¼ˆã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚»ãƒ¼ãƒ•ï¼‰
            with tempfile.NamedTemporaryFile(
                mode="w", suffix=".tmp",
                dir=p.parent, delete=False, encoding="utf-8",
            ) as f:
                f.write(content)
                tmp = f.name
            Path(tmp).replace(path)
            n = len(content.splitlines())
            _log(f"  â† wrote {Path(path).name} ({n} lines)")
            return f"OK: wrote {n} lines to {path}", []
        except Exception as e:
            return f"ERROR writing {path}: {e}", []

    # â”€â”€ run_python â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif tool_name == "run_python":
        path = tool_args.get("path", "")
        py_exec = _agent.QIIME2_PYTHON
        if not py_exec or not Path(py_exec).exists():
            py_exec = sys.executable

        fig_dir = Path(figure_dir)
        fig_dir.mkdir(parents=True, exist_ok=True)
        before = (
            set(fig_dir.glob("*.png"))
            | set(fig_dir.glob("*.pdf"))
            | set(fig_dir.glob("*.svg"))
        )

        try:
            proc = subprocess.run(
                [py_exec, path],
                capture_output=True, text=True,
                timeout=300, cwd=output_dir,
            )
        except subprocess.TimeoutExpired:
            return "ERROR: execution timed out (300 seconds)", []
        except Exception as e:
            return f"ERROR launching process: {e}", []

        after = (
            set(fig_dir.glob("*.png"))
            | set(fig_dir.glob("*.pdf"))
            | set(fig_dir.glob("*.svg"))
        )
        new_figs = [str(f) for f in sorted(after - before)]

        parts = []
        if proc.stdout.strip():
            parts.append(f"STDOUT:\n{proc.stdout[:3000]}")
        if proc.returncode != 0 and proc.stderr.strip():
            parts.append(f"STDERR:\n{proc.stderr[:3000]}")
            if log_callback:
                for line in proc.stderr.splitlines()[:10]:
                    log_callback(f"    [err] {line}")
        parts.append(f"EXIT CODE: {proc.returncode}")
        if new_figs:
            parts.append(f"NEW FIGURES: {[Path(f).name for f in new_figs]}")
            _log(f"  â† ğŸ“Š {[Path(f).name for f in new_figs]}")

        _log(f"  â† run {Path(path).name} â†’ exit {proc.returncode}")
        return "\n".join(parts), new_figs

    # â”€â”€ list_files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif tool_name == "list_files":
        directory = tool_args.get("directory", "")
        pattern = tool_args.get("pattern", "*")
        try:
            files = sorted(Path(directory).glob(pattern))
            if not files:
                return f"(no files matching '{pattern}' in {directory})", []
            return "\n".join(str(f) for f in files), []
        except Exception as e:
            return f"ERROR: {e}", []

    # â”€â”€ install_package â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    elif tool_name == "install_package":
        package = tool_args.get("package", "")
        _log(f"  âš ï¸  ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ '{package}' ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒè¦æ±‚ã•ã‚Œã¾ã—ãŸ")
        approved = install_callback(package) if install_callback else False
        if not approved:
            return (
                f"DECLINED: user declined to install '{package}'. "
                "Try an alternative approach without this package.", []
            )
        ok = pip_install(package, log_callback)
        return (
            f"OK: installed {package}" if ok
            else f"ERROR: failed to install {package}"
        ), []

    else:
        return f"ERROR: unknown tool '{tool_name}'", []


def _parse_text_tool_calls(content: str) -> list:
    """
    tool_calls ãŒç©ºã®ã¨ãã€ãƒ†ã‚­ã‚¹ãƒˆ content ã‹ã‚‰ JSON ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’æŠ½å‡ºã™ã‚‹ã€‚
    qwen2.5-coder ç­‰ã€ãƒ„ãƒ¼ãƒ« API ã«éå¯¾å¿œãªãƒ¢ãƒ‡ãƒ«å‘ã‘ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚

    å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
      {"name": "...", "arguments": {...}}
      [{"name": "...", "arguments": {...}}, ...]
    """
    if not content:
        return []

    tool_calls = []

    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã— JSON ãŒè¤‡æ•°è¡Œã«ã‚ãŸã‚‹å ´åˆã‚‚å«ã‚å…¨ä½“ã‚’æ¤œç´¢
    # ```json ... ``` ãƒ–ãƒ­ãƒƒã‚¯å†…ã‚’å„ªå…ˆ
    for block in re.findall(r'```(?:json)?\s*([\s\S]*?)```', content):
        try:
            obj = json.loads(block.strip())
            items = obj if isinstance(obj, list) else [obj]
            for item in items:
                if isinstance(item, dict) and "name" in item and (
                    "arguments" in item or "parameters" in item
                ):
                    args = item.get("arguments") or item.get("parameters") or {}
                    tool_calls.append({
                        "function": {"name": item["name"], "arguments": args}
                    })
        except (json.JSONDecodeError, TypeError):
            pass

    if tool_calls:
        return tool_calls

    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: content å…¨ä½“ãŒ JSON (å˜ä¸€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—)
    try:
        obj = json.loads(content.strip())
        items = obj if isinstance(obj, list) else [obj]
        for item in items:
            if isinstance(item, dict) and "name" in item:
                args = item.get("arguments") or item.get("parameters") or {}
                tool_calls.append({
                    "function": {"name": item["name"], "arguments": args}
                })
        if tool_calls:
            return tool_calls
    except (json.JSONDecodeError, TypeError):
        pass

    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: ãƒ†ã‚­ã‚¹ãƒˆå†…ã«åŸ‹ã‚è¾¼ã¾ã‚ŒãŸ JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚¹ã‚­ãƒ£ãƒ³
    for match in re.finditer(r'\{[^{}]*"name"\s*:\s*"([^"]+)"[^{}]*\}', content):
        try:
            obj = json.loads(match.group(0))
            if "name" in obj:
                args = obj.get("arguments") or obj.get("parameters") or {}
                if isinstance(args, str):
                    try:
                        args = json.loads(args)
                    except Exception:
                        args = {}
                tool_calls.append({
                    "function": {"name": obj["name"], "arguments": args}
                })
        except (json.JSONDecodeError, TypeError):
            pass

    # ãƒ‘ã‚¿ãƒ¼ãƒ³4a: name ãªã— JSON ã‚’ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã§æ¨è«–
    # ãƒ¢ãƒ‡ãƒ«ãŒ {"path": "...", "content": "..."} ã‚’å‡ºåŠ›ã—ãŸå ´åˆã« write_file ã¨ã—ã¦è§£é‡ˆ
    if not tool_calls:
        try:
            obj = json.loads(content.strip())
            if isinstance(obj, dict) and "name" not in obj:
                if "path" in obj and "content" in obj:
                    tool_calls.append({"function": {"name": "write_file", "arguments": obj}})
                elif "path" in obj and str(obj.get("path", "")).endswith(".py"):
                    tool_calls.append({"function": {"name": "run_python", "arguments": obj}})
                elif "directory" in obj:
                    tool_calls.append({"function": {"name": "list_files", "arguments": obj}})
        except (json.JSONDecodeError, TypeError):
            pass

    if tool_calls:
        return tool_calls

    # ãƒ‘ã‚¿ãƒ¼ãƒ³4b: ```json ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã® name ãªã— JSON ã«ã‚‚åŒæ§˜ã«é©ç”¨
    if not tool_calls:
        for block in re.findall(r'```(?:json)?\s*([\s\S]*?)```', content):
            try:
                obj = json.loads(block.strip())
                if isinstance(obj, dict) and "name" not in obj:
                    if "path" in obj and "content" in obj:
                        tool_calls.append({"function": {"name": "write_file", "arguments": obj}})
                        break
                    elif "path" in obj and str(obj.get("path", "")).endswith(".py"):
                        tool_calls.append({"function": {"name": "run_python", "arguments": obj}})
                        break
                    elif "directory" in obj:
                        tool_calls.append({"function": {"name": "list_files", "arguments": obj}})
                        break
            except (json.JSONDecodeError, TypeError):
                pass

    if tool_calls:
        return tool_calls

    # ãƒ‘ã‚¿ãƒ¼ãƒ³4: å£Šã‚ŒãŸ JSON ã‚’å¯›å®¹ã«ãƒ‘ãƒ¼ã‚¹ï¼ˆname/arguments ã‚’æ­£è¦è¡¨ç¾ã§æŠ½å‡ºï¼‰
    if not tool_calls:
        m_name = re.search(r'"name"\s*:\s*"([^"]+)"', content)
        m_path = re.search(r'"path"\s*:\s*"([^"]+)"', content)
        m_dir  = re.search(r'"directory"\s*:\s*"([^"]+)"', content)
        m_pkg  = re.search(r'"package"\s*:\s*"([^"]+)"', content)
        if m_name:
            name = m_name.group(1)
            if name in ("read_file", "write_file", "run_python", "list_files", "install_package"):
                args: dict = {}
                if m_path:
                    args["path"] = m_path.group(1)
                if m_dir:
                    args["directory"] = m_dir.group(1)
                if m_pkg:
                    args["package"] = m_pkg.group(1)
                # write_file ã® content ã¯ JSON ç ´æã—ã‚„ã™ã„ã®ã§åˆ¥é€”æŠ½å‡º
                if name == "write_file" and '"content"' in content:
                    # content ã®é–‹å§‹ä½ç½®ã‚’ç‰¹å®š
                    cm = re.search(r'"content"\s*:\s*"', content)
                    if cm:
                        start = cm.end()
                        # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡¦ç†ã—ã¤ã¤ content ã‚’æŠ½å‡º
                        raw = content[start:]
                        extracted = []
                        i = 0
                        while i < len(raw):
                            c = raw[i]
                            if c == '\\' and i + 1 < len(raw):
                                nc = raw[i + 1]
                                if nc == 'n': extracted.append('\n')
                                elif nc == 't': extracted.append('\t')
                                elif nc == '"': extracted.append('"')
                                elif nc == '\\': extracted.append('\\')
                                else: extracted.append(c + nc)
                                i += 2
                            elif c == '"':
                                break  # content æ–‡å­—åˆ—ã®çµ‚ç«¯
                            else:
                                extracted.append(c)
                                i += 1
                        file_content = "".join(extracted)
                        if len(file_content) > 10:
                            args["content"] = file_content
                if args or name in ("list_files",):
                    tool_calls.append({"function": {"name": name, "arguments": args}})

    return tool_calls


def run_coding_agent(
    export_files: dict,
    user_prompt: str,
    output_dir: str,
    figure_dir: str,
    metadata_path: str = "",
    model: Optional[str] = None,
    max_steps: int = 30,
    log_callback: Optional[Callable[[str], None]] = None,
    install_callback: Optional[Callable[[str], bool]] = None,
) -> CodeExecutionResult:
    """
    vibe-local ã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—å‹ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚

    å¾“æ¥ã®ã€Œã‚¹ã‚¯ãƒªãƒ—ãƒˆä¸€æ‹¬ç”Ÿæˆâ†’å®Ÿè¡Œã€ã¨ç•°ãªã‚Šã€LLM ãŒ:
      1. list_files ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ç´¢
      2. read_file ã§ãƒ‡ãƒ¼ã‚¿ã®å®Ÿéš›ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç¢ºèª
      3. write_file ã§è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆ
      4. run_python ã§å®Ÿè¡Œ
      5. ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã‚‰ write_file ã§ä¿®æ­£ â†’ run_python ã‚’ç¹°ã‚Šè¿”ã™
    ã¨ã„ã†è‡ªå¾‹çš„ãªãƒ«ãƒ¼ãƒ—ã§ã€Œå¿…ãšå‹•ãã‚³ãƒ¼ãƒ‰ã€ã‚’ä½œã‚Šä¸Šã’ã‚‹ã€‚

    user_prompt ãŒç©ºã®å ´åˆã¯åŒ…æ‹¬çš„ãªè§£æã‚’è‡ªå¾‹å®Ÿè¡Œï¼ˆè‡ªå¾‹ãƒ¢ãƒ¼ãƒ‰ï¼‰ã€‚
    user_prompt ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯ãã®å†…å®¹ã«å¾“ã†ï¼ˆæŒ‡ç¤ºãƒ¢ãƒ¼ãƒ‰ï¼‰ã€‚
    """
    if model is None:
        model = _agent.DEFAULT_MODEL

    def _log(msg: str):
        if log_callback:
            log_callback(msg)

    # â”€â”€ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆvibe-local "TOOL FIRST" è¨­è¨ˆï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    system_content = "\n".join([
        "You are an autonomous microbiome bioinformatics coding agent.",
        "",
        "## CRITICAL RULES â€” follow exactly, no exceptions",
        "1. TOOL FIRST: Call a tool immediately. Never write explanations before acting.",
        "2. READ BEFORE CODING: Call read_file on data files before writing analysis code.",
        "   You MUST verify column names, delimiter, skiprows, and data structure â€” do not assume.",
        "3. NEVER GIVE UP: If run_python fails, diagnose STDERR, call write_file to fix,",
        "   then run_python again. Repeat until EXIT CODE: 0. Fix silently.",
        "4. COMPLETE SCRIPT: Write all analysis sections into one .py file.",
        "   Each section in a try/except block â€” one failure must not stop others.",
        "5. DONE WHEN FIGURES ARE SAVED: Stop calling tools when all requested figures",
        "   are saved in FIGURE_DIR. Respond with a brief summary of what was generated.",
        "",
        "## WORKFLOW",
        "Step 1 â†’ list_files to explore directories",
        "Step 2 â†’ read_file on each data file (100 lines is enough to understand format)",
        "Step 3 â†’ write_file to create analysis.py",
        "Step 4 â†’ run_python on analysis.py",
        "Step 5 â†’ If EXIT CODE != 0: read STDERR, write_file to fix, run_python again",
        "Step 6 â†’ Repeat Step 5 until EXIT CODE: 0",
        "",
        "## FILE FORMATS",
        "",
        "feature_table (feature-table.tsv):",
        "  Line 1: '# Constructed from biom file'  â† SKIP (skiprows=1)",
        "  Line 2: '#OTU ID\\t<sample1>\\t...'      â† header",
        "  ft = pd.read_csv(path, sep='\\t', skiprows=1, index_col=0)  # shape: features Ã— samples",
        "",
        "taxonomy (taxonomy.tsv):",
        "  Columns: Feature ID (index) | Taxon | Confidence",
        "  Phylum: tax['phylum'] = tax['Taxon'].str.extract(r'p__([^;]+)').fillna('Unknown').str.strip()",
        "  Genus:  tax['genus']  = tax['Taxon'].str.extract(r'g__([^;]+)').fillna('Unknown').str.strip()",
        "",
        "alpha-diversity TSV (one file per metric; metric name = first column after index):",
        "  alpha = pd.read_csv(path, sep='\\t', index_col=0)  # shape: samples Ã— 1",
        "  Possible metrics: shannon, observed_features, chao1, faith_pd â€” ALL available files",
        "",
        "beta distance-matrix TSV (one file per metric):",
        "  dm = pd.read_csv(path, sep='\\t', index_col=0)  # square symmetric, samples Ã— samples",
        "  Possible metrics: bray_curtis, jaccard, unweighted_unifrac, weighted_unifrac",
        "",
        "denoising-stats.tsv:",
        "  stats = pd.read_csv(path, sep='\\t', index_col=0)",
        "  Columns: input | filtered | denoised | merged | non-chimeric | passed filter",
        "",
        "## ANALYSIS IMPLEMENTATIONS",
        "",
        "Genus/phylum aggregation:",
        "  merged = ft.join(tax[['genus']], how='left').fillna({'genus': 'Unknown'})",
        "  genus_tbl = merged.groupby('genus').sum()              # features â†’ genus",
        "  rel = genus_tbl.div(genus_tbl.sum(axis=0), axis=1)    # relative abundance",
        "  top15 = rel.sum(axis=1).nlargest(15).index",
        "  others = rel.loc[~rel.index.isin(top15)].sum()",
        "  plot_df = rel.loc[top15].T                             # samples Ã— genera",
        "  plot_df['Other'] = others.values",
        "",
        "PCA (CLR-transformed):",
        "  ra = ft.div(ft.sum(axis=0), axis=1)                   # features Ã— samples",
        "  clr = np.log(ra.T + 1e-6)                             # samples Ã— features",
        "  clr = clr - clr.mean(axis=1).values[:, None]",
        "  from sklearn.decomposition import PCA",
        "  pca = PCA(n_components=2); coords = pca.fit_transform(clr)",
        "  # variance: pca.explained_variance_ratio_",
        "",
        "PCoA (metric MDS on distance matrix):",
        "  from sklearn.manifold import MDS",
        "  pcoa = MDS(n_components=2, dissimilarity='precomputed', metric=True, random_state=42)",
        "  coords = pcoa.fit_transform(dm.values)  # dm must be square float matrix",
        "",
        "NMDS (non-metric MDS):",
        "  nmds = MDS(n_components=2, dissimilarity='precomputed', metric=False,",
        "             random_state=42, max_iter=500, n_init=4)",
        "  coords = nmds.fit_transform(dm.values)",
        "  stress = round(nmds.stress_, 4)  # print in title; good < 0.2",
        "",
        "Rarefaction curves:",
        "  min_d = int(ft.sum(axis=0).min())",
        "  depths = np.linspace(100, min_d, 10).astype(int)",
        "  richness = []",
        "  for d in depths:",
        "      sub = ft.apply(lambda c: pd.Series(",
        "          np.random.multinomial(d, c/c.sum()) if c.sum()>=d else c.values,",
        "          index=c.index), axis=0)",
        "      richness.append((sub > 0).sum(axis=0).mean())",
        "",
        "## PYTHON SCRIPT TEMPLATE",
        "import matplotlib",
        "matplotlib.use('Agg')  # MUST be first",
        "import matplotlib.pyplot as plt",
        "import pandas as pd",
        "import numpy as np",
        "import os",
        f"FIGURE_DIR = r'{figure_dir}'",
        "DPI = 150",
        "os.makedirs(FIGURE_DIR, exist_ok=True)",
        "",
        "try:  # --- Section: figure name ---",
        "    # ... analysis code ...",
        "    plt.savefig(os.path.join(FIGURE_DIR, 'figNN_name.png'), dpi=DPI, bbox_inches='tight')",
        "    plt.close()",
        "    print('figNN saved')",
        "except Exception as e:",
        "    print(f'figNN failed: {e}')",
        "",
        "NEVER plt.show(). ALWAYS plt.savefig() + plt.close().",
        "Print 'figNN saved' on success so you can verify which figures were generated.",
        "",
        "## COMMON MISTAKES â€” avoid these",
        "- WRONG: from scipy.stats import boxplot  â† scipy.stats has NO boxplot",
        "  RIGHT:  plt.boxplot(data)  or  import seaborn; seaborn.boxplot(data=df)",
        "- WRONG: import biom  â† not available; use pd.read_csv() on .tsv files",
        "- WRONG: hardcoding data values â€” ALWAYS read from file paths in the task",
        "- WRONG: plt.show()  â† never; always plt.savefig() + plt.close()",
        "- TAXONOMY str.extract RETURNS DataFrame (not Series):",
        "  WRONG: tax['Taxon'].str.extract(r'g__([^;]+)').fillna('Unknown').str.strip()",
        "  RIGHT:  tax['Taxon'].str.extract(r'g__([^;]+)')[0].fillna('Unknown').str.strip()",
        "- DO NOT use bare except: print(e) â€” it hides errors and prevents figure generation.",
        "  Instead: write code without try/except, or use 'raise' inside except blocks.",
    ])

    # â”€â”€ åˆå›ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    file_lines = []
    for cat, paths in export_files.items():
        for p in paths:
            file_lines.append(f"  [{cat}] {p}")
    if metadata_path:
        file_lines.append(f"  [metadata] {metadata_path}")

    auto_task = "\n".join([
        "Perform a COMPREHENSIVE microbiome analysis.",
        "Write ALL figures to FIGURE_DIR. Skip any figure gracefully if required data is unavailable.",
        "",
        "## Phase 1 â€” Data Quality & Summary",
        "  fig01_read_depth.png    Per-sample total read counts (bar chart, sorted descending)",
        "  fig02_feature_hist.png  ASV/OTU frequency histogram (log x-axis, log y-axis)",
        "  fig03_denoising.png     DADA2 stats: grouped bar input/filtered/denoised/merged/non-chimeric",
        "                          (only if denoising file is available)",
        "",
        "## Phase 2 â€” Taxonomic Composition",
        "  fig04_phylum_bar.png    Phylum-level stacked bar (relative abundance, all phyla)",
        "  fig05_genus_bar.png     Genus-level stacked bar (top 15 genera + 'Other')",
        "  fig06_genus_heatmap.png Genus heatmap: top 25 genera Ã— samples, z-score per row,",
        "                          seaborn clustermap with hierarchical clustering",
        "  fig07_genus_boxplot.png Top 10 genus abundance box + strip plot across samples",
        "",
        "## Phase 3 â€” Alpha Diversity",
        "  fig08_alpha_multi.png   All available alpha metrics in subplots (Shannon, Observed,",
        "                          Chao1, Faith PD â€” include whichever files exist)",
        "  fig09_rarefaction.png   Rarefaction curves: mean observed features vs subsampling depth",
        "",
        "## Phase 4 â€” Beta Diversity Ordination",
        "  fig10_pcoa_all.png      PCoA for ALL available beta matrices in subplots",
        "                          (Bray-Curtis, Jaccard, unweighted/weighted UniFrac)",
        "  fig11_pca.png           PCA on CLR-transformed feature table; label axes with",
        "                          % variance explained; scatter + sample ID labels",
        "  fig12_nmds_bray.png     NMDS on Bray-Curtis (metric=False); show stress in title",
        "",
        "## Phase 5 â€” Sample Relationships & Summary",
        "  fig13_sample_corr.png   Sample-to-sample Spearman correlation heatmap (genus-level)",
        "  fig14_top_taxa_pie.png  Pie chart of mean relative abundance at genus level (top 10)",
        "",
        "Rules:",
        "- dpi=150, bbox_inches='tight', clear English axis labels, plt.close() after each figure",
        "- try/except around every figure section; print 'figXX saved' on success",
        "- For ordination figures with multiple matrices, use matplotlib subplots",
        "- Use seaborn color palettes for aesthetics when appropriate",
    ])
    task = user_prompt.strip() if user_prompt.strip() else auto_task

    initial_content = "\n".join([
        "## Available QIIME2-exported data files (exact paths)",
        *file_lines,
        "",
        f"## FIGURE_DIR: {figure_dir}",
        f"## Script path: {output_dir}/analysis.py",
        "",
        "## Your task",
        task,
        "",
        "## Start",
        "Call list_files first, then read_file on key data files, then write_file to create",
        f"analysis.py at {output_dir}/analysis.py, then call run_python to execute it.",
    ])

    messages = [
        {"role": "system", "content": system_content},
        {"role": "user",   "content": initial_content},
    ]

    all_figs: list = []
    final_code     = ""
    final_error    = ""
    success        = False
    total_steps    = 0
    _run_python_count = 0   # run_python ãŒå®Ÿè¡Œã•ã‚ŒãŸå›æ•°ï¼ˆé€²æ—ç¢ºèªç”¨ï¼‰

    _log("ğŸ¤– ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèµ·å‹•ï¼ˆtool-calling ãƒ¢ãƒ¼ãƒ‰ï¼‰")
    _log(f"   æœ€å¤§ {max_steps} ã‚¹ãƒ†ãƒƒãƒ—  |  Ctrl+C ã§ä¸­æ–­")
    _log("")

    for step in range(1, max_steps + 1):
        # â”€â”€ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¤å®š1: 5 ã‚¹ãƒ†ãƒƒãƒ—çµŒéã—ã¦ run_python ã™ã‚‰å‘¼ã°ã‚Œã¦ã„ãªã„ â”€â”€
        # â”€â”€ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ¤å®š2: run_python ã‚’ 3 å›ä»¥ä¸Šå‘¼ã‚“ã§ã‚‚å›³ãŒæœªç”Ÿæˆ â”€â”€
        if not all_figs and (
            (step == 6 and _run_python_count == 0)
            or (_run_python_count >= 3)
        ):
            _log("  âš ï¸  ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãƒ«ãƒ¼ãƒ—ãŒé€²æ—ã—ã¾ã›ã‚“ã€‚1ã‚·ãƒ§ãƒƒãƒˆç”Ÿæˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™...")
            fallback = run_code_agent(
                export_files=export_files,
                user_prompt=user_prompt,
                output_dir=output_dir,
                figure_dir=figure_dir,
                metadata_path=metadata_path,
                model=model,
                max_retries=3,
                log_callback=log_callback,
                install_callback=install_callback,
            )
            return fallback
        total_steps = step
        _log(f"[step {step}/{max_steps}] é€ä¿¡ä¸­...")

        try:
            response = _agent.call_ollama(messages, model, tools=_TOOL_DEFS)
        except KeyboardInterrupt:
            _log("\nâš ï¸  ä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
            break
        except Exception as e:
            _log(f"Ollama ã‚¨ãƒ©ãƒ¼: {e}")
            final_error = str(e)
            break

        content    = response.get("content", "")
        tool_calls = response.get("tool_calls", [])

        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¼šè©±å±¥æ­´ã«è¿½åŠ 
        assistant_msg: dict = {"role": "assistant", "content": content}
        if tool_calls:
            assistant_msg["tool_calls"] = tool_calls
        messages.append(assistant_msg)

        if not tool_calls:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ†ã‚­ã‚¹ãƒˆå†… JSON ã‚’ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã¨ã—ã¦è§£é‡ˆ
            parsed = _parse_text_tool_calls(content)
            if parsed:
                _log(f"  â„¹ï¸  ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã— {len(parsed)} ä»¶ã‚’è§£æã—ã¾ã—ãŸ")
                # assistant ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ tool_calls ä»˜ãã§ä¸Šæ›¸ã
                messages[-1]["tool_calls"] = parsed
                tool_calls = parsed
            else:
                # å›³ãŒã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ãªã„å ´åˆã¯ç¶™ç¶šã‚’ä¿ƒã™
                _ran_python = any(
                    m.get("role") == "tool" and m.get("name") == "run_python"
                    for m in messages
                )
                if not all_figs and not _ran_python and step < max_steps - 2:
                    if content:
                        _log(f"  â† ãƒ¢ãƒ‡ãƒ«å¿œç­”ï¼ˆãƒ‡ãƒ¼ã‚¿å‡ºåŠ›ã¨åˆ¤æ–­ï¼‰: {content[:80]}...")
                    _log("  â„¹ï¸  ã¾ã å›³ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆã‚’ä¿ƒã—ã¾ã™...")
                    messages.append({
                        "role": "user",
                        "content": (
                            "You have read the data. Now proceed to the next step:\n"
                            "1. Call write_file to create the analysis script at "
                            f"{output_dir}/analysis.py\n"
                            "2. Call run_python to execute it.\n"
                            "Do NOT output data or summaries â€” call write_file NOW."
                        ),
                    })
                    continue

                # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãªã— â†’ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå®Œäº†ã¨åˆ¤æ–­
                if content:
                    _log(f"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¿œç­”: {content[:300]}")
                _log("âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã—ã¾ã—ãŸã€‚")
                success = True
                break

        # â”€â”€ å„ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å®Ÿè¡Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for tc in tool_calls:
            fn         = tc.get("function", {})
            tool_name  = fn.get("name", "")
            raw_args   = fn.get("arguments", {})

            # arguments ãŒ JSON æ–‡å­—åˆ—ã§è¿”ã£ã¦ãã‚‹å ´åˆã«å¯¾å¿œ
            if isinstance(raw_args, str):
                try:
                    tool_args = json.loads(raw_args)
                except Exception:
                    tool_args = {}
            elif isinstance(raw_args, dict):
                tool_args = raw_args
            else:
                tool_args = {}

            # å¼•æ•°ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
            preview = ", ".join(
                f"{k}={repr(str(v))[:60]}" for k, v in tool_args.items()
            )
            _log(f"  ğŸ”§ {tool_name}({preview})")

            tool_result, new_figs = _exec_tool(
                tool_name, tool_args,
                output_dir, figure_dir,
                log_callback, install_callback,
            )
            all_figs.extend(new_figs)
            if tool_name == "run_python":
                _run_python_count += 1

            # run_python æˆåŠŸæ™‚: æœ€å¾Œã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜
            if tool_name == "run_python" and "EXIT CODE: 0" in tool_result:
                success = True
                script_path = tool_args.get("path", "")
                if script_path and Path(script_path).exists():
                    try:
                        final_code = Path(script_path).read_text(encoding="utf-8")
                    except Exception:
                        pass

            # ãƒ„ãƒ¼ãƒ«çµæœã‚’ä¼šè©±å±¥æ­´ã«è¿½åŠ ï¼ˆé•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šæ¨ã¦ï¼‰
            messages.append({
                "role":    "tool",
                "name":    tool_name,
                "content": tool_result[:4000],
            })

            # write_file ã§ .py ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ã„ãŸå¾Œã€run_python ã‚’å³æ™‚æ³¨å…¥
            if (
                tool_name == "write_file"
                and "OK: wrote" in tool_result
                and tool_args.get("path", "").endswith(".py")
            ):
                script_path = tool_args.get("path", "")
                _log(f"  â†’ auto-injecting run_python for {Path(script_path).name}")
                # run_python ãƒ„ãƒ¼ãƒ«ã‚’ç›´æ¥å®Ÿè¡Œ
                run_result, run_figs = _exec_tool(
                    "run_python", {"path": script_path},
                    output_dir, figure_dir,
                    log_callback, install_callback,
                )
                all_figs.extend(run_figs)
                _run_python_count += 1  # auto-inject åˆ†ã‚‚ã‚«ã‚¦ãƒ³ãƒˆ
                if "EXIT CODE: 0" in run_result and run_figs:
                    success = True
                    try:
                        final_code = Path(script_path).read_text(encoding="utf-8")
                    except Exception:
                        pass
                # å®Ÿè¡Œçµæœã‚’ä¼šè©±ã«è¿½åŠ 
                messages.append({
                    "role":    "tool",
                    "name":    "run_python",
                    "content": run_result[:4000],
                })
                # auto-inject ã§ã‚‚ exit 0 ã ãŒå›³ãŒç”Ÿæˆã•ã‚Œã¦ã„ãªã„å ´åˆã¯æœ¬ç•ªã‚³ãƒ¼ãƒ‰å¼·åˆ¶
                if (
                    "EXIT CODE: 0" in run_result
                    and not run_figs
                    and not all_figs
                    and step < max_steps - 2
                ):
                    _log("  â„¹ï¸  auto-inject: exit 0 ã§ã‚‚å›³ãŒæœªç”Ÿæˆã€‚æœ¬ç•ªã‚³ãƒ¼ãƒ‰ã®ä½œæˆã‚’ä¿ƒã—ã¾ã™...")
                    _file_refs = "\n".join(
                        f"  [{cat}] {p}"
                        for cat, paths in export_files.items()
                        for p in paths
                    )
                    messages.append({
                        "role": "user",
                        "content": (
                            "The script ran with EXIT CODE: 0 but NO figures were saved.\n"
                            "The script likely hardcoded data or had a silent error in a try/except.\n\n"
                            "IMPORTANT: Read data from the ACTUAL FILES listed below â€” do NOT hardcode values.\n\n"
                            "CORRECT FILE PATHS:\n"
                            f"{_file_refs}\n\n"
                            f"FIGURE_DIR = r'{figure_dir}'\n"
                            f"Script path: {output_dir}/analysis.py\n\n"
                            "Call write_file NOW with a script that:\n"
                            "  1. Uses pd.read_csv() on the EXACT paths above\n"
                            "  2. Generates the requested figures\n"
                            "  3. Saves each with plt.savefig() to FIGURE_DIR\n"
                            "Add print() after each plt.savefig() to confirm the save."
                        ),
                    })

            # run_python ãŒ exit 0 ã§ã‚‚å›³ãŒç”Ÿæˆã•ã‚Œã¦ã„ãªã„å ´åˆã¯ç¶™ç¶š
            if (
                tool_name == "run_python"
                and "EXIT CODE: 0" in tool_result
                and not new_figs
                and not all_figs
                and step < max_steps - 2
            ):
                _log("  â„¹ï¸  ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯æˆåŠŸã—ã¾ã—ãŸãŒå›³ãŒæœªç”Ÿæˆã§ã™ã€‚æœ¬ç•ªã‚³ãƒ¼ãƒ‰ã®ä½œæˆã‚’ä¿ƒã—ã¾ã™...")
                # æ­£ç¢ºãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å†æ²ã™ã‚‹
                _file_refs = "\n".join(
                    f"  [{cat}] {p}"
                    for cat, paths in export_files.items()
                    for p in paths
                )
                messages.append({
                    "role": "user",
                    "content": (
                        "The script ran with EXIT CODE: 0 but NO figures were saved to FIGURE_DIR.\n"
                        "The script was likely empty or a stub.\n\n"
                        "CORRECT FILE PATHS â€” use these EXACT paths in your script:\n"
                        f"{_file_refs}\n\n"
                        f"FIGURE_DIR = r'{figure_dir}'\n"
                        f"Script path: {output_dir}/analysis.py\n\n"
                        "Call write_file NOW with a COMPLETE Python analysis script that:\n"
                        "  1. Reads the exact paths listed above\n"
                        "  2. Generates figures fig01â€“fig14 as described in the task\n"
                        "  3. Saves each with plt.savefig() to FIGURE_DIR\n"
                        "Use only the exact paths listed above. Do NOT guess paths."
                    ),
                })

    return CodeExecutionResult(
        success=success,
        stdout="",
        stderr=final_error,
        code=final_code,
        figures=all_figs,
        retry_count=total_steps,
        error_message=final_error[:500] if not success else "",
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ + è§£æï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_manifest_agent(
    manifest_path: str,
    user_prompt: str,
    output_dir: str,
    figure_dir: str,
    metadata_path: str = "",
    model: Optional[str] = None,
    max_retries: int = 3,
    plot_config: Optional[dict] = None,
    log_callback: Optional[Callable[[str], None]] = None,
    install_callback: Optional[Callable[[str], bool]] = None,
) -> CodeExecutionResult:
    """
    ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ QIIME2 ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ + è§£æã‚³ãƒ¼ãƒ‰ã‚’
    LLM ã«ç”Ÿæˆã•ã›ã¦å®Ÿè¡Œã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚

    Parameters
    ----------
    manifest_path : str
        QIIME2 å½¢å¼ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆ TSVï¼ˆPairedEndFastqManifestPhred33V2ï¼‰
    user_prompt : str
        ã‚„ã‚ŠãŸã„è§£æã®è‡ªç„¶è¨€èªæŒ‡ç¤º
    output_dir : str
        QIIME2 æˆæœç‰©ãƒ»ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›å…ˆ
    figure_dir : str
        å›³ã®ä¿å­˜å…ˆ
    """
    if model is None:
        model = _agent.DEFAULT_MODEL

    def _log(msg: str):
        if log_callback:
            log_callback(msg)

    _log("LLM ã«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼‹è§£æã‚³ãƒ¼ãƒ‰ã®ç”Ÿæˆã‚’ä¾é ¼ä¸­...")

    system_msg = {
        "role": "system",
        "content": (
            "You are a microbiome analysis expert using QIIME2 and Python. "
            "Generate only Python code without any explanation. "
            "Wrap code in ```python ... ```."
        ),
    }
    user_msg = {
        "role": "user",
        "content": _build_manifest_prompt(
            manifest_path, user_prompt, output_dir, figure_dir,
            metadata_path, plot_config,
        ),
    }
    messages = [system_msg, user_msg]

    try:
        response = _agent.call_ollama(messages, model)
    except Exception as e:
        return CodeExecutionResult(
            success=False,
            error_message=f"Ollama æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}",
        )

    code = _extract_code(response.get("content", ""))
    if not code:
        return CodeExecutionResult(
            success=False,
            error_message="LLM ãŒã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã›ã‚“ã§ã—ãŸ",
        )
    _log(f"ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº† ({len(code.splitlines())} è¡Œ)")

    last_code = code
    last_stderr = ""

    for attempt in range(max_retries + 1):
        _log(f"ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œä¸­... (è©¦è¡Œ {attempt + 1}/{max_retries + 1})")

        success, stdout, stderr, new_figs = _run_code(
            last_code, output_dir, figure_dir, log_callback
        )

        if success:
            _log(f"å®Ÿè¡ŒæˆåŠŸã€‚ç”Ÿæˆã•ã‚ŒãŸå›³: {len(new_figs)} ä»¶")
            return CodeExecutionResult(
                success=True,
                stdout=stdout,
                stderr=stderr,
                code=last_code,
                figures=new_figs,
                retry_count=attempt,
            )

        last_stderr = stderr

        missing_pkg = _detect_missing_module(stderr)
        if missing_pkg:
            _log(f"æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’æ¤œå‡º: {missing_pkg}")
            approved = install_callback(missing_pkg) if install_callback else False
            if approved:
                ok = pip_install(missing_pkg, log_callback)
                if ok:
                    _log(f"{missing_pkg} ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†ã€‚å†å®Ÿè¡Œã—ã¾ã™ã€‚")
                    continue
            else:
                _log(f"{missing_pkg} ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

        if attempt >= max_retries:
            break

        _log("ã‚¨ãƒ©ãƒ¼ã‚’ LLM ã«æ¸¡ã—ã¦ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã‚’ä¾é ¼ä¸­...")
        messages.append({
            "role": "assistant",
            "content": f"```python\n{last_code}\n```",
        })
        messages.append({
            "role": "user",
            "content": (
                f"The code produced the following error:\n"
                f"```\n{stderr[:1500]}\n```\n\n"
                f"Please fix the code and output the complete corrected version "
                f"wrapped in ```python ... ```."
            ),
        })

        try:
            fix_response = _agent.call_ollama(messages, model)
        except Exception as e:
            _log(f"Ollama æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            break

        fixed = _extract_code(fix_response.get("content", ""))
        if fixed:
            last_code = fixed
            _log(f"ä¿®æ­£æ¸ˆã¿ã‚³ãƒ¼ãƒ‰å—ä¿¡ ({len(last_code.splitlines())} è¡Œ)")
        else:
            _log("ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            break

    return CodeExecutionResult(
        success=False,
        stdout="",
        stderr=last_stderr,
        code=last_code,
        figures=[],
        retry_count=max_retries,
        error_message=last_stderr[:500],
    )
