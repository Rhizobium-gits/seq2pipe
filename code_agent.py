#!/usr/bin/env python3
"""
code_agent.py
=============
LLM ã« Python è§£æã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã•ã›ã€å®Ÿè¡Œãƒ»ã‚¨ãƒ©ãƒ¼ä¿®æ­£ãƒ»ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèªã‚’è¡Œã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‚
"""

import re
import subprocess
import tempfile
from dataclasses import dataclass, field
from pathlib import Path
from typing import Callable, Optional

import sys
sys.path.insert(0, str(Path(__file__).parent))
import qiime2_agent as _agent


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class CodeExecutionResult:
    """ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»å®Ÿè¡Œã®çµæœ"""
    success: bool
    stdout: str = ""
    stderr: str = ""
    code: str = ""
    figures: list = field(default_factory=list)
    retry_count: int = 0
    error_message: str = ""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_prompt(
    export_files: dict,
    user_prompt: str,
    figure_dir: str,
    metadata_path: str = "",
    plot_config: Optional[dict] = None,
) -> str:
    """LLM ã¸ã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµ„ã¿ç«‹ã¦ã‚‹"""
    cfg = plot_config or {}
    dpi     = cfg.get("dpi", 150)
    figsize = cfg.get("figsize", [10, 6])

    lines = [
        "You are a microbiome bioinformatics expert.",
        "Write a single, complete, self-contained Python script that analyzes and visualizes",
        "the QIIME2-exported data listed below.",
        "",
        "## Available files",
    ]
    for category, paths in export_files.items():
        for p in paths:
            lines.append(f"  [{category}] {p}")
    if metadata_path:
        lines.append(f"  [metadata] {metadata_path}")

    lines += [
        "",
        f"## Output directory for figures: {figure_dir}",
        f"## DPI: {dpi}",
        f"## figsize: {figsize}",
        "",
        "## User request",
        user_prompt.strip() or (
            "Generate: (1) genus-level stacked bar chart of relative abundance, "
            "(2) alpha diversity boxplot (Shannon), (3) beta diversity PCoA (Bray-Curtis)."
        ),
        "",
        "## FILE FORMAT â€” read exactly as described",
        "",
        "### [feature_table] TSV  (exported from QIIME2 via biom convert)",
        "  - First line  : '# Constructed from biom file'  â† comment, skip it",
        "  - Second line : '#OTU ID\\t<sample1>\\t<sample2>...'  â† use as header",
        "  - Remaining   : Feature ID (ASV/OTU) | per-sample read counts",
        "  - Read with   :",
        "      ft = pd.read_csv(path, sep='\\t', skiprows=1, index_col=0)",
        "      ft.index.name = 'Feature ID'",
        "",
        "### [taxonomy] taxonomy.tsv",
        "  - Columns: Feature ID (index) | Taxon | Confidence",
        "  - Taxon format: 'd__Bacteria; p__Firmicutes; c__Clostridia; o__...; f__...; g__Genus; s__species'",
        "  - Read with   : tax = pd.read_csv(path, sep='\\t', index_col=0)",
        "  - Get genus   : tax['genus'] = tax['Taxon'].str.extract(r'g__([^;]+)').fillna('Unknown').str.strip()",
        "",
        "### [alpha] alpha-diversity TSV",
        "  - Columns: sample-id (index) | metric value (shannon / observed_features / faith_pd ...)",
        "  - Read with   : alpha = pd.read_csv(path, sep='\\t', index_col=0)",
        "",
        "### [beta] distance-matrix TSV",
        "  - Square symmetric matrix; row names = column names = sample IDs",
        "  - Read with   : dm = pd.read_csv(path, sep='\\t', index_col=0)",
        "  - PCoA with sklearn :",
        "      from sklearn.manifold import MDS",
        "      coords = MDS(n_components=2, dissimilarity='precomputed', random_state=42).fit_transform(dm.values)",
        "",
        "## Code requirements",
        "1. First two lines MUST be:",
        "      import matplotlib",
        "      matplotlib.use('Agg')",
        "2. Define at the top:",
        f"      FIGURE_DIR = r'{figure_dir}'",
        f"      DPI = {dpi}",
        "      import os; os.makedirs(FIGURE_DIR, exist_ok=True)",
        "3. Save every figure:",
        "      plt.savefig(os.path.join(FIGURE_DIR, 'name.png'), dpi=DPI, bbox_inches='tight')",
        "      plt.close()",
        "4. All axis labels, titles, legend entries in English.",
        "5. Use try/except around each section so one failure does not stop the whole script.",
        "6. Output ONLY the Python code, wrapped in ```python ... ```.",
        "7. Do NOT use plt.show().",
    ]
    return "\n".join(lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _build_manifest_prompt(
    manifest_path: str,
    user_prompt: str,
    output_dir: str,
    figure_dir: str,
    metadata_path: str = "",
    plot_config: Optional[dict] = None,
) -> str:
    """ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
    import csv

    # ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’èª­ã‚“ã§ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒ»æ§‹é€ ã‚’ç¢ºèª
    samples = []
    try:
        with open(manifest_path, newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f, delimiter="\t")
            for row in reader:
                sid = row.get("sample-id") or row.get("sampleid") or ""
                if sid:
                    samples.append(sid)
    except Exception:
        pass

    qiime_bin = (
        str(Path(_agent.QIIME2_CONDA_BIN) / "qiime")
        if _agent.QIIME2_CONDA_BIN and Path(_agent.QIIME2_CONDA_BIN).exists()
        else "qiime"
    )
    biom_bin = (
        str(Path(_agent.QIIME2_CONDA_BIN) / "biom")
        if _agent.QIIME2_CONDA_BIN and Path(_agent.QIIME2_CONDA_BIN).exists()
        else "biom"
    )

    cfg = plot_config or {}
    sample_preview = ", ".join(samples[:5]) + ("..." if len(samples) > 5 else "")

    lines = [
        "ã‚ãªãŸã¯QIIME2ã¨Pythonã‚’ä½¿ã£ãŸãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ è§£æã®å°‚é–€å®¶ã§ã™ã€‚",
        "ä»¥ä¸‹ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰QIIME2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã€",
        "è§£æãƒ»å¯è¦–åŒ–ã¾ã§è¡Œã†å®Œå…¨ãªPythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’1ã¤æ›¸ã„ã¦ãã ã•ã„ã€‚",
        "",
        "## QIIME2 å®Ÿè¡Œç’°å¢ƒ",
        f"qiime ã‚³ãƒãƒ³ãƒ‰: {qiime_bin}",
        f"biom ã‚³ãƒãƒ³ãƒ‰: {biom_bin}",
        "",
        "## ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«",
        f"ãƒ‘ã‚¹: {manifest_path}",
        "å½¢å¼: PairedEndFastqManifestPhred33V2ï¼ˆã‚¿ãƒ–åŒºåˆ‡ã‚Šã€ãƒ˜ãƒƒãƒ€: sample-id / forward-absolute-filepath / reverse-absolute-filepathï¼‰",
        f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(samples)}",
        f"ã‚µãƒ³ãƒ—ãƒ«IDä¾‹: {sample_preview}",
        "",
    ]

    if metadata_path:
        lines += [
            "## ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«",
            f"ãƒ‘ã‚¹: {metadata_path}",
            "(sample-id åˆ—ã¨ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚’å«ã‚€ TSV)",
            "",
        ]

    lines += [
        f"## å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}",
        f"## å›³ã®ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {figure_dir}",
        f"## DPI: {cfg.get('dpi', 150)}",
        f"## figsize: {cfg.get('figsize', [10, 6])}",
        "",
        "## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚",
        user_prompt if user_prompt.strip() else (
            "å±ãƒ¬ãƒ™ãƒ«ç›¸å¯¾å­˜åœ¨é‡ã®ç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•ã€Shannon Î±å¤šæ§˜æ€§ã€Bray-Curtis PCoA ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        ),
        "",
        "## ã‚³ãƒ¼ãƒ‰ã®è¦ä»¶",
        "- import matplotlib; matplotlib.use('Agg') ã‚’æœ€åˆã«æ›¸ã",
        "- QIIME2 ã‚³ãƒãƒ³ãƒ‰ã¯ subprocess.run([qiime_cmd, ...], check=True, capture_output=True, text=True) ã§å®Ÿè¡Œã™ã‚‹",
        "  ä¾‹: result = subprocess.run(['/path/to/qiime', 'tools', 'import', ...], check=True, capture_output=True, text=True)",
        "- å„ã‚¹ãƒ†ãƒƒãƒ—ã® returncode != 0 ã®ã¨ã stderr ã‚’è¡¨ç¤ºã—ã¦ sys.exit(1) ã§åœæ­¢ã™ã‚‹",
        "- å›³ã¯ plt.savefig() ã§ä¿å­˜ã— plt.show() ã¯ä½¿ã‚ãªã„",
        "- ã‚¿ã‚¤ãƒˆãƒ«ãƒ»ãƒ©ãƒ™ãƒ«ã¯è‹±èªã§æ›¸ãï¼ˆæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆä¾å­˜ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰",
        "- ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’å‡ºåŠ›ã™ã‚‹ã€‚èª¬æ˜æ–‡ã¯ä¸è¦",
        "- ã‚³ãƒ¼ãƒ‰ã¯ ```python ... ``` ã§å›²ã‚€",
        "",
        "## QIIME2ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ¨å¥¨ãƒ•ãƒ­ãƒ¼",
        "1. qiime tools import ã§ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ",
        "   --type 'SampleData[PairedEndSequencesWithQuality]'",
        "   --input-format PairedEndFastqManifestPhred33V2",
        "2. qiime dada2 denoise-paired ã§ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°",
        "   æ¨å¥¨: --p-trim-left-f 0 --p-trim-left-r 0 --p-trunc-len-f 250 --p-trunc-len-r 200 --p-n-threads 0",
        "3. qiime taxa collapse --p-level 6 ã§å±ãƒ¬ãƒ™ãƒ«ã«é›†ç´„",
        "4. qiime tools export ã§ feature-table.biom ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
        "5. biom convert -i feature-table.biom -o feature-table.tsv --to-tsv ã§TSVã«å¤‰æ›",
        "6. pandasã§TSVã‚’èª­ã¿è¾¼ã‚“ã§ç›¸å¯¾å­˜åœ¨é‡ã‚’è¨ˆç®—ãƒ»matplotlib ã§å¯è¦–åŒ–",
        "7. å¤šæ§˜æ€§è§£æãŒå¿…è¦ãªå ´åˆã¯ qiime diversity core-metrics-phylogenetic ãªã©ã‚’ä½¿ç”¨",
    ]

    return "\n".join(lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚³ãƒ¼ãƒ‰æŠ½å‡º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _extract_code(content: str) -> str:
    """LLM ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ Python ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºã™ã‚‹"""
    # ```python ... ``` ã¾ãŸã¯ ``` ... ```
    match = re.search(r'```(?:python)?\s*([\s\S]*?)```', content)
    if match:
        return match.group(1).strip()
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: import ã‹ã‚‰å§‹ã¾ã‚‹è¡Œä»¥é™
    for i, line in enumerate(content.splitlines()):
        if line.strip().startswith(("import ", "from ")):
            return "\n".join(content.splitlines()[i:]).strip()
    return content.strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _run_code(
    code: str,
    output_dir: str,
    figure_dir: str,
    log_callback: Optional[Callable[[str], None]] = None,
) -> tuple:
    """
    ã‚³ãƒ¼ãƒ‰ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚“ã§ QIIME2_PYTHON ã§å®Ÿè¡Œã™ã‚‹ã€‚
    æˆ»ã‚Šå€¤: (success: bool, stdout: str, stderr: str, new_figures: list[str])
    """
    py_exec = _agent.QIIME2_PYTHON
    if not py_exec or not Path(py_exec).exists():
        py_exec = sys.executable

    fig_dir = Path(figure_dir)
    fig_dir.mkdir(parents=True, exist_ok=True)

    # å®Ÿè¡Œå‰ã®å›³ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
    existing = set(fig_dir.glob("*.png")) | set(fig_dir.glob("*.pdf")) | set(fig_dir.glob("*.svg"))

    with tempfile.NamedTemporaryFile(
        mode='w', suffix='.py', delete=False, encoding='utf-8'
    ) as f:
        f.write(code)
        tmp_path = f.name

    try:
        proc = subprocess.run(
            [py_exec, tmp_path],
            capture_output=True,
            text=True,
            timeout=300,
            cwd=output_dir,
        )

        if log_callback:
            for line in proc.stdout.splitlines():
                log_callback(line)
            if proc.stderr:
                for line in proc.stderr.splitlines()[:20]:
                    log_callback(f"[stderr] {line}")

        new_figs = sorted(
            (set(fig_dir.glob("*.png")) | set(fig_dir.glob("*.pdf")) | set(fig_dir.glob("*.svg")))
            - existing
        )
        return (
            proc.returncode == 0,
            proc.stdout,
            proc.stderr,
            [str(f) for f in new_figs],
        )
    finally:
        try:
            Path(tmp_path).unlink()
        except Exception:
            pass


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ModuleNotFoundError æ¤œå‡º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_PIP_NAME_MAP = {
    "sklearn": "scikit-learn",
    "skbio":   "scikit-bio",
    "Bio":     "biopython",
    "cv2":     "opencv-python",
    "PIL":     "Pillow",
}

def _detect_missing_module(stderr: str) -> Optional[str]:
    """stderr ã‹ã‚‰ ModuleNotFoundError ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã‚’æŠ½å‡ºã™ã‚‹"""
    match = re.search(r"No module named '([^']+)'", stderr)
    if match:
        mod = match.group(1).split(".")[0]
        return _PIP_NAME_MAP.get(mod, mod)
    return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# pip ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def pip_install(
    package: str,
    log_callback: Optional[Callable[[str], None]] = None,
) -> bool:
    """QIIME2 conda ç’°å¢ƒã® pip ã§ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹"""
    conda_bin = _agent.QIIME2_CONDA_BIN
    if conda_bin and Path(conda_bin).exists():
        pip_exec = str(Path(conda_bin) / "pip")
    else:
        pip_exec = str(Path(sys.executable).parent / "pip")

    if log_callback:
        log_callback(f"[pip] ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­: {package}")

    proc = subprocess.run(
        [pip_exec, "install", package],
        capture_output=True, text=True, timeout=180,
    )
    if log_callback:
        for line in proc.stdout.splitlines()[-3:]:
            log_callback(f"[pip] {line}")
        if proc.returncode != 0:
            for line in proc.stderr.splitlines()[-5:]:
                log_callback(f"[pip error] {line}")
    return proc.returncode == 0


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_code_agent(
    export_files: dict,
    user_prompt: str,
    output_dir: str,
    figure_dir: str,
    metadata_path: str = "",
    model: Optional[str] = None,
    max_retries: int = 3,
    plot_config: Optional[dict] = None,
    log_callback: Optional[Callable[[str], None]] = None,
    install_callback: Optional[Callable[[str], bool]] = None,
) -> CodeExecutionResult:
    """
    LLM ã§ Python è§£æã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆãƒ»å®Ÿè¡Œã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚

    Parameters
    ----------
    export_files : dict
        pipeline_runner.get_exported_files() ã®æˆ»ã‚Šå€¤
    user_prompt : str
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è§£ææŒ‡ç¤ºï¼ˆè‡ªç„¶è¨€èªï¼‰
    output_dir : str
        ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    figure_dir : str
        å›³ã®ä¿å­˜å…ˆ
    model : str, optional
        Ollama ãƒ¢ãƒ‡ãƒ«åï¼ˆNone ãªã‚‰ DEFAULT_MODELï¼‰
    max_retries : int
        ã‚¨ãƒ©ãƒ¼æ™‚ã®æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 3ï¼‰
    install_callback : (pkg: str) -> bool, optional
        ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«è¨±å¯ã‚’æ±‚ã‚ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
        True ã‚’è¿”ã™ã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Ÿè¡Œã€‚
        None ã®å ´åˆã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãªã„ã€‚
    """
    if model is None:
        model = _agent.DEFAULT_MODEL

    def _log(msg: str):
        if log_callback:
            log_callback(msg)

    _log("LLM ã«ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚’ä¾é ¼ä¸­...")

    # â”€â”€ STEP 1: åˆå›ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    system_msg = {
        "role": "system",
        "content": (
            "You are a microbiome analysis expert. "
            "Generate only Python code without any explanation. "
            "Wrap code in ```python ... ```."
        ),
    }
    user_msg = {
        "role": "user",
        "content": _build_prompt(
            export_files, user_prompt, figure_dir, metadata_path, plot_config
        ),
    }
    messages = [system_msg, user_msg]

    try:
        response = _agent.call_ollama(messages, model)
    except Exception as e:
        return CodeExecutionResult(
            success=False,
            error_message=f"Ollama æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}",
        )

    code = _extract_code(response.get("content", ""))
    if not code:
        return CodeExecutionResult(
            success=False,
            error_message="LLM ãŒã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã›ã‚“ã§ã—ãŸ",
        )
    _log(f"ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº† ({len(code.splitlines())} è¡Œ)")

    # â”€â”€ STEP 2: å®Ÿè¡Œ + ãƒªãƒˆãƒ©ã‚¤ãƒ«ãƒ¼ãƒ— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    last_code = code
    last_stderr = ""

    for attempt in range(max_retries + 1):
        _log(f"ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œä¸­... (è©¦è¡Œ {attempt + 1}/{max_retries + 1})")

        success, stdout, stderr, new_figs = _run_code(
            last_code, output_dir, figure_dir, log_callback
        )

        if success:
            _log(f"å®Ÿè¡ŒæˆåŠŸã€‚ç”Ÿæˆã•ã‚ŒãŸå›³: {len(new_figs)} ä»¶")
            return CodeExecutionResult(
                success=True,
                stdout=stdout,
                stderr=stderr,
                code=last_code,
                figures=new_figs,
                retry_count=attempt,
            )

        last_stderr = stderr

        # ModuleNotFoundError ã®å‡¦ç†
        missing_pkg = _detect_missing_module(stderr)
        if missing_pkg:
            _log(f"æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’æ¤œå‡º: {missing_pkg}")
            approved = install_callback(missing_pkg) if install_callback else False
            if approved:
                ok = pip_install(missing_pkg, log_callback)
                if ok:
                    _log(f"{missing_pkg} ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†ã€‚å†å®Ÿè¡Œã—ã¾ã™ã€‚")
                    continue   # åŒã˜ã‚³ãƒ¼ãƒ‰ã§å†å®Ÿè¡Œï¼ˆã‚³ãƒ¼ãƒ‰ä¿®æ­£ä¸è¦ï¼‰
            else:
                _log(f"{missing_pkg} ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

        if attempt >= max_retries:
            break

        # LLM ã«ã‚¨ãƒ©ãƒ¼ã‚’æ¸¡ã—ã¦ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã‚’ä¾é ¼
        _log(f"ã‚¨ãƒ©ãƒ¼ã‚’ LLM ã«æ¸¡ã—ã¦ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã‚’ä¾é ¼ä¸­...")
        messages.append({
            "role": "assistant",
            "content": f"```python\n{last_code}\n```",
        })
        messages.append({
            "role": "user",
            "content": (
                f"The code produced the following error:\n"
                f"```\n{stderr[:1500]}\n```\n\n"
                f"Please fix the code and output the complete corrected version "
                f"wrapped in ```python ... ```."
            ),
        })

        try:
            fix_response = _agent.call_ollama(messages, model)
        except Exception as e:
            _log(f"Ollama æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            break

        fixed = _extract_code(fix_response.get("content", ""))
        if fixed:
            last_code = fixed
            _log(f"ä¿®æ­£æ¸ˆã¿ã‚³ãƒ¼ãƒ‰å—ä¿¡ ({len(last_code.splitlines())} è¡Œ)")
        else:
            _log("ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            break

    return CodeExecutionResult(
        success=False,
        stdout="",
        stderr=last_stderr,
        code=last_code,
        figures=[],
        retry_count=max_retries,
        error_message=last_stderr[:500],
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆAuto Agentï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class AutoAgentResult:
    """è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œçµæœ"""
    rounds: list = field(default_factory=list)       # list[CodeExecutionResult]
    total_figures: list = field(default_factory=list)
    completed: bool = False                           # ANALYSIS_COMPLETE ã‚’å—ä¿¡ã—ãŸã‹


def _build_auto_initial_prompt(
    export_files: dict,
    figure_dir: str,
    metadata_path: str = "",
    plot_config: Optional[dict] = None,
) -> str:
    """è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨ã®åˆå›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡ç¤ºãªã—ãƒ»AI ãŒè¨ˆç”»ç«‹æ¡ˆï¼‰"""
    cfg     = plot_config or {}
    dpi     = cfg.get("dpi", 150)
    figsize = cfg.get("figsize", [10, 6])

    lines = [
        "You are an autonomous microbiome bioinformatics analysis agent.",
        "Analyze the QIIME2-exported data listed below, one analysis per round.",
        "",
        "## PROTOCOL",
        "- Each response: write EXACTLY ONE complete Python script in ```python ... ```.",
        "- After the script runs you receive the result and plan the next analysis.",
        "- When you have completed a comprehensive suite, respond with: ANALYSIS_COMPLETE",
        "",
        "## Recommended analysis plan (adapt to available files):",
        "  Round 1 â€” Summary statistics (sample count, feature count, read-depth distribution)",
        "  Round 2 â€” Genus-level stacked bar chart (relative abundance, top genera)",
        "  Round 3 â€” Alpha diversity boxplot (Shannon; observed_features if available)",
        "  Round 4 â€” Beta diversity PCoA (Bray-Curtis distance matrix â†’ MDS)",
        "  Round 5 â€” Taxonomy heatmap (top 20 genera, z-score normalized)",
        "  Round 6 â€” Any additional insight you find relevant",
        "",
        "## Available files",
    ]
    for category, paths in export_files.items():
        for p in paths:
            lines.append(f"  [{category}] {p}")
    if metadata_path:
        lines.append(f"  [metadata] {metadata_path}")

    lines += [
        "",
        f"## Figure output directory : {figure_dir}",
        f"## DPI: {dpi}    figsize: {figsize}",
        "",
        "## FILE FORMAT â€” read exactly as described",
        "",
        "### [feature_table] TSV  (exported from QIIME2 via biom convert)",
        "  - Line 1  : '# Constructed from biom file'  â† skip",
        "  - Line 2  : '#OTU ID\\t<sample1>\\t<sample2>...'  â† header",
        "  - Read:   ft = pd.read_csv(path, sep='\\t', skiprows=1, index_col=0)",
        "",
        "### [taxonomy] taxonomy.tsv",
        "  - Columns : Feature ID (index) | Taxon | Confidence",
        "  - Genus   : tax['genus'] = tax['Taxon'].str.extract(r'g__([^;]+)').fillna('Unknown').str.strip()",
        "",
        "### [alpha] alpha-diversity TSV",
        "  - Columns : sample-id (index) | metric value",
        "  - Read:   alpha = pd.read_csv(path, sep='\\t', index_col=0)",
        "",
        "### [beta] distance-matrix TSV",
        "  - Square symmetric matrix; row = column = sample IDs",
        "  - Read:   dm = pd.read_csv(path, sep='\\t', index_col=0)",
        "  - PCoA:   from sklearn.manifold import MDS",
        "            coords = MDS(n_components=2, dissimilarity='precomputed', random_state=42).fit_transform(dm.values)",
        "",
        "## Code requirements",
        "1. First two lines MUST be:",
        "      import matplotlib",
        "      matplotlib.use('Agg')",
        "2. Define at the top:",
        f"      FIGURE_DIR = r'{figure_dir}'",
        f"      DPI = {dpi}",
        "      import os; os.makedirs(FIGURE_DIR, exist_ok=True)",
        "3. Include the round number in every filename: e.g. 'round1_summary.png'",
        "4. Save and close every figure:",
        "      plt.savefig(os.path.join(FIGURE_DIR, 'roundN_name.png'), dpi=DPI, bbox_inches='tight')",
        "      plt.close()",
        "5. All labels, titles, legend entries in English.",
        "6. try/except around each major section.",
        "7. No plt.show().",
        "",
        "## Begin: write code for Round 1 now.",
    ]
    return "\n".join(lines)


def run_auto_agent(
    export_files: dict,
    output_dir: str,
    figure_dir: str,
    metadata_path: str = "",
    model: Optional[str] = None,
    max_rounds: int = 6,
    plot_config: Optional[dict] = None,
    log_callback: Optional[Callable[[str], None]] = None,
    install_callback: Optional[Callable[[str], bool]] = None,
) -> AutoAgentResult:
    """
    è‡ªå¾‹çš„ã«è§£æã‚’é€²ã‚ã‚‹ AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚

    LLM ãŒè§£æè¨ˆç”»ã‚’è‡ªã‚‰ç«‹ã¦ã€ãƒ©ã‚¦ãƒ³ãƒ‰ã”ã¨ã«ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆãƒ»å®Ÿè¡Œã—ã€
    çµæœã‚’å—ã‘å–ã£ã¦æ¬¡ã®è§£æã‚’æ±ºã‚ã‚‹ã€‚
    ã€ŒANALYSIS_COMPLETEã€ã‚’å—ä¿¡ã™ã‚‹ã‹ max_rounds ã«é”ã—ãŸã‚‰çµ‚äº†ã€‚
    """
    if model is None:
        model = _agent.DEFAULT_MODEL

    def _log(msg: str):
        if log_callback:
            log_callback(msg)

    results: list = []
    all_figures: list = []

    messages = [
        {
            "role": "system",
            "content": (
                "You are an autonomous microbiome analysis agent. "
                "Each response must contain ONE complete Python script in ```python...``` "
                "OR the text ANALYSIS_COMPLETE when all analyses are done."
            ),
        },
        {
            "role": "user",
            "content": _build_auto_initial_prompt(
                export_files, figure_dir, metadata_path, plot_config
            ),
        },
    ]

    for round_n in range(1, max_rounds + 1):
        _log(f"\n{'â”€' * 44}")
        _log(f"  ğŸ¤– Round {round_n} / {max_rounds}")
        _log(f"{'â”€' * 44}")
        _log("æ¬¡ã®è§£æã‚’è¨ˆç”»ä¸­...")

        try:
            response = _agent.call_ollama(messages, model)
        except Exception as e:
            _log(f"Ollama ã‚¨ãƒ©ãƒ¼: {e}")
            break

        content = response.get("content", "")

        # çµ‚äº†å®£è¨€
        if "ANALYSIS_COMPLETE" in content:
            _log("âœ… AI ãŒå…¨è§£æå®Œäº†ã¨åˆ¤æ–­ã—ã¾ã—ãŸã€‚")
            return AutoAgentResult(
                rounds=results, total_figures=all_figures, completed=True
            )

        code = _extract_code(content)
        if not code:
            _log("ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ç¶šè¡Œã‚’ä¿ƒã—ã¾ã™ã€‚")
            messages.append({"role": "assistant", "content": content})
            messages.append({
                "role": "user",
                "content": (
                    "No Python code was found in your response. "
                    "Please write the next analysis as a complete Python script "
                    "in ```python...``` or respond with ANALYSIS_COMPLETE."
                ),
            })
            continue

        _log(f"ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº† ({len(code.splitlines())} è¡Œ)")

        # â”€â”€ å®Ÿè¡Œ + ãƒªãƒˆãƒ©ã‚¤ï¼ˆæœ€å¤§ 3 å›ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        last_code   = code
        last_stderr = ""
        round_success = False
        new_figs: list = []

        for attempt in range(3):
            _log(f"å®Ÿè¡Œä¸­... (è©¦è¡Œ {attempt + 1}/3)")
            success, stdout, stderr, figs = _run_code(
                last_code, output_dir, figure_dir, log_callback
            )

            if success:
                round_success = True
                new_figs = figs
                break

            last_stderr = stderr

            # ModuleNotFoundError å‡¦ç†
            missing_pkg = _detect_missing_module(stderr)
            if missing_pkg:
                _log(f"æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: {missing_pkg}")
                approved = install_callback(missing_pkg) if install_callback else False
                if approved and pip_install(missing_pkg, log_callback):
                    continue

            if attempt < 2:
                _log("LLM ã«ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã‚’ä¾é ¼ä¸­...")
                fix_msgs = messages + [
                    {"role": "assistant", "content": f"```python\n{last_code}\n```"},
                    {
                        "role": "user",
                        "content": (
                            f"Error:\n```\n{stderr[:1000]}\n```\n"
                            "Fix and return the complete corrected code in ```python...```."
                        ),
                    },
                ]
                try:
                    fix_resp = _agent.call_ollama(fix_msgs, model)
                    fixed = _extract_code(fix_resp.get("content", ""))
                    if fixed:
                        last_code = fixed
                        _log(f"ä¿®æ­£æ¸ˆã¿ã‚³ãƒ¼ãƒ‰å—ä¿¡ ({len(last_code.splitlines())} è¡Œ)")
                except Exception:
                    pass

        # â”€â”€ ãƒ©ã‚¦ãƒ³ãƒ‰çµæœã‚’è¨˜éŒ² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        results.append(CodeExecutionResult(
            success=round_success,
            stdout="",
            stderr=last_stderr,
            code=last_code,
            figures=new_figs,
            retry_count=0,
            error_message=last_stderr[:300] if not round_success else "",
        ))
        all_figures.extend(new_figs)

        if round_success:
            _log(f"âœ… Round {round_n} æˆåŠŸ")
            if new_figs:
                _log(f"ğŸ“Š å›³ã‚’ä¿å­˜: {[Path(f).name for f in new_figs]}")
            status_line = f"Round {round_n} succeeded."
            if new_figs:
                status_line += f" New figures saved: {[Path(f).name for f in new_figs]}."
        else:
            _log(f"âŒ Round {round_n} å¤±æ•—")
            status_line = f"Round {round_n} failed. Error: {last_stderr[:200]}"

        all_names = [Path(f).name for f in all_figures]
        messages.append({"role": "assistant", "content": content})
        messages.append({
            "role": "user",
            "content": (
                f"{status_line}\n"
                f"All figures generated so far: {all_names}\n\n"
                f"Proceed with Round {round_n + 1}, "
                f"or respond ANALYSIS_COMPLETE if done."
            ),
        })

    return AutoAgentResult(rounds=results, total_figures=all_figures, completed=False)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ + è§£æï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_manifest_agent(
    manifest_path: str,
    user_prompt: str,
    output_dir: str,
    figure_dir: str,
    metadata_path: str = "",
    model: Optional[str] = None,
    max_retries: int = 3,
    plot_config: Optional[dict] = None,
    log_callback: Optional[Callable[[str], None]] = None,
    install_callback: Optional[Callable[[str], bool]] = None,
) -> CodeExecutionResult:
    """
    ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ QIIME2 ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ + è§£æã‚³ãƒ¼ãƒ‰ã‚’
    LLM ã«ç”Ÿæˆã•ã›ã¦å®Ÿè¡Œã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚

    Parameters
    ----------
    manifest_path : str
        QIIME2 å½¢å¼ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆ TSVï¼ˆPairedEndFastqManifestPhred33V2ï¼‰
    user_prompt : str
        ã‚„ã‚ŠãŸã„è§£æã®è‡ªç„¶è¨€èªæŒ‡ç¤º
    output_dir : str
        QIIME2 æˆæœç‰©ãƒ»ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›å…ˆ
    figure_dir : str
        å›³ã®ä¿å­˜å…ˆ
    """
    if model is None:
        model = _agent.DEFAULT_MODEL

    def _log(msg: str):
        if log_callback:
            log_callback(msg)

    _log("LLM ã«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼‹è§£æã‚³ãƒ¼ãƒ‰ã®ç”Ÿæˆã‚’ä¾é ¼ä¸­...")

    system_msg = {
        "role": "system",
        "content": (
            "You are a microbiome analysis expert using QIIME2 and Python. "
            "Generate only Python code without any explanation. "
            "Wrap code in ```python ... ```."
        ),
    }
    user_msg = {
        "role": "user",
        "content": _build_manifest_prompt(
            manifest_path, user_prompt, output_dir, figure_dir,
            metadata_path, plot_config,
        ),
    }
    messages = [system_msg, user_msg]

    try:
        response = _agent.call_ollama(messages, model)
    except Exception as e:
        return CodeExecutionResult(
            success=False,
            error_message=f"Ollama æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}",
        )

    code = _extract_code(response.get("content", ""))
    if not code:
        return CodeExecutionResult(
            success=False,
            error_message="LLM ãŒã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã›ã‚“ã§ã—ãŸ",
        )
    _log(f"ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº† ({len(code.splitlines())} è¡Œ)")

    last_code = code
    last_stderr = ""

    for attempt in range(max_retries + 1):
        _log(f"ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œä¸­... (è©¦è¡Œ {attempt + 1}/{max_retries + 1})")

        success, stdout, stderr, new_figs = _run_code(
            last_code, output_dir, figure_dir, log_callback
        )

        if success:
            _log(f"å®Ÿè¡ŒæˆåŠŸã€‚ç”Ÿæˆã•ã‚ŒãŸå›³: {len(new_figs)} ä»¶")
            return CodeExecutionResult(
                success=True,
                stdout=stdout,
                stderr=stderr,
                code=last_code,
                figures=new_figs,
                retry_count=attempt,
            )

        last_stderr = stderr

        missing_pkg = _detect_missing_module(stderr)
        if missing_pkg:
            _log(f"æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’æ¤œå‡º: {missing_pkg}")
            approved = install_callback(missing_pkg) if install_callback else False
            if approved:
                ok = pip_install(missing_pkg, log_callback)
                if ok:
                    _log(f"{missing_pkg} ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†ã€‚å†å®Ÿè¡Œã—ã¾ã™ã€‚")
                    continue
            else:
                _log(f"{missing_pkg} ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

        if attempt >= max_retries:
            break

        _log("ã‚¨ãƒ©ãƒ¼ã‚’ LLM ã«æ¸¡ã—ã¦ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã‚’ä¾é ¼ä¸­...")
        messages.append({
            "role": "assistant",
            "content": f"```python\n{last_code}\n```",
        })
        messages.append({
            "role": "user",
            "content": (
                f"The code produced the following error:\n"
                f"```\n{stderr[:1500]}\n```\n\n"
                f"Please fix the code and output the complete corrected version "
                f"wrapped in ```python ... ```."
            ),
        })

        try:
            fix_response = _agent.call_ollama(messages, model)
        except Exception as e:
            _log(f"Ollama æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            break

        fixed = _extract_code(fix_response.get("content", ""))
        if fixed:
            last_code = fixed
            _log(f"ä¿®æ­£æ¸ˆã¿ã‚³ãƒ¼ãƒ‰å—ä¿¡ ({len(last_code.splitlines())} è¡Œ)")
        else:
            _log("ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            break

    return CodeExecutionResult(
        success=False,
        stdout="",
        stderr=last_stderr,
        code=last_code,
        figures=[],
        retry_count=max_retries,
        error_message=last_stderr[:500],
    )
