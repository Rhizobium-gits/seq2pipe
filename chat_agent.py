#!/usr/bin/env python3
"""
chat_agent.py
=============
å¯¾è©±å‹è§£æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚

å®Ÿé¨“ç³»ã‚„ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’è‡ªç„¶è¨€èªã§èª¬æ˜ã—ãªãŒã‚‰ã€
ä¼šè©±ã‚’ã—ã¤ã¤ã©ã‚“ã©ã‚“è§£æã‚’é€²ã‚ã¦ã„ããƒ¢ãƒ¼ãƒ‰ã€‚

ä½¿ã„æ–¹:
    from chat_agent import InteractiveSession

    session = InteractiveSession(
        export_dir="~/data/exported",
        output_dir="~/analysis/output",
        figure_dir="~/analysis/figures",
        model="qwen2.5-coder:7b",
    )

    # å®Ÿé¨“ã®èª¬æ˜
    print(session.setup("ãƒã‚¦ã‚¹è…¸å†…ãƒ•ãƒ­ãƒ¼ãƒ©ã®16Sãƒ‡ãƒ¼ã‚¿ã€‚æŠ—ç”Ÿç‰©è³ªæŠ•ä¸ç¾¤ã¨å¯¾ç…§ç¾¤ã®æ¯”è¼ƒ"))

    # å¯¾è©±ãƒ«ãƒ¼ãƒ—
    result = session.chat("ã¾ãšã‚¢ãƒ«ãƒ•ã‚¡å¤šæ§˜æ€§ã‚’ç¾¤é–“ã§æ¯”è¼ƒã—ã¦")
    print(result["text"])   # è‡ªç„¶è¨€èªã‚µãƒãƒªãƒ¼
    print(result["figures"]) # ç”Ÿæˆã•ã‚ŒãŸå›³ã®ãƒ‘ã‚¹ä¸€è¦§
"""

from __future__ import annotations

import re
import glob
import json
import datetime
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional

import qiime2_agent as _agent
from code_agent import run_code_agent, CodeExecutionResult


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•ç™ºè¦‹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_FILE_PATTERNS = {
    "feature_table": ["feature-table.tsv", "feature_table.tsv"],
    "taxonomy":      ["taxonomy/taxonomy.tsv"],
    "denoising":     ["denoising_stats/stats.tsv", "denoising-stats/stats.tsv"],
    "alpha":         ["alpha/**/*.tsv"],
    "beta":          ["beta/**/*.tsv"],
    "metadata":      ["metadata.tsv", "sample-metadata.tsv", "sample_metadata.tsv"],
}


def discover_export_files(export_dir: str | Path) -> dict[str, list[str]]:
    """ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†é¡ã™ã‚‹ã€‚"""
    base = Path(export_dir).expanduser()
    result: dict[str, list[str]] = {}
    for category, patterns in _FILE_PATTERNS.items():
        found: list[str] = []
        for pat in patterns:
            found.extend(glob.glob(str(base / pat), recursive=True))
        if found:
            result[category] = sorted(set(found))
    return result


def _file_summary(export_files: dict[str, list[str]]) -> str:
    lines = []
    for cat, paths in export_files.items():
        for p in paths:
            lines.append(f"  [{cat}] {Path(p).name}  ({p})")
    return "\n".join(lines) if lines else "  ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼‰"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class AnalysisFinding:
    """1ã‚¿ãƒ¼ãƒ³ã®è§£æçµæœã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè“„ç©ã«ä½¿ç”¨ã€‚"""
    step: int
    user_request: str
    analysis_description: str    # å®Ÿéš›ã«ä½•ã®è§£æã‚’ã—ãŸã‹
    result_summary: str          # LLM ã«ã‚ˆã‚‹è‡ªç„¶è¨€èªã‚µãƒãƒªãƒ¼
    figures: list[str] = field(default_factory=list)
    success: bool = True


@dataclass
class SessionContext:
    experiment_description: str = ""
    groups: list[str] = field(default_factory=list)
    data_type: str = ""
    notes: str = ""                            # è¿½åŠ ã®ãƒ¡ãƒ¢ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰å¾—ãŸæƒ…å ±ï¼‰
    findings: list[AnalysisFinding] = field(default_factory=list)
    all_figures: list[str] = field(default_factory=list)

    def to_context_block(self) -> str:
        """ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æŒ¿å…¥ã™ã‚‹å®Ÿé¨“ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—åˆ—ã€‚"""
        parts = ["## EXPERIMENT CONTEXT (use this to guide analysis)"]
        if self.experiment_description:
            parts.append(f"Experiment: {self.experiment_description}")
        if self.data_type:
            parts.append(f"Data type: {self.data_type}")
        if self.groups:
            parts.append(f"Groups: {', '.join(self.groups)}")
        if self.notes:
            parts.append(f"Notes: {self.notes}")

        if self.findings:
            parts.append("\n## PREVIOUS ANALYSES (results so far)")
            for f in self.findings[-4:]:   # ç›´è¿‘4ä»¶ã¾ã§å‚ç…§
                parts.append(f"  Step {f.step}: {f.analysis_description}")
                if f.result_summary:
                    # å…ˆé ­180æ–‡å­—ã ã‘ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‚¥å¤§åŒ–é˜²æ­¢ï¼‰
                    parts.append(f"  â†’ {f.result_summary[:180]}")
                if f.figures:
                    parts.append(f"  â†’ Figures: {', '.join(Path(p).name for p in f.figures)}")

        return "\n".join(parts)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class InteractiveSession:
    """
    å¯¾è©±å‹ãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ è§£æã‚»ãƒƒã‚·ãƒ§ãƒ³ã€‚

    1. setup()  â€” å®Ÿé¨“ã®èª¬æ˜ã‚’å—ã‘ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
    2. chat()   â€” è§£ææŒ‡ç¤ºã‚’å—ã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆãƒ»å®Ÿè¡Œãƒ»çµæœã‚’ã‚µãƒãƒªãƒ¼
    3. get_summary() â€” ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã®ã‚µãƒãƒªãƒ¼
    """

    def __init__(
        self,
        export_dir: str | Path,
        output_dir: str | Path,
        figure_dir: str | Path,
        model: str | None = None,
        log_callback=None,
        install_callback=None,
    ):
        self.export_dir  = Path(export_dir).expanduser()
        self.output_dir  = Path(output_dir).expanduser()
        self.figure_dir  = Path(figure_dir).expanduser()
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.figure_dir.mkdir(parents=True, exist_ok=True)

        self.model            = model or _agent.DEFAULT_MODEL
        self._log             = log_callback or (lambda m: None)
        self._install_cb      = install_callback
        self.ctx              = SessionContext()
        self._llm_history: list[dict] = []   # LLM ä¼šè©±å±¥æ­´ï¼ˆã‚µãƒãƒªãƒ¼ç”¨ï¼‰
        self._step            = 0

        # ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•ç™ºè¦‹
        self.export_files = discover_export_files(self.export_dir)

    # â”€â”€ 1. setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def setup(self, description: str) -> str:
        """
        å®Ÿé¨“ã®èª¬æ˜ã‚’å—ã‘å–ã‚Šã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
        Returns: ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‹ã‚‰ã®ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆè‡ªç„¶è¨€èªï¼‰
        """
        self.ctx.experiment_description = description

        # LLM ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè§£æ + ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã•ã›ã‚‹
        n_files = sum(len(v) for v in self.export_files.values())
        file_block = _file_summary(self.export_files)

        prompt = (
            "You are a microbiome bioinformatics assistant.\n"
            "The user has described their experiment. Respond in the SAME LANGUAGE the user used.\n\n"
            f"User's description:\n{description}\n\n"
            f"Available export files ({n_files} files found):\n{file_block}\n\n"
            "Please:\n"
            "1. Briefly confirm what you understood (experiment type, groups, data).\n"
            "2. List the key files available.\n"
            "3. Suggest 2-3 concrete analysis options to start with.\n"
            "Keep it under 200 words. Be friendly and practical."
        )

        reply = self._call_llm_simple(prompt)

        # å±¥æ­´ã«è¿½åŠ 
        self._llm_history.append({"role": "user", "content": description})
        self._llm_history.append({"role": "assistant", "content": reply})

        return reply

    # â”€â”€ 2. chat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def chat(self, user_input: str) -> dict:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è§£ææŒ‡ç¤ºã‚’å—ã‘ã¦ã€ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆãƒ»å®Ÿè¡Œã—çµæœã‚’ã‚µãƒãƒªãƒ¼ã™ã‚‹ã€‚

        Returns:
            {
                "text":    str,          # è‡ªç„¶è¨€èªã‚µãƒãƒªãƒ¼ + æ¬¡ã®ææ¡ˆ
                "figures": list[str],    # ç”Ÿæˆã•ã‚ŒãŸå›³ã®ãƒ‘ã‚¹
                "step":    int,
                "success": bool,
            }
        """
        self._step += 1
        self._llm_history.append({"role": "user", "content": user_input})
        self._log(f"\nğŸ”¬ [Step {self._step}] è§£æå®Ÿè¡Œä¸­...")

        # ã‚³ãƒ¼ãƒ‰ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãï¼‰
        code_prompt = self._build_code_prompt(user_input)

        # ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»å®Ÿè¡Œ
        result = run_code_agent(
            export_files=self.export_files,
            user_prompt=code_prompt,
            output_dir=str(self.output_dir),
            figure_dir=str(self.figure_dir),
            model=self.model,
            max_retries=3,
            log_callback=self._log,
            install_callback=self._install_cb,
        )

        # çµæœã®ã‚µãƒãƒªãƒ¼ï¼ˆè‡ªç„¶è¨€èªï¼‰
        summary_text = self._summarize(user_input, result)

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¨˜éŒ²
        finding = AnalysisFinding(
            step=self._step,
            user_request=user_input,
            analysis_description=user_input[:120],
            result_summary=summary_text,
            figures=result.figures,
            success=result.success,
        )
        self.ctx.findings.append(finding)
        self.ctx.all_figures.extend(result.figures)

        self._llm_history.append({"role": "assistant", "content": summary_text})

        return {
            "text":    summary_text,
            "figures": result.figures,
            "step":    self._step,
            "success": result.success,
        }

    # â”€â”€ 3. summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def get_summary(self) -> str:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã®ã‚µãƒãƒªãƒ¼ã‚’è¿”ã™ã€‚"""
        if not self.ctx.findings:
            return "ã¾ã è§£æã¯å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

        lines = [
            "=" * 55,
            "ğŸ“Š è§£æã‚»ãƒƒã‚·ãƒ§ãƒ³ ã‚µãƒãƒªãƒ¼",
            "=" * 55,
            f"å®Ÿé¨“: {self.ctx.experiment_description[:120]}",
            f"ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {self._step}",
            f"ç”Ÿæˆã•ã‚ŒãŸå›³: {len(self.ctx.all_figures)} ä»¶",
            "",
        ]
        for f in self.ctx.findings:
            icon = "âœ…" if f.success else "âŒ"
            lines.append(f"{icon} Step {f.step}: {f.user_request[:70]}")
            if f.figures:
                for fig in f.figures:
                    lines.append(f"     ğŸ“Š {Path(fig).name}")
        lines.append("")
        lines.append(f"å›³ã®ä¿å­˜å…ˆ: {self.figure_dir}")
        lines.append("=" * 55)
        return "\n".join(lines)

    # â”€â”€ å†…éƒ¨ãƒ¡ã‚½ãƒƒãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _build_code_prompt(self, user_request: str) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å«ã‚“ã ã‚³ãƒ¼ãƒ‰ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚"""
        ctx_block = self.ctx.to_context_block()
        if ctx_block:
            return f"{ctx_block}\n\n## CURRENT ANALYSIS REQUEST\n{user_request}"
        return user_request

    def _summarize(self, user_request: str, result: CodeExecutionResult) -> str:
        """è§£æçµæœã‚’è‡ªç„¶è¨€èªã§ã‚µãƒãƒªãƒ¼ã—ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ææ¡ˆã™ã‚‹ã€‚"""
        if not result.success and not result.figures:
            return (
                f"âš ï¸ è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
                f"ã‚¨ãƒ©ãƒ¼å†…å®¹: {(result.error_message or '')[:300]}\n\n"
                "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰ãˆã‚‹ã‹ã€åˆ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"
            )

        fig_names = [Path(f).name for f in result.figures]
        stdout_snip = (result.stdout or "")[:400]

        # LLM ã«ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã•ã›ã‚‹
        summary_prompt = (
            f"Microbiome analysis result summary.\n\n"
            f"User requested: \"{user_request}\"\n"
            f"Figures generated: {', '.join(fig_names) if fig_names else 'none'}\n"
            f"Script output:\n{stdout_snip}\n\n"
            f"Previous context:\n{self.ctx.to_context_block()[:400]}\n\n"
            "Write a concise summary (3-5 sentences) in the SAME LANGUAGE the user uses:\n"
            "1. What was analyzed and what the result shows\n"
            "2. Any notable biological interpretation\n"
            "3. Suggest 1-2 natural next analysis steps"
        )

        summary = self._call_llm_simple(summary_prompt)

        # å›³ãƒªã‚¹ãƒˆã‚’æœ«å°¾ã«è¿½åŠ 
        if fig_names:
            summary += "\n\nğŸ“Š ç”Ÿæˆã•ã‚ŒãŸå›³:\n" + "\n".join(f"  â€¢ {n}" for n in fig_names)

        return summary

    def _call_llm_simple(self, prompt: str) -> str:
        """ã‚µãƒãƒªãƒ¼ãƒ»ã‚¦ã‚§ãƒ«ã‚«ãƒ ç”¨ã®å˜ç´”ãª LLM å‘¼ã³å‡ºã—ã€‚"""
        try:
            resp = _agent.call_ollama(
                [{"role": "user", "content": prompt}],
                self.model,
            )
            return resp.get("content", "ï¼ˆå¿œç­”ãªã—ï¼‰").strip()
        except Exception as e:
            return f"ï¼ˆLLM å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}ï¼‰"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLIã‚¿ãƒ¼ãƒŸãƒŠãƒ«ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œç”¨ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_HELP_TEXT = """
ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§:
  summary  â€” ã“ã‚Œã¾ã§ã®è§£æã‚’ã¾ã¨ã‚ã¦è¡¨ç¤º
  figures  â€” ç”Ÿæˆã•ã‚ŒãŸå›³ã®ãƒ‘ã‚¹ã‚’ä¸€è¦§è¡¨ç¤º
  context  â€” ç¾åœ¨ã®å®Ÿé¨“ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèª
  help     â€” ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º
  exit     â€” çµ‚äº†
"""


def run_terminal_chat(
    export_dir: str | Path,
    output_dir: str | None = None,
    figure_dir: str | None = None,
    model: str | None = None,
    log_callback=None,
    install_callback=None,
):
    """ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ã®å¯¾è©±å‹è§£æã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ã€‚"""
    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    base = Path.home() / "seq2pipe_results" / ts
    out_dir = output_dir or str(base / "output")
    fig_dir = figure_dir or str(base / "figures")

    def _log(m: str):
        # ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®è©³ç´°ãƒ­ã‚°ã¯è–„ãè¡¨ç¤º
        if m.startswith("  "):
            print(f"\033[2m{m}\033[0m", flush=True)
        else:
            print(m, flush=True)

    if log_callback:
        _log = log_callback  # noqa: F811

    def _install_cb(pkg: str) -> bool:
        ans = input(f"\nâš ï¸  ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ '{pkg}' ãŒå¿…è¦ã§ã™ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã‹? [Y/n]: ").strip().lower()
        return ans != "n"

    _cb = install_callback or _install_cb

    print()
    print("â”€" * 55)
    print("ğŸ§¬  seq2pipe  å¯¾è©±å‹è§£æãƒ¢ãƒ¼ãƒ‰")
    print("â”€" * 55)
    print(f"  ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿: {export_dir}")
    print(f"  å›³ã®å‡ºåŠ›å…ˆ        : {fig_dir}")
    print("â”€" * 55)

    session = InteractiveSession(
        export_dir=export_dir,
        output_dir=out_dir,
        figure_dir=fig_dir,
        model=model,
        log_callback=_log,
        install_callback=_cb,
    )

    if not session.export_files:
        print(f"\nâŒ {export_dir} ã« QIIME2 ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print("   feature-table.tsv / taxonomy/taxonomy.tsv ãªã©ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    n = sum(len(v) for v in session.export_files.values())
    print(f"\nâœ… {n} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ã¾ã—ãŸ:")
    for cat, paths in session.export_files.items():
        for p in paths:
            print(f"   [{cat}] {Path(p).name}")

    # â”€â”€ å®Ÿé¨“ã®èª¬æ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print()
    print("å®Ÿé¨“ã®æ¦‚è¦ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚")
    print("ï¼ˆä¾‹: ãƒã‚¦ã‚¹è…¸å†…ãƒ•ãƒ­ãƒ¼ãƒ© 16S ãƒ‡ãƒ¼ã‚¿ã€‚æŠ—ç”Ÿç‰©è³ªæŠ•ä¸ç¾¤ vs å¯¾ç…§ç¾¤ã€å„ 10 åŒ¹ï¼‰")
    print()
    try:
        description = input("ã‚ãªãŸ> ").strip()
    except (EOFError, KeyboardInterrupt):
        print(); return

    if not description:
        description = "QIIME2 ã§å‡¦ç†ã—ãŸãƒã‚¤ã‚¯ãƒ­ãƒã‚¤ã‚ªãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿"

    print("\nğŸ¤– è€ƒãˆä¸­...\n")
    welcome = session.setup(description)
    print(f"ğŸ¤–  {welcome}\n")

    # â”€â”€ ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("â”€" * 55)
    print("è§£ææŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚(help ã§ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§)\n")

    while True:
        try:
            user_input = input("ã‚ãªãŸ> ").strip()
        except (EOFError, KeyboardInterrupt):
            print()
            break

        if not user_input:
            continue

        # ç‰¹æ®Šã‚³ãƒãƒ³ãƒ‰
        cmd = user_input.lower()
        if cmd in ("exit", "quit", "q"):
            break
        if cmd == "summary":
            print("\n" + session.get_summary() + "\n")
            continue
        if cmd == "figures":
            figs = session.ctx.all_figures
            if figs:
                print("\nğŸ“Š ç”Ÿæˆã•ã‚ŒãŸå›³:")
                for f in figs:
                    print(f"   {f}")
                print()
            else:
                print("\nï¼ˆã¾ã å›³ã¯ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼‰\n")
            continue
        if cmd == "context":
            print("\n" + session.ctx.to_context_block() + "\n")
            continue
        if cmd == "help":
            print(_HELP_TEXT)
            continue

        # è§£æå®Ÿè¡Œ
        print()
        result = session.chat(user_input)
        print()
        print(f"ğŸ¤–  {result['text']}\n")
        print("â”€" * 55)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†
    print("\n" + session.get_summary())
    print("\nğŸ‘‹ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚\n")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    import argparse, sys

    parser = argparse.ArgumentParser(
        description="seq2pipe å¯¾è©±å‹è§£æãƒ¢ãƒ¼ãƒ‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=(
            "ä½¿ç”¨ä¾‹:\n"
            "  python chat_agent.py ~/data/exported/\n"
            "  python chat_agent.py ~/data/exported/ --model qwen2.5-coder:7b"
        ),
    )
    parser.add_argument("export_dir", help="QIIME2 ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--output-dir", help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆçœç•¥æ™‚ã¯ ~/seq2pipe_results/<timestamp>/ï¼‰")
    parser.add_argument("--figure-dir", help="å›³ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--model",      help="ä½¿ç”¨ã™ã‚‹ Ollama ãƒ¢ãƒ‡ãƒ«å")
    args = parser.parse_args()

    run_terminal_chat(
        export_dir=args.export_dir,
        output_dir=args.output_dir,
        figure_dir=args.figure_dir,
        model=args.model,
    )
