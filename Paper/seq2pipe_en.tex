% seq2pipe: A Local LLM-Powered AI Agent for Automated QIIME2 Pipeline Generation
% Compile with: pdflatex seq2pipe_en.tex  or  lualatex seq2pipe_en.tex

\documentclass[12pt, a4paper]{article}

% -------------------------------------------------------
% Packages
% -------------------------------------------------------
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{top=25mm, bottom=25mm, left=25mm, right=25mm}

\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue!70!black,
  urlcolor=blue!70!black,
  citecolor=blue!70!black,
  pdftitle={seq2pipe: A Local LLM-Powered AI Agent for Automated QIIME2 Pipeline Generation},
  pdfauthor={Rhizobium-gits, Claude (Anthropic)}
}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{abstract}
\usepackage{microtype}

% -------------------------------------------------------
% Code listing style
% -------------------------------------------------------
\definecolor{codebg}{RGB}{245,245,245}
\definecolor{codecomment}{RGB}{100,100,100}
\definecolor{codestring}{RGB}{160,40,40}
\definecolor{codekeyword}{RGB}{0,80,160}

\lstdefinestyle{mystyle}{
  backgroundcolor=\color{codebg},
  commentstyle=\color{codecomment}\itshape,
  keywordstyle=\color{codekeyword}\bfseries,
  stringstyle=\color{codestring},
  basicstyle=\ttfamily\small,
  breakatwhitespace=false,
  breaklines=true,
  keepspaces=true,
  numbers=left,
  numberstyle=\tiny\color{gray},
  numbersep=8pt,
  showspaces=false,
  showstringspaces=false,
  tabsize=2,
  frame=single,
  rulecolor=\color{gray!40},
  xleftmargin=15pt,
}
\lstset{style=mystyle}

% -------------------------------------------------------
% Header / Footer
% -------------------------------------------------------
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small seq2pipe Technical Report}
\fancyhead[R]{\small March 2026}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}

% -------------------------------------------------------
% Section format
% -------------------------------------------------------
\titleformat{\section}{\large\bfseries}{}{0em}{\thesection\quad}
\titleformat{\subsection}{\normalsize\bfseries}{}{0em}{\thesubsection\quad}

% -------------------------------------------------------
% Document
% -------------------------------------------------------
\begin{document}

% Title block
\begin{center}
  {\LARGE \textbf{seq2pipe}}\\[6pt]
  {\large A Local LLM-Powered AI Agent for Automated QIIME2 Pipeline Generation}\\[12pt]
  {\normalsize Rhizobium-gits \quad Claude (Anthropic)}\\[4pt]
  {\small \texttt{https://github.com/Rhizobium-gits/seq2pipe}}\\[4pt]
  {\small March 2, 2026}
\end{center}

\vspace{4mm}
\hrule
\vspace{4mm}

% Abstract
\begin{abstract}
We present \textbf{seq2pipe}, an interactive AI agent that automates end-to-end
microbiome analysis by combining a locally running large language model (LLM)
with the QIIME2 bioinformatics platform.
Given raw FASTQ sequencing data, seq2pipe automatically inspects
the data structure, designs an appropriate QIIME2 analysis pipeline,
generates ready-to-execute shell scripts, and then invokes a
\textbf{deterministic comprehensive analysis module} (\texttt{analysis.py})
that generates \textbf{29 publication-quality PNG figures without any LLM dependency}
--- including core diversity analyses (fig01--12), taxonomy compositions (fig13--15),
extended ecological analyses (fig16--25), and exhaustive community-level views (fig26--29).
Additionally, a \textbf{tool-calling code-generation agent} (\texttt{code\_agent.py})
reads actual exported file contents before writing Python code ---
eliminating format-mismatch errors common in blind one-shot generation.
The code agent follows a ``NEVER GIVE UP'' policy: on any Python error
it rewrites and retries until \texttt{EXIT CODE: 0}.
In autonomous mode (\texttt{--auto}), the system completes all analysis in 4 steps:
STEP~1 (QIIME2 pipeline) $\to$ STEP~1.5 (deterministic analysis, 29 figures) $\to$
STEP~2 (adaptive autonomous agent) $\to$ STEP~3 (HTML report).
An \textbf{adaptive autonomous mode} allows the agent to dynamically select
and execute additional analyses based on the data characteristics.
The \texttt{--classifier} option enables SILVA~138 taxonomic classification,
automatically generating genus/phylum composition figures (fig13--fig15).
After analysis completes, a \textbf{post-analysis refinement mode} is activated
where users can iteratively refine figures through natural language instructions
(e.g.\ ``change colors'', ``move legend outside'').
The entire workflow runs on the user's local machine, eliminating
dependencies on cloud services or paid APIs.
\end{abstract}

\vspace{4mm}
\hrule
\vspace{6mm}

% -------------------------------------------------------
\section{Introduction}
% -------------------------------------------------------

QIIME2~\cite{qiime2} (Quantitative Insights Into Microbial Ecology 2)
has become the de facto standard platform for 16S rRNA amplicon sequencing
analysis in microbiome research. However, QIIME2 carries a steep learning curve:
users must understand multiple data formats, select appropriate parameters for
denoising algorithms (DADA2), manage Docker-containerized execution environments,
and interpret multi-step analysis outputs. These barriers make QIIME2 inaccessible
to many researchers, particularly those without bioinformatics backgrounds.
Furthermore, visualization of QIIME2 outputs (\texttt{.qzv} artifacts) typically
requires an online viewer (\texttt{view.qiime2.org}), creating an additional
dependency that is unavailable in offline or restricted-network environments.

The rapid advancement of large language models (LLMs) has opened the door to
domain-specific analysis automation through natural language~\cite{brown2020gpt3}.
Yet cloud-hosted LLM services introduce concerns about cost, data privacy,
and network availability. The emergence of local LLM inference frameworks
such as Ollama~\cite{ollama} allows high-quality language reasoning to be
performed entirely on commodity hardware, resolving these concerns.

In this report, we describe the design, architecture, and implementation of
\textbf{seq2pipe}, an interactive AI agent that integrates local LLM inference
with QIIME2 to provide a fully automated, offline-capable microbiome analysis
assistant. seq2pipe goes well beyond pipeline generation: its deterministic
comprehensive analysis module reliably produces 29 publication-quality figures,
the LLM agent provides flexible additional analysis,
and the system automatically generates bilingual research reports --- all within
a single conversational interface.

% -------------------------------------------------------
\section{Background and Related Work}
% -------------------------------------------------------

\subsection{Complexity of QIIME2 Analysis}

A complete QIIME2 microbiome analysis involves at least eight major steps:
data import, quality inspection, denoising (ASV generation via DADA2),
feature table summarization, phylogenetic tree construction,
taxonomic classification (using SILVA~\cite{silva}),
diversity analysis, and differential abundance analysis.
Each step requires careful selection of command-line parameters that depend on
the sequencing library configuration (paired-end vs.\ single-end),
the 16S rRNA hypervariable region amplified (V1--V3, V3--V4, V4, etc.),
and primer sequences.

\subsection{LLM Agents and Function Calling}

The ReAct framework~\cite{yao2023react} established the paradigm of
LLMs that interleave reasoning and action --- calling external tools
at appropriate times to gather information or perform operations
that cannot be accomplished through text generation alone.
Modern instruction-tuned LLMs supporting function calling
can select and invoke pre-defined tools with structured arguments,
enabling autonomous task completion.

\subsection{Local LLM Inference with Ollama}

Ollama wraps the \texttt{llama.cpp} inference engine into a single binary
distributable across macOS, Linux, and Windows.
It exposes a REST API (\texttt{/api/chat}) compatible with the
OpenAI Chat Completions format, including support for function calling,
making it an ideal backend for locally deployed AI agents.

% -------------------------------------------------------
\section{System Design}
% -------------------------------------------------------

\subsection{Design Principles}

seq2pipe was developed according to eight core design principles:

\begin{enumerate}[leftmargin=2em]
  \item \textbf{Zero external dependencies}:
    Only Python's standard library (\texttt{json}, \texttt{urllib},
    \texttt{subprocess}, \texttt{pathlib}, \texttt{socket}, etc.) is used,
    eliminating the need for \texttt{pip install}.
  \item \textbf{Fully local execution}:
    Ollama's local inference engine is used exclusively,
    requiring no internet connection after initial setup.
  \item \textbf{Cross-platform compatibility}:
    The agent runs on macOS, Linux, and Windows.
  \item \textbf{Safe command execution}:
    All shell commands require explicit user confirmation before execution.
  \item \textbf{Embedded domain knowledge}:
    The system prompt encodes a complete QIIME2 workflow knowledge base.
  \item \textbf{Multilingual UI}:
    The user selects Japanese or English at startup; all AI responses
    and auto-generated reports follow this preference.
  \item \textbf{Robust error handling}:
    Connection errors, timeouts, empty responses, and filesystem errors
    are all caught and reported with user-friendly messages.
  \item \textbf{Guaranteed deterministic analysis}:
    An LLM-independent comprehensive analysis module (\texttt{analysis.py})
    reliably generates 29 figures regardless of model quality.
\end{enumerate}

\subsection{Overall Architecture}

Figure~\ref{fig:arch} illustrates the 3-step architecture of seq2pipe.
The user launches \texttt{cli.py} via platform-specific launch scripts.
\texttt{cli.py} presents a rainbow ASCII banner and prompts the user to
select between two operating modes.
In \texttt{--auto} mode, a 4-step automated pipeline executes:
STEP~1 runs \texttt{pipeline\_runner.py} for the QIIME2 pipeline and exports results,
STEP~1.5 runs \texttt{analysis.py} to deterministically generate 29 PNG figures,
STEP~2 launches an adaptive autonomous agent for data-driven additional analyses,
and STEP~3 auto-generates an HTML report.
In Mode~1 (directed analysis), \texttt{code\_agent.py} provides
vibe-local-style tool-calling code generation.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.95\linewidth]{../Figure/architecture.png}
  \caption{Four-step architecture of seq2pipe}
  \label{fig:arch}
\end{figure}

% -------------------------------------------------------
\section{Implementation Details}
% -------------------------------------------------------

\subsection{Startup Sequence and Multilingual UI}

On launch, \texttt{select\_language()} prompts the user to choose
Japanese (\texttt{ja}) or English (\texttt{en}).
The selection is stored in the \texttt{LANG} global variable, and the
\texttt{ui()} function returns all interface text in the chosen language.
Auto-generated reports follow the same language setting.

\texttt{check\_python\_deps()} verifies that numpy, pandas, matplotlib,
and seaborn are available at startup via \texttt{subprocess},
guiding the user to install any missing packages before analysis begins.

\subsection{Embedding Domain Knowledge in the System Prompt}

The \texttt{SYSTEM\_PROMPT} variable contains a comprehensive QIIME2
workflow knowledge base. This includes:

\begin{itemize}
  \item Automatic data format detection criteria
    (e.g., paired-end detection via \texttt{*\_R1*.fastq.gz} patterns)
  \item Complete QIIME2 commands for all eight analysis steps
    (import through differential abundance analysis)
  \item Region-specific recommended parameters for
    V1--V3 (27F/338R), V3--V4 (341F/806R), and V4 (515F/806R) amplicons
  \item Docker execution command templates
  \item Metadata file format specifications
  \item SILVA 138 taxonomic hierarchy explanation
  \item Common errors and troubleshooting guidance
  \item Python downstream analysis and autonomous exploration mode guidelines
\end{itemize}

By embedding this knowledge directly into the system prompt,
a general-purpose code LLM is transformed into a QIIME2 domain expert.

\subsection{Tool Definitions and Function Calling}

seq2pipe uses two separate tool sets.
\texttt{qiime2\_agent.py} defines 11 tools (Table~\ref{tab:tools_qiime2})
for QIIME2 pipeline orchestration.
\texttt{code\_agent.py} defines 5 tools (Table~\ref{tab:tools_code})
for Python code generation following the vibe-local paradigm:
the LLM \emph{reads the actual file contents before writing code},
eliminating format-mismatch errors.

\begin{table}[h]
  \centering
  \caption{Tools in \texttt{qiime2\_agent.py} (QIIME2 pipeline orchestration)}
  \label{tab:tools_qiime2}
  \begin{tabular}{lp{7.5cm}}
    \toprule
    \textbf{Tool Name} & \textbf{Function} \\
    \midrule
    \texttt{inspect\_directory} &
      Lists files with sizes; auto-identifies FASTQ, QZA, metadata \\
    \texttt{read\_file} &
      Reads text files (TSV, CSV, Markdown, etc.) up to 50 lines \\
    \texttt{write\_file} &
      Writes scripts, manifests, and README files \\
    \texttt{edit\_file} &
      Replaces a unique string in an existing file \\
    \texttt{generate\_manifest} &
      Auto-generates QIIME2 manifest TSV from a FASTQ directory \\
    \texttt{run\_command} &
      Executes shell commands after user confirmation;
      auto-detects QIIME2 conda bin, supports \texttt{SEQ2PIPE\_AUTO\_YES} \\
    \texttt{check\_system} &
      Verifies Docker, Ollama, Python, and disk space \\
    \texttt{set\_plot\_config} &
      Configures matplotlib style, palette, DPI, and output format \\
    \texttt{execute\_python} &
      Executes Python analysis code; saves figures to \texttt{FIGURE\_DIR};
      logs steps to \texttt{ANALYSIS\_LOG} \\
    \texttt{build\_report\_tex} &
      Builds TeX/PDF reports from \texttt{ANALYSIS\_LOG} via lualatex \\
    \texttt{log\_analysis\_step} &
      Manually registers QIIME2 steps into \texttt{ANALYSIS\_LOG} \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[h]
  \centering
  \caption{Tools in \texttt{code\_agent.py} (vibe-local style code generation)}
  \label{tab:tools_code}
  \begin{tabular}{lp{8cm}}
    \toprule
    \textbf{Tool Name} & \textbf{Function} \\
    \midrule
    \texttt{list\_files} &
      Lists all files in the exported results directory with their sizes \\
    \texttt{read\_file} &
      Returns the full content of a file (TSV, CSV, Python, etc.) to the LLM,
      allowing it to inspect column names and data format \emph{before} writing code \\
    \texttt{write\_file} &
      Writes a Python script atomically (via \texttt{mkstemp}+\texttt{replace})
      to prevent partial writes \\
    \texttt{run\_python} &
      Executes the written script using the QIIME2 conda Python interpreter;
      returns stdout, stderr, and exit code; detects new figure files \\
    \texttt{install\_package} &
      Detects \texttt{ModuleNotFoundError}, prompts user for approval,
      then runs \texttt{pip install} \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Deterministic Comprehensive Analysis Module (\texttt{analysis.py})}

To improve the reliability of \texttt{--auto} mode, we introduced a
deterministic comprehensive analysis module \texttt{analysis.py} that
operates entirely without LLM dependency.
The \texttt{run\_comprehensive\_analysis()} function reads QIIME2 exported
data directly and uses pandas, matplotlib, seaborn, and scikit-learn to
generate 29 publication-quality PNG figures (Table~\ref{tab:analysis_figures}).

Because this module does not depend on LLM response quality,
identical analysis results are produced regardless of which model is used.
When SILVA~138 classifier results are available, fig13--fig15
(genus/phylum composition) are automatically generated.
Figures fig16--25 provide extended ecological analyses (rarefaction curves,
NMDS ordination, rank-abundance, alluvial taxonomy, co-occurrence networks,
family-level composition, core microbiome, differential abundance,
sample clustering, and correlation analysis).
Figures fig26--29 offer exhaustive community-level views (class/order composition,
additional diversity indices, and ASV overlap patterns).

Each PCoA figure (fig05--08) reports the percentage of variance explained
on each axis, computed via eigendecomposition of the centred distance matrix.
The \texttt{generate\_analysis\_summary()} function produces a structured
JSON summary of all analysis results, including diversity statistics,
taxonomic composition, and figure metadata, which is consumed by the
report generator.

\begin{table}[h]
  \centering
  \caption{29 figures generated by \texttt{analysis.py}}
  \label{tab:analysis_figures}
  \begin{tabular}{clp{5.5cm}}
    \toprule
    \textbf{Figure} & \textbf{Analysis} & \textbf{Key Packages} \\
    \midrule
    \multicolumn{3}{l}{\textit{Core analysis (fig01--12)}} \\
    fig01 & DADA2 denoising statistics & pandas, matplotlib \\
    fig02 & Sequencing depth per sample & pandas, matplotlib \\
    fig03 & Alpha diversity boxplots & pandas, seaborn \\
    fig04 & Shannon diversity per sample & pandas, seaborn \\
    fig05 & PCoA (Bray-Curtis) & sklearn MDS \\
    fig06 & PCoA (Jaccard) & sklearn MDS \\
    fig07 & PCoA (Unweighted UniFrac) & sklearn MDS \\
    fig08 & PCoA (Weighted UniFrac) & sklearn MDS \\
    fig09 & Beta diversity heatmaps (2$\times$2) & seaborn \\
    fig10 & Top 30 ASV heatmap & seaborn \\
    fig11 & Alpha diversity correlations & matplotlib \\
    fig12 & ASV richness vs depth & matplotlib \\
    \midrule
    \multicolumn{3}{l}{\textit{Taxonomy (fig13--15; requires classifier)}} \\
    fig13 & Genus-level stacked bar$^*$ & matplotlib \\
    fig14 & Phylum-level stacked bar$^*$ & matplotlib \\
    fig15 & Genus-level heatmap$^*$ & seaborn \\
    \midrule
    \multicolumn{3}{l}{\textit{Extended ecological analysis (fig16--25)}} \\
    fig16 & Rarefaction curves & numpy \\
    fig17 & NMDS (Bray-Curtis) & sklearn MDS \\
    fig18 & Rank-Abundance curve & matplotlib \\
    fig19 & Taxonomic alluvial plot (Phylum$\to$Class$\to$Order) & matplotlib \\
    fig20 & Genus co-occurrence network & networkx \\
    fig21 & Family-level stacked bar$^*$ & matplotlib \\
    fig22 & Core microbiome (prevalence vs abundance)$^*$ & matplotlib \\
    fig23 & Differential abundance volcano$^*$$^{\dagger}$ & scipy, matplotlib \\
    fig24 & Sample dendrogram (UPGMA) & scipy hierarchy \\
    fig25 & Genus Spearman correlation clustermap$^*$ & scipy, seaborn \\
    \midrule
    \multicolumn{3}{l}{\textit{Exhaustive community views (fig26--29)}} \\
    fig26 & Class-level stacked bar$^*$ & matplotlib \\
    fig27 & Order-level stacked bar$^*$ & matplotlib \\
    fig28 & Simpson diversity + Pielou evenness & matplotlib \\
    fig29 & ASV overlap pattern (UpSet-style) & matplotlib \\
    \bottomrule
    \multicolumn{3}{l}{\small $^*$ Generated only when SILVA 138 classifier results are available} \\
    \multicolumn{3}{l}{\small $^{\dagger}$ Benjamini--Hochberg FDR correction applied}
  \end{tabular}
\end{table}

\subsection{The Code Agent Loop (vibe-local Style)}

\texttt{run\_coding\_agent()} in \texttt{code\_agent.py} implements
a ``read-first, code-second'' tool-calling loop.
The LLM is instructed to \textbf{always call a tool immediately}
(TOOL FIRST principle) and \textbf{never give up on errors}
(NEVER GIVE UP principle).
The typical sequence per analysis task is:

\begin{enumerate}[leftmargin=2em]
  \item \texttt{list\_files} --- discover available exported files
  \item \texttt{read\_file} --- read a target file to inspect
    column names and data format
  \item \texttt{write\_file} --- generate a Python script that uses
    the exact column names seen in step 2
  \item \texttt{run\_python} --- execute the script;
    if exit code $\neq 0$, the LLM reads the traceback and loops
    back to \texttt{write\_file} to fix the error
\end{enumerate}

Listing~\ref{lst:loop} shows the core loop structure.

\begin{lstlisting}[language=Python, caption={Core tool-calling loop in run\_coding\_agent()}, label={lst:loop}]
def run_coding_agent(export_files, user_prompt, ...):
    messages = [{"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user",   "content": task}]
    steps = 0
    while steps < max_steps:
        response = call_ollama(messages, model, tools=_TOOL_DEFS)
        tool_calls = response.get("tool_calls", [])

        if not tool_calls:
            break  # LLM says it's done

        for tc in tool_calls:
            fn   = tc["function"]
            name = fn["name"]
            args = fn["arguments"]  # dict or JSON string
            if isinstance(args, str):
                args = json.loads(args)

            result, new_figs = _exec_tool(name, args, ...)
            figures.extend(new_figs)
            messages.append({"role": "tool",
                              "name": name,
                              "content": result[:4000]})
        steps += 1

    return CodeExecutionResult(success=bool(figures), figures=figures)
\end{lstlisting}

\subsection{Robustness Enhancements for Small LLMs}

Smaller models (7B parameters and below) often do not emit structured
\texttt{tool\_calls} objects via the Ollama API; instead, they embed
JSON tool invocations as plain text in the response body.
seq2pipe handles this through a four-layer fallback system implemented
in \texttt{run\_coding\_agent()}:

\begin{enumerate}[leftmargin=2em]
  \item \textbf{Text-based tool call parser (\texttt{\_parse\_text\_tool\_calls})}:
    When \texttt{tool\_calls} is empty, the response body is searched
    for JSON objects using five heuristic patterns:
    (a) \texttt{```json} code blocks,
    (b) the entire response as a JSON object,
    (c) inline regex scan for \texttt{"name": "..."} patterns,
    (d) name-less JSON objects inferred as \texttt{write\_file}/\texttt{list\_files}
        by key inspection, and
    (e) a lenient regex-based broken-JSON extractor.

  \item \textbf{Auto-inject \texttt{run\_python}}:
    Immediately after \texttt{write\_file} successfully writes a
    \texttt{.py} file, \texttt{run\_python} is automatically executed
    without waiting for the LLM to call it --- avoiding the common
    failure mode where small models write a script but forget to run it.

  \item \textbf{Step-6 fallback to 1-shot generation}:
    A \texttt{\_run\_python\_count} counter tracks how many times
    \texttt{run\_python} has been called (both via tool calls and
    auto-inject). If no execution has occurred after 5 steps,
    \texttt{run\_coding\_agent()} falls back to \texttt{run\_code\_agent()},
    which performs 1-shot code generation with up to 3 error-correction
    retries --- ensuring figure output even when the tool-calling loop stalls.

  \item \textbf{Repetition detector in \texttt{call\_ollama()}}:
    A sliding-window check truncates generation when the same 50-character
    chunk appears four consecutive times, or when total output exceeds
    20\,000 characters --- preventing infinite loops caused by degenerate
    model outputs.
\end{enumerate}

Together, these mechanisms guarantee that at least one analysis figure
is produced regardless of model size or Ollama version.
Furthermore, since \texttt{analysis.py} runs before the LLM agent,
29 core figures are always generated regardless of LLM performance.

\subsection{The QIIME2 Pipeline Agent Loop}

\texttt{run\_agent\_loop()} in \texttt{qiime2\_agent.py} controls
the QIIME2 pipeline generation cycle.
It sends conversation history to the LLM, detects tool calls,
executes them sequentially, appends results, and repeats until
the LLM produces a text-only response.
An empty-response guard retries automatically if the LLM returns
neither content nor tool calls.

\subsection{SILVA 138 Classifier Auto-Discovery (\texttt{--classifier})}

The \texttt{--classifier} option was added to \texttt{cli.py} to specify
the path to a SILVA~138 Naive Bayes classifier.
When no path is explicitly given, \texttt{\_find\_classifier()} searches
candidate locations:
\texttt{\textasciitilde/seq2pipe/silva-138-99-nb-classifier.qza},
\texttt{\textasciitilde/classifiers/} subdirectory, and
\texttt{/usr/local/share/qiime2/} directory.
When found, QIIME2 performs taxonomic classification, and
\texttt{analysis.py} automatically generates genus/phylum composition figures.

\subsection{Communication with the Ollama API and Error Handling}

The \texttt{call\_ollama()} function sends JSON requests to Ollama's
\texttt{/api/chat} endpoint with streaming enabled, and processes
server-sent events line by line using only \texttt{urllib.request}
from Python's standard library.

Comprehensive error handling covers:
\begin{itemize}
  \item \texttt{urllib.error.HTTPError}: Ollama server HTTP errors (4xx/5xx)
  \item \texttt{urllib.error.URLError + socket.timeout}:
    distinguishes timeouts (300 s) from connection-refused errors
    (Ollama not running)
  \item \texttt{socket.timeout / TimeoutError}:
    socket-level timeout fallback
\end{itemize}

\subsection{Automatic PNG Conversion for Figures}

When the LLM generates \texttt{plt.savefig()} calls with \texttt{.pdf} or
\texttt{.svg} extensions, the resulting files cannot be opened in macOS Preview.
The \texttt{\_convert\_new\_figs()} helper automatically detects such files
immediately after code execution and converts them to PNG using the macOS
built-in \texttt{sips} command, then removes the original.
The system prompt was also strengthened with an explicit instruction that
the extension ``MUST be \texttt{.png}'', reducing the frequency of incorrect
extension choices from the LLM.

\subsection{Diversity Analysis Without Metadata}

The standard \texttt{qiime diversity core-metrics-phylogenetic} command
requires \texttt{--m-metadata-file} as a mandatory argument; when no metadata
file is provided, the entire diversity analysis step (Step 7) was previously
skipped. This was corrected by adding a fallback branch that individually
invokes \texttt{qiime diversity alpha}, \texttt{qiime diversity beta},
\texttt{qiime diversity alpha-phylogenetic}, and
\texttt{qiime diversity beta-phylogenetic} for each metric
(Shannon, Faith's PD, Bray-Curtis, UniFrac, etc.) when metadata is absent.

\subsection{Post-Analysis Refinement Mode and Report Generation}

After analysis completes, \texttt{\_run\_refinement\_session()} launches
an interactive loop where users can issue natural-language instructions to
refine the generated figures. Each instruction is passed to
\texttt{run\_refinement\_loop()}, which has the LLM modify the existing
\texttt{analysis.py} script and re-execute it. The loop exits on empty
Enter or \texttt{quit}.

In \texttt{--auto} mode, an HTML report is automatically generated as STEP~3.
Additionally, within the refinement session, keyword detection triggers report generation:

\begin{itemize}
  \item ``report'' / ``html'' $\rightarrow$ \texttt{generate\_html\_report()}:
    a self-contained HTML file with figures embedded as base64 data URIs,
    LLM-generated Japanese captions per figure, an overall summary, and
    a parameter table.
  \item ``PDF'' / ``latex'' $\rightarrow$ \texttt{generate\_latex\_report()}:
    auto-detects \texttt{lualatex} (preferred, using \texttt{luatexja-preset}
    for Japanese) or \texttt{xelatex} (fallback, using \texttt{xeCJK} +
    Hiragino fonts on macOS). Compiles twice for cross-reference resolution.
    If no LaTeX engine is found, \texttt{report.tex} is saved for
    manual compilation.
\end{itemize}

\subsection{Python Downstream Analysis}

\texttt{tool\_execute\_python()} executes Python code via
\texttt{subprocess.run()} with a configurable timeout.
Before execution, a preamble is prepended that injects
\texttt{FIGURE\_DIR}, \texttt{DPI}, and required imports,
allowing the LLM to generate analysis code without knowing exact paths.
Generated figures are detected by comparing the directory listing before
and after execution, and PDF/SVG files are immediately converted to PNG.

\subsection{Automatic Manifest Generation}

The \texttt{tool\_generate\_manifest()} function uses regular expressions
(\texttt{re.sub(count=1)}) to parse FASTQ filenames,
automatically generating QIIME2 manifest TSV files for both
paired-end and single-end data. R2 file lookup is implemented
with a dictionary for O(1) performance, scaling to large datasets.
If no R1/R2 pairs are found, the function returns an error
without writing an empty manifest. Partial matching rates below 80\%
trigger an enhanced warning showing the mismatch percentage.
Path translation to Docker container-internal paths
(default: \texttt{/data/output}) is performed automatically.

\subsection{Cross-Platform Compatibility}

Three platform-specific differences are handled explicitly:

\begin{itemize}
  \item \textbf{Docker detection}:
    On macOS, the Docker Desktop binary path
    (\texttt{/Applications/Docker.app/.../docker})
    is checked first; on other platforms, \texttt{shutil.which("docker")}
    is used.
  \item \textbf{Windows ANSI color support}:
    Calling \texttt{os.system("")} activates ANSI escape sequence
    processing in Windows 10+ terminals.
  \item \textbf{Separated launch scripts}:
    Bash shell scripts for macOS/Linux and
    PowerShell + batch files for Windows are provided separately.
\end{itemize}

% -------------------------------------------------------
\section{Analysis Workflow}
% -------------------------------------------------------

The QIIME2 pipeline generated by seq2pipe consists of eight steps
as summarized in Table~\ref{tab:workflow}.

\begin{table}[h]
  \centering
  \caption{Overview of the generated QIIME2 analysis pipeline}
  \label{tab:workflow}
  \begin{tabular}{clp{7.5cm}}
    \toprule
    \textbf{Step} & \textbf{Process} & \textbf{Key Command} \\
    \midrule
    1 & Data import &
      \texttt{qiime tools import} \\
    2 & Quality visualization &
      \texttt{qiime demux summarize} \\
    3 & Denoising (ASV generation) &
      \texttt{qiime dada2 denoise-paired} \\
    4 & Feature table summarization &
      \texttt{qiime feature-table summarize} \\
    5 & Phylogenetic tree construction &
      \texttt{qiime phylogeny align-to-tree-mafft-fasttree} \\
    6 & Taxonomic classification &
      \texttt{qiime feature-classifier classify-sklearn} \\
    7 & Diversity analysis &
      \texttt{qiime diversity core-metrics-phylogenetic} \\
    8 & Differential abundance (opt.) &
      \texttt{qiime composition ancombc} \\
    \bottomrule
  \end{tabular}
\end{table}

Taxonomic classification is performed using a Naive Bayes classifier
trained on the SILVA 138 reference database~\cite{silva}.
Primer trim lengths and truncation positions are automatically
adjusted based on the detected hypervariable region
(V1--V3: 27F/338R, V3--V4: 341F/806R, V4: 515F/806R).

Following QIIME2 analysis, the \texttt{--auto} mode executes a 4-step
automated pipeline:

\begin{enumerate}[leftmargin=2em]
  \item \textbf{STEP 1}: QIIME2 pipeline (8 steps above) + result export
  \item \textbf{STEP 1.5}: Deterministic comprehensive analysis (\texttt{analysis.py})
    $\to$ \textbf{29 PNG figures}:
    \begin{itemize}
      \item fig01--12: Core analysis (DADA2 stats, depth, alpha/beta diversity, heatmaps)
      \item fig13--15: Taxonomy (genus/phylum composition, genus heatmap; with classifier)
      \item fig16--25: Extended ecological analysis (rarefaction, NMDS, rank-abundance,
        alluvial taxonomy, co-occurrence network, family composition, core microbiome,
        differential abundance volcano, sample dendrogram, correlation clustermap)
      \item fig26--29: Exhaustive community views (class/order composition,
        Simpson diversity + Pielou evenness, ASV overlap UpSet-style)
    \end{itemize}
  \item \textbf{STEP 2}: Adaptive autonomous agent --- dynamically selects
    and executes additional analyses based on data characteristics
  \item \textbf{STEP 3}: Automatic HTML report generation (base64-embedded figures)
\end{enumerate}

Upon completion, the post-analysis refinement mode activates, allowing
natural-language figure refinement and additional report generation
(\texttt{report\_generator.py}).

% -------------------------------------------------------
\section{Supported Models and Performance}
% -------------------------------------------------------

seq2pipe is model-agnostic and can be used with any LLM available
in Ollama. Table~\ref{tab:models} lists recommended models.

\begin{table}[h]
  \centering
  \caption{Supported models}
  \label{tab:models}
  \begin{tabular}{llll}
    \toprule
    \textbf{Model} & \textbf{RAM Required} & \textbf{Size} & \textbf{Characteristics} \\
    \midrule
    \texttt{qwen2.5-coder:7b} & 8 GB+ & \textasciitilde4.7 GB &
      Code generation optimized (recommended) \\
    \texttt{qwen2.5-coder:3b} & 4 GB+ & \textasciitilde1.9 GB &
      Lightweight and fast \\
    \texttt{llama3.2:3b}      & 4 GB+ & \textasciitilde2.0 GB &
      General purpose, strong dialogue \\
    \texttt{qwen3:8b}         & 16 GB+ & \textasciitilde5.2 GB &
      Highest quality, strong reasoning \\
    \bottomrule
  \end{tabular}
\end{table}

Note that the deterministic analysis (STEP~2) via \texttt{analysis.py}
does not use the LLM, so all 29 figures are generated identically
regardless of model choice. Model quality primarily affects the flexibility
of Mode~1 (directed analysis) and the quality of the refinement mode.

% -------------------------------------------------------
\section{Setup and Launch}
% -------------------------------------------------------

\subsection{Software Requirements}

Table~\ref{tab:requirements} summarizes the required software stack.

\begin{table}[h]
  \centering
  \caption{Software requirements}
  \label{tab:requirements}
  \begin{tabular}{lll}
    \toprule
    \textbf{Software} & \textbf{Purpose} & \textbf{Installation} \\
    \midrule
    Python 3.9+ & Agent runtime & Typically pre-installed \\
    Ollama & Local LLM inference & Automated via \texttt{setup.sh} \\
    Docker Desktop/Engine & QIIME2 execution environment & Manual install \\
    numpy, pandas, etc. & Python downstream analysis &
      Automated via \texttt{setup.sh} \\
    lualatex / xelatex (optional) & PDF report compilation &
      \texttt{brew install --cask mactex-no-gui} \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Launch Sequence}

\begin{enumerate}[leftmargin=2em]
  \item Run \texttt{setup.sh} (macOS/Linux) or \texttt{setup.bat} (Windows)
    to install Ollama, download the LLM model, and install Python packages.
  \item Run \texttt{launch.sh} / \texttt{launch.bat}: the script verifies
    Ollama and Docker availability, then starts the agent.
  \item Select Japanese or English at the language prompt.
  \item Through natural language dialogue, provide the data directory path
    and specify the desired analyses
    (taxonomic composition, diversity, differential abundance, etc.).
  \item The agent automatically inspects the data, generates a customized
    script bundle, runs Python analyses, and produces a report.
\end{enumerate}

% -------------------------------------------------------
\section{Example Results}
% -------------------------------------------------------

To demonstrate seq2pipe's end-to-end capability, we analysed
10 human stool samples (TEST01--TEST10, freeze-dried, Illumina MiSeq
paired-end V3--V4) without manual intervention.
The full pipeline ran in a single command:

\begin{lstlisting}[language=bash, caption={Fully autonomous analysis with seq2pipe}]
./launch.sh --fastq-dir ~/input --auto --threads 1
\end{lstlisting}

STEP~1 executed the QIIME2 pipeline (DADA2 denoising +
phylogenetic tree + diversity analysis + SILVA~138 taxonomic classification),
STEP~1.5 generated 29 PNG figures via \texttt{analysis.py},
STEP~2 launched the adaptive autonomous agent for data-driven additional analyses, and
STEP~3 produced an HTML report automatically.
Figures are stored in the \texttt{Figure/} directory of this repository.

\subsection{DADA2 Denoising Statistics}

The progression of reads through each DADA2 stage
(input $\rightarrow$ filtered $\rightarrow$ denoised $\rightarrow$
merged $\rightarrow$ non-chimeric) is shown in Figure~\ref{fig:dada2}.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.92\textwidth]{../Figure/fig01_dada2_stats.png}
  \caption{DADA2 denoising statistics for 10 stool samples.
    The figure reveals consistent filtering efficiency across samples.}
  \label{fig:dada2}
\end{figure}

\subsection{Alpha Diversity}

Three alpha diversity metrics (Shannon entropy, Faith's PD, and
observed ASVs) were computed per sample and displayed
as boxplots (Figure~\ref{fig:alpha}).
A per-sample Shannon diversity strip plot is shown in Figure~\ref{fig:shannon}.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.92\textwidth]{../Figure/fig03_alpha_diversity.png}
  \caption{Alpha diversity of 10 human stool samples.
    Each panel shows a different metric computed from the DADA2-denoised
    feature table.}
  \label{fig:alpha}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figure/fig04_shannon_per_sample.png}
  \caption{Shannon alpha diversity per sample (strip plot).}
  \label{fig:shannon}
\end{figure}

\subsection{Beta Diversity}

Beta diversity was assessed using four dissimilarity measures.
Bray--Curtis PCoA (Figure~\ref{fig:bc}) and Unweighted UniFrac PCoA
(Figure~\ref{fig:unifrac}) were computed via scikit-learn MDS
(\texttt{n\_components=2, dissimilarity=`precomputed'}).
A 2$\times$2 panel of distance heatmaps is shown in Figure~\ref{fig:beta_heatmaps}.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figure/fig05_pcoa_braycurtis.png}
  \caption{Bray--Curtis PCoA. Samples are coloured by ID
    and labelled directly on the plot.}
  \label{fig:bc}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figure/fig07_pcoa_unweighted_unifrac.png}
  \caption{Unweighted UniFrac PCoA. Phylogenetic distances computed by
    QIIME2 are projected onto two MDS dimensions.}
  \label{fig:unifrac}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.92\textwidth]{../Figure/fig09_beta_distance_heatmaps.png}
  \caption{Beta diversity distance heatmaps (2$\times$2):
    Bray-Curtis, Jaccard, Unweighted UniFrac, and Weighted UniFrac.}
  \label{fig:beta_heatmaps}
\end{figure}

\subsection{Taxonomic Composition}

Using SILVA~138 classifier results, genus-level stacked bar charts
(Figure~\ref{fig:genus}) and genus-level heatmaps
(Figure~\ref{fig:genus_heatmap}) were generated.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.92\textwidth]{../Figure/fig13_genus_composition.png}
  \caption{Genus-level taxonomic composition (stacked bar chart).
    Top genera are colour-coded to show microbial community structure
    across samples.}
  \label{fig:genus}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.92\textwidth]{../Figure/fig15_genus_heatmap.png}
  \caption{Genus-level heatmap showing relative abundances across samples.}
  \label{fig:genus_heatmap}
\end{figure}

All 29 figures and the HTML report were generated automatically by
\texttt{analysis.py} and \texttt{report\_generator.py}.

\subsection{Extended and Exhaustive Analysis}

The extended ecological analyses (fig16--25) and exhaustive community views
(fig26--29) provide deeper insights beyond the core diversity metrics.
Figure~16 shows rarefaction curves that confirm adequate sequencing depth
across all samples. Figure~20 reveals genus co-occurrence patterns through
a network analysis, highlighting positively and negatively correlated taxa.
Figure~28 complements Shannon entropy with Simpson diversity and Pielou evenness
indices, providing a more complete picture of community structure.
The differential abundance volcano plot (fig23) applies Benjamini--Hochberg
FDR correction to control for multiple testing, and the UpSet-style ASV
overlap pattern (fig29) visualises shared and unique ASVs across sample
intersections.

% -------------------------------------------------------
\section{Discussion}
% -------------------------------------------------------

\subsection{Achieved Goals}

seq2pipe achieves the following:

\begin{itemize}
  \item Zero-dependency implementation using only Python's standard library
  \item Fully offline operation via local LLM inference
  \item Complete cross-platform support (macOS / Linux / Windows)
  \item Automatic recognition of FASTQ data structure and adaptive pipeline generation
  \item Safe QIIME2 command execution with explicit user confirmation
  \item \textbf{Deterministic comprehensive analysis module (\texttt{analysis.py})}:
    29 publication-quality PNG figures generated reliably without LLM dependency
  \item \textbf{SILVA 138 classifier auto-discovery (\texttt{--classifier})}:
    automatic genus/phylum composition figure generation
  \item \textbf{4-step automated pipeline}:
    STEP~1 (QIIME2) $\to$ STEP~1.5 (deterministic analysis, 29 figures)
    $\to$ STEP~2 (adaptive autonomous agent) $\to$ STEP~3 (HTML report)
  \item \textbf{Adaptive autonomous agent}:
    dynamically selects and executes additional analyses based on
    data characteristics, extending beyond the deterministic figure set
  \item \textbf{Vibe-local style tool-calling code agent} that reads actual file
    contents before writing code, eliminating format-mismatch errors
  \item \textbf{Automated error correction}: NEVER GIVE UP policy ---
    rewrites and retries until \texttt{EXIT CODE: 0}
  \item \textbf{Small-LLM robustness}: four-layer fallback system
  \item Two operation modes: directed (Mode 1) and fully autonomous (Mode 2)
  \item \textbf{Post-analysis refinement mode}:
    iterative figure refinement via natural language
  \item \textbf{Automatic PDF/SVG to PNG conversion (\texttt{sips})}:
    no extra dependencies on macOS
  \item \textbf{Metadata-free diversity analysis}:
    individual commands as fallback when metadata is absent
  \item \textbf{HTML and LaTeX/PDF report auto-generation}
  \item Startup language selection UI (Japanese / English)
\end{itemize}

\subsection{Current Limitations}

\begin{itemize}
  \item The accuracy of generated QIIME2 commands depends on
    the underlying LLM model quality; incorrect parameters may be produced.
  \item Performance with large datasets (100+ samples) has not been formally evaluated.
  \item PDF report compilation requires \texttt{lualatex} or \texttt{xelatex}
    (MacTeX / TeX Live); if unavailable, \texttt{report.tex} is saved for
    manual compilation.
  \item PDF/SVG auto-conversion relies on macOS \texttt{sips}; Linux/Windows
    users must convert manually (Pillow-based conversion is planned).
\end{itemize}

\subsection{Future Directions}

\begin{itemize}
  \item Support for additional marker genes (ITS, 18S rRNA)
  \item Pillow-based PDF/SVG $\to$ PNG conversion for Linux and Windows
  \item Machine learning-based analyses (Random Forest feature importance,
    supervised classification) in the deterministic module
  \item Integration of statistical result annotation directly into figures
\end{itemize}

% -------------------------------------------------------
\section{Conclusion}
% -------------------------------------------------------

We have described seq2pipe, an interactive AI agent that integrates
local LLM inference with the QIIME2 microbiome analysis platform.
The system combines three complementary modules:
\texttt{qiime2\_agent.py} orchestrates 11 specialized tools for
QIIME2 pipeline generation, \texttt{analysis.py} deterministically
generates 29 publication-quality PNG figures without LLM dependency,
and \texttt{code\_agent.py} --- a vibe-local-style tool-calling agent
with 5 tools --- provides flexible additional analysis by reading
actual file contents before writing code and automatically correcting errors.
A post-analysis refinement mode allows iterative figure improvement via
natural language, and \texttt{report\_generator.py} produces HTML or
LaTeX/PDF reports.
Together they enable researchers to automate an entire 16S rRNA analysis workflow ---
from raw FASTQ data through 29 publication-quality figures
and an HTML report --- entirely offline and without any cloud dependencies.
The adaptive autonomous mode further extends the analysis by dynamically
selecting data-driven explorations beyond the deterministic figure set.

seq2pipe is released as open source under the MIT License and is available at:
\texttt{https://github.com/Rhizobium-gits/seq2pipe}

% -------------------------------------------------------
% References
% -------------------------------------------------------
\begin{thebibliography}{9}

\bibitem{qiime2}
  Bolyen, E., et al. (2019).
  \textit{Reproducible, interactive, scalable and extensible microbiome
    data science using QIIME 2}.
  Nature Biotechnology, 37, 852--857.

\bibitem{brown2020gpt3}
  Brown, T. B., et al. (2020).
  \textit{Language Models are Few-Shot Learners}.
  Advances in Neural Information Processing Systems, 33, 1877--1901.

\bibitem{yao2023react}
  Yao, S., et al. (2023).
  \textit{ReAct: Synergizing Reasoning and Acting in Language Models}.
  International Conference on Learning Representations (ICLR 2023).

\bibitem{ollama}
  Ollama (2023).
  \textit{Ollama: Get up and running with large language models locally}.
  \url{https://ollama.com/}

\bibitem{silva}
  Quast, C., et al. (2013).
  \textit{The SILVA ribosomal RNA gene database project:
    improved data processing and web-based tools}.
  Nucleic Acids Research, 41(D1), D590--D596.

\bibitem{dada2}
  Callahan, B. J., et al. (2016).
  \textit{DADA2: High-resolution sample inference from Illumina amplicon data}.
  Nature Methods, 13(7), 581--583.

\end{thebibliography}

\end{document}
