% seq2pipe: ローカルLLMによるQIIME2パイプライン自動生成AIエージェント
% LuaLaTeX + luatexja-preset でコンパイル（推奨）
% lualatex seq2pipe_ja.tex  または  xelatex seq2pipe_ja.tex

\documentclass[12pt, a4paper]{article}

% -------------------------------------------------------
% パッケージ
% -------------------------------------------------------
\usepackage{fontspec}
\usepackage{xeCJK}
\setCJKmainfont{Hiragino Mincho ProN}   % macOS 標準日本語フォント
\setCJKsansfont{Hiragino Sans}
\setCJKmonofont{Hiragino Sans}

\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{top=25mm, bottom=25mm, left=25mm, right=25mm}

\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue!70!black,
  urlcolor=blue!70!black,
  citecolor=blue!70!black,
  pdftitle={seq2pipe: ローカルLLMによるQIIME2パイプライン自動生成AIエージェント},
  pdfauthor={Rhizobium-gits, Claude (Anthropic)}
}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{abstract}

% -------------------------------------------------------
% コードブロックのスタイル
% -------------------------------------------------------
\definecolor{codebg}{RGB}{245,245,245}
\definecolor{codecomment}{RGB}{100,100,100}
\definecolor{codestring}{RGB}{160,40,40}
\definecolor{codekeyword}{RGB}{0,80,160}

\lstdefinestyle{mystyle}{
  backgroundcolor=\color{codebg},
  commentstyle=\color{codecomment}\itshape,
  keywordstyle=\color{codekeyword}\bfseries,
  stringstyle=\color{codestring},
  basicstyle=\ttfamily\small,
  breakatwhitespace=false,
  breaklines=true,
  keepspaces=true,
  numbers=left,
  numberstyle=\tiny\color{gray},
  numbersep=8pt,
  showspaces=false,
  showstringspaces=false,
  tabsize=2,
  frame=single,
  rulecolor=\color{gray!40},
  xleftmargin=15pt,
}
\lstset{style=mystyle}

% -------------------------------------------------------
% ヘッダー・フッター
% -------------------------------------------------------
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\small seq2pipe 技術レポート}
\fancyhead[R]{\small 2026年3月}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}

% -------------------------------------------------------
% セクション書式
% -------------------------------------------------------
\titleformat{\section}{\large\bfseries}{}{0em}{\thesection\quad}
\titleformat{\subsection}{\normalsize\bfseries}{}{0em}{\thesubsection\quad}

% -------------------------------------------------------
% ドキュメント開始
% -------------------------------------------------------
\begin{document}

% タイトル
\begin{center}
  {\LARGE \textbf{seq2pipe}}\\[6pt]
  {\large ローカル LLM による QIIME2 パイプライン自動生成 AI エージェント}\\[12pt]
  {\normalsize Rhizobium-gits \quad Claude (Anthropic)}\\[4pt]
  {\small \texttt{https://github.com/Rhizobium-gits/seq2pipe}}\\[4pt]
  {\small 2026 年 3 月 2 日}
\end{center}

\vspace{4mm}
\hrule
\vspace{4mm}

% アブストラクト
\begin{abstract}
本稿では、ローカル大規模言語モデル（LLM）を用いたマイクロバイオーム解析自動化エージェント
\textbf{seq2pipe} の設計と実装について報告する。
seq2pipe はユーザーが保有する生 FASTQ データを入力として受け取り、
データ構造の自動認識・QIIME2 解析パイプラインの設計・実行可能シェルスクリプトの生成を行い、
続いて \textbf{決定論的包括解析モジュール}（\texttt{analysis.py}）が
LLM に依存せず \textbf{29 種類の出版品質 PNG 図を確実に生成} する。
さらに \textbf{ツール呼び出し型コード生成エージェント}（\texttt{code\_agent.py}）が
実際のエクスポートファイルの内容を先に読んでからコードを生成するため、
フォーマットの不一致によるエラーを根本的に排除する。
コードエージェントは「NEVER GIVE UP」方針に従い、
エラーが発生するたびにコードを修正して \texttt{EXIT CODE: 0} になるまで実行を繰り返す。
自律モード（\texttt{--auto}）では 4 ステップで全解析を完了する:
STEP 1（QIIME2 パイプライン）$\to$ STEP 1.5（決定論的解析・29 図）$\to$ STEP 2（適応型自律エージェント）$\to$ STEP 3（HTML レポート）。
STEP 2 の適応型自律エージェントは STEP 1.5 の解析サマリーをもとに LLM がデータ適応型の応用解析を自動実行する。
\texttt{--classifier} オプションにより SILVA 138 分類器を指定すると、
属・門レベルの分類組成図（fig13〜fig15）も自動生成される。
解析完了後は \textbf{振り返り・修正モード} が起動し、
「色を変えて」「凡例を外に出して」などの自然言語指示で図を対話的に修正できる。
処理はすべてユーザーのローカル環境で完結し、
クラウドサービスや有料 API への依存を排除する。
\end{abstract}

\vspace{4mm}
\hrule
\vspace{6mm}

% -------------------------------------------------------
\section{はじめに}
% -------------------------------------------------------

マイクロバイオーム研究において QIIME2~\cite{qiime2} は
16S rRNA アンプリコンシーケンシングデータの標準的な解析プラットフォームとして
広く普及している。しかし、QIIME2 の学習コストは高く、
データ形式の理解・適切なパラメータ選択・Docker を介した実行環境の構築など、
初心者にとっての障壁が大きい。
さらに QIIME2 の出力（\texttt{.qzv} アーティファクト）の可視化には
\texttt{view.qiime2.org} への依存があり、オフライン環境では解析結果の確認も困難である。

近年、大規模言語モデル（LLM）の急速な発展により、
自然言語によるコード生成やドメイン特化型の解析支援が実用化されつつある~\cite{brown2020gpt3}。
一方で、従来のクラウド型 LLM サービスはコスト・プライバシー・ネットワーク依存性という問題を持つ。
Ollama~\cite{ollama} をはじめとするローカル LLM 実行フレームワークの登場により、
これらの課題をクリアしながら高度な言語処理を実現することが可能となった。

本研究では、これらの技術を統合した対話型 AI エージェント \textbf{seq2pipe} を開発し、
その設計原則・アーキテクチャ・実装詳細を報告する。
seq2pipe は QIIME2 解析の自動化に留まらず、
決定論的な包括解析モジュールによる 29 種類の図の確実な生成、
LLM による柔軟な追加解析、
そして日本語・英語両対応の自動レポート生成まで
一貫したパイプラインを提供する点で、従来ツールを大きく超える。

% -------------------------------------------------------
\section{背景と関連研究}
% -------------------------------------------------------

\subsection{QIIME2 における解析の複雑性}

QIIME2 は、データのインポートからデノイジング（DADA2）・系統樹構築・分類学的解析・
多様性解析・差次解析まで、多段階の処理を必要とする。
各ステップで適切なコマンドとパラメータを選択するには
シーケンシングのライブラリ構成（ペアエンド/シングルエンド）・
増幅領域（V1--V3, V3--V4, V4 など）・プライマー配列の知識が不可欠である。

\subsection{LLM エージェントの台頭}

ReAct フレームワーク~\cite{yao2023react} に代表されるように、
LLM が思考と行動を交互に実行することで複雑なタスクを自律的に処理する
「エージェント」パターンが確立されている。
関数呼び出し（Function Calling）機能を持つ LLM は、
外部ツールを適切なタイミングで呼び出しながら、
ユーザーの意図を達成することができる。

\subsection{ローカル LLM の実用化}

Ollama は \texttt{llama.cpp} を基盤とし、macOS・Linux・Windows 上で
量子化された LLM モデルをシングルバイナリで実行できる。
OpenAI の Chat Completions API と互換性のある
REST API（\texttt{/api/chat}）を提供しており、
関数呼び出しを含む高度な推論が可能である。

% -------------------------------------------------------
\section{システム設計}
% -------------------------------------------------------

\subsection{設計原則}

seq2pipe は以下の設計原則に従って開発した。

\begin{enumerate}[leftmargin=2em]
  \item \textbf{外部依存ゼロ}: Python 標準ライブラリ（\texttt{json}, \texttt{urllib},
    \texttt{subprocess}, \texttt{pathlib}, \texttt{socket} 等）のみを使用し、
    \texttt{pip install} を不要とする。
  \item \textbf{ローカル完結}: Ollama のローカル推論エンジンを使用し、
    インターネット接続を不要とする（初期セットアップを除く）。
  \item \textbf{クロスプラットフォーム}: macOS・Linux・Windows のすべてで動作する。
  \item \textbf{安全なコマンド実行}: コマンド実行前にユーザーへの確認を必須とする。
  \item \textbf{QIIME2 ドメイン知識の内包}: システムプロンプトに QIIME2 の
    完全なワークフロー知識を埋め込む。
  \item \textbf{多言語 UI}: 起動時に日本語 / 英語を選択し、
    AI 応答・自動生成レポートを統一する。
  \item \textbf{堅牢なエラー処理}: 接続エラー・タイムアウト・空レスポンス・
    ファイルシステムエラーをすべて適切にキャッチし、ユーザーに分かりやすいメッセージを返す。
  \item \textbf{決定論的解析の保証}: LLM に依存しない包括解析モジュール（\texttt{analysis.py}）
    により、29 種類の図を確実に生成する。
\end{enumerate}

\subsection{全体アーキテクチャ}

図~\ref{fig:arch} に seq2pipe の 4 ステップアーキテクチャを示す。
ユーザーは起動スクリプトを通じてエントリーポイント（\texttt{cli.py}）を起動する。
\texttt{cli.py} は虹色 ASCII バナーを表示し、
2 つの操作モード（指定解析モード / 自律エージェントモード）を選択させる。
\texttt{--auto} モードでは 4 ステップの自動化パイプラインが実行される:
STEP 1 で \texttt{pipeline\_runner.py} が QIIME2 パイプラインを実行し結果をエクスポート、
STEP 1.5 で \texttt{analysis.py} が決定論的に 29 種類の PNG 図を生成、
STEP 2 で適応型自律エージェントがデータ適応型の応用解析を実行、
STEP 3 で HTML レポートを自動生成する。
指定解析モード（モード 1）では \texttt{code\_agent.py} が
vibe-local 方式のツール呼び出し型コード生成を行う。

\begin{figure}[h]
  \centering
  \begin{verbatim}
  ユーザー
    |
    v
  [launch.sh] -> [cli.py]  (バナー・モード選択)
                     |
    +----------------+---------------------------+
    |                |                           |
    v                v                           v
  モード 1      [pipeline_runner.py]        モード 2
  指定解析       QIIME2 実行 + エクスポート   --auto フラグ
    |                |   (STEP 1)                |
    |                v                           |
    |       [analysis.py]  (STEP 1.5)            |
    |         決定論的包括解析（LLM 不要）          |
    |         29 種類の PNG 図を確実に生成          |
    |         fig01-12: 基本解析                  |
    |         fig13-15: 分類組成（分類器あり時）    |
    |         fig16-25: 拡張解析                  |
    |         fig26-29: 網羅的解析                |
    |                |                           |
    |                v                           |
    |       STEP 2: 適応型自律エージェント          |
    |         generate_analysis_summary() ->      |
    |         LLM データ適応型応用解析              |
    |                |                           |
    v                v                           v
  [code_agent.py] <-+----> [report_generator.py]
    ツール呼び出し型          HTML / LaTeX+PDF
    コード生成エージェント     レポート生成
    |                          (STEP 3)
    +---> Ollama (localhost:11434)
  \end{verbatim}
  \caption{seq2pipe の 4 ステップアーキテクチャ}
  \label{fig:arch}
\end{figure}

% -------------------------------------------------------
\section{実装詳細}
% -------------------------------------------------------

\subsection{起動シーケンスと多言語 UI}

エージェントの起動時に \texttt{select\_language()} が呼ばれ、
ユーザーは日本語（\texttt{ja}）または英語（\texttt{en}）を選択する。
選択は \texttt{LANG} グローバル変数に保存され、
\texttt{ui()} 関数が全 UI テキストを選択言語で返す。
自動生成されるレポートも同じ言語設定を使用する。

また \texttt{check\_python\_deps()} が起動時に numpy・pandas・matplotlib・seaborn
の存在を \texttt{subprocess} 経由で確認し、不足する場合はインストールコマンドを案内する。

\subsection{システムプロンプトへのドメイン知識埋め込み}

\texttt{SYSTEM\_PROMPT} 変数に QIIME2 の完全なワークフロー知識を記述した。
これには以下の情報が含まれる。

\begin{itemize}
  \item データ形式の自動判定基準
    （\texttt{*\_R1*.fastq.gz} パターンによるペアエンド検出など）
  \item 全 8 ステップの QIIME2 コマンド（インポート〜差次解析）
  \item 増幅領域別推奨パラメータ（V1--V3, V3--V4, V4）
  \item Docker 実行テンプレート
  \item メタデータファイル形式仕様
  \item SILVA 138 分類階層の説明
  \item 一般的なエラーとトラブルシューティング
  \item Python 下流解析・自律探索モードの実行指針
\end{itemize}

この手法により、汎用 LLM モデルが QIIME2 専門家として振る舞うことを可能にした。

\subsection{ツール定義と関数呼び出し}

seq2pipe は 2 種類のツールセットを持つ。
\texttt{qiime2\_agent.py} が QIIME2 パイプライン生成用の 11 ツール（表~\ref{tab:tools_qiime2}）を提供し、
\texttt{code\_agent.py} が vibe-local 方式の Python コード生成用 5 ツール（表~\ref{tab:tools_code}）を提供する。
コードエージェントは、LLM がコードを書く前に必ず \texttt{read\_file} でファイルの
列名・形式を確認するよう指示されており、盲目的なコード生成によるフォーマットエラーを排除する。

\begin{table}[h]
  \centering
  \caption{\texttt{qiime2\_agent.py} のツール一覧（QIIME2 パイプライン生成）}
  \label{tab:tools_qiime2}
  \begin{tabular}{lp{7cm}}
    \toprule
    \textbf{ツール名} & \textbf{機能} \\
    \midrule
    \texttt{inspect\_directory} &
      ファイル一覧・サイズ取得、FASTQ/QZA/メタデータを自動判定 \\
    \texttt{read\_file} &
      テキストファイルを最大 50 行読み込む \\
    \texttt{write\_file} &
      スクリプト・マニフェスト・README を書き出す \\
    \texttt{edit\_file} &
      既存ファイルの文字列を置換する \\
    \texttt{generate\_manifest} &
      FASTQ ディレクトリから QIIME2 マニフェスト TSV を自動生成 \\
    \texttt{run\_command} &
      ユーザー確認後にシェルコマンドを実行；
      conda 環境を自動検出・\texttt{SEQ2PIPE\_AUTO\_YES} 対応 \\
    \texttt{check\_system} &
      Docker・Ollama・Python・ディスク容量を確認 \\
    \texttt{set\_plot\_config} &
      matplotlib スタイル・カラー・DPI・フォント・保存形式を設定 \\
    \texttt{execute\_python} &
      Python コードを実行し図を保存、\texttt{ANALYSIS\_LOG} に記録 \\
    \texttt{build\_report\_tex} &
      \texttt{ANALYSIS\_LOG} から TeX 構築・lualatex でコンパイル \\
    \texttt{log\_analysis\_step} &
      QIIME2 操作を \texttt{ANALYSIS\_LOG} に手動登録 \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[h]
  \centering
  \caption{\texttt{code\_agent.py} のツール一覧（vibe-local 方式コード生成）}
  \label{tab:tools_code}
  \begin{tabular}{lp{7.5cm}}
    \toprule
    \textbf{ツール名} & \textbf{機能} \\
    \midrule
    \texttt{list\_files} &
      エクスポートディレクトリのファイル一覧とサイズを返す \\
    \texttt{read\_file} &
      ファイルの全内容を LLM に渡す。
      コード生成前に列名・データ形式を確認させることで精度を向上させる \\
    \texttt{write\_file} &
      \texttt{mkstemp}+\texttt{replace} による atomic write で
      Python スクリプトを安全に生成する \\
    \texttt{run\_python} &
      QIIME2 conda Python で実行；stdout・stderr・exit code を返す；
      新規生成図ファイルを自動検出する \\
    \texttt{install\_package} &
      \texttt{ModuleNotFoundError} を検出してユーザーに承認を求め、
      承認されれば \texttt{pip install} を実行する \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{決定論的包括解析モジュール（\texttt{analysis.py}）}

\texttt{--auto} モードの信頼性を向上させるため、
LLM に依存しない決定論的包括解析モジュール \texttt{analysis.py} を導入した。
\texttt{run\_comprehensive\_analysis()} 関数は QIIME2 エクスポートデータを
直接読み込み、pandas / matplotlib / seaborn / scikit-learn を使用して
29 種類の出版品質 PNG 図を生成する（表~\ref{tab:analysis_figures}）。

このモジュールは LLM の応答品質に左右されないため、
どのモデルを使用しても同一の解析結果が得られる。
fig01〜fig12 は基本解析、fig13〜fig15 は SILVA 138 分類器利用時の分類組成、
fig16〜fig25 は拡張解析（ラレファクション・NMDS・ネットワーク等）、
fig26〜fig29 は網羅的解析（綱・目レベル組成・Simpson 多様性・ASV 共有パターン）を提供する。

\begin{table}[h]
  \centering
  \caption{\texttt{analysis.py} が生成する 29 種類の図}
  \label{tab:analysis_figures}
  \begin{tabular}{clp{5.5cm}}
    \toprule
    \textbf{図番号} & \textbf{解析内容} & \textbf{主要パッケージ} \\
    \midrule
    fig01 & DADA2 デノイジング統計 & pandas, matplotlib \\
    fig02 & シーケンシング深度 & pandas, matplotlib \\
    fig03 & $\alpha$ 多様性ボックスプロット & pandas, seaborn \\
    fig04 & Shannon 多様性（サンプル別） & pandas, seaborn \\
    fig05 & PCoA (Bray-Curtis) & sklearn MDS \\
    fig06 & PCoA (Jaccard) & sklearn MDS \\
    fig07 & PCoA (Unweighted UniFrac) & sklearn MDS \\
    fig08 & PCoA (Weighted UniFrac) & sklearn MDS \\
    fig09 & $\beta$ 多様性距離ヒートマップ (2$\times$2) & seaborn \\
    fig10 & Top 30 ASV ヒートマップ & seaborn \\
    fig11 & $\alpha$ 多様性相関 & matplotlib \\
    fig12 & ASV リッチネス vs 深度 & matplotlib \\
    fig13 & 属レベル積み上げ棒グラフ$^*$ & matplotlib \\
    fig14 & 門レベル積み上げ棒グラフ$^*$ & matplotlib \\
    fig15 & 属レベルヒートマップ$^*$ & seaborn \\
    \midrule
    fig16 & ラレファクションカーブ & numpy \\
    fig17 & NMDS (Bray-Curtis) & sklearn MDS \\
    fig18 & Rank-Abundance カーブ & matplotlib \\
    fig19 & 分類学的 Alluvial プロット & matplotlib (B\'{e}zier) \\
    fig20 & 属間共起ネットワーク & networkx \\
    fig21 & 科レベル積み上げ棒グラフ$^*$ & matplotlib \\
    fig22 & コアマイクロバイオーム$^*$ & matplotlib \\
    fig23 & 差次的存在量ボルケーノプロット$^{*\dagger}$ & scipy, matplotlib \\
    fig24 & サンプルデンドログラム (UPGMA) & scipy hierarchy \\
    fig25 & 属間 Spearman 相関$^*$ & scipy, seaborn \\
    \midrule
    fig26 & 綱レベル積み上げ棒グラフ$^*$ & matplotlib \\
    fig27 & 目レベル積み上げ棒グラフ$^*$ & matplotlib \\
    fig28 & Simpson 多様性 + Pielou 均等度 & matplotlib \\
    fig29 & サンプル間 ASV 共有パターン & matplotlib \\
    \bottomrule
    \multicolumn{3}{l}{\small $^*$ SILVA 138 分類器が利用可能な場合のみ生成} \\
    \multicolumn{3}{l}{\small $^{\dagger}$ Benjamini--Hochberg FDR 補正}
  \end{tabular}
\end{table}

PCoA（fig05〜fig08）では固有値分解に基づく分散説明率（\%）を軸ラベルに表示し、
各主座標が群集構造のどの程度の変動を説明するかを定量的に示す。
また、\texttt{generate\_analysis\_summary()} 関数が全 29 図の解析結果を構造化データとして
要約し、STEP 2 の適応型自律エージェントに渡すことで、
LLM がデータの特性に応じた応用解析を自動的に計画・実行する。

\subsection{コードエージェントループの実装（vibe-local 方式）}

\texttt{code\_agent.py} の \texttt{run\_coding\_agent()} は
「先に読む、後で書く」原則に基づくツール呼び出しループを実装する。
LLM には \textbf{TOOL FIRST}（即座にツールを呼び出す）と
\textbf{NEVER GIVE UP}（エラーが出ても修正して再実行）を指示しており、
典型的な 1 解析タスクの流れは以下の通りである。

\begin{enumerate}[leftmargin=2em]
  \item \texttt{list\_files} でエクスポートファイルを把握
  \item \texttt{read\_file} で対象ファイルの列名・データ形式を確認
  \item \texttt{write\_file} で実際の列名を使った Python スクリプトを生成
  \item \texttt{run\_python} で実行し、exit code $\neq 0$ ならトレースバックを読んで
    \texttt{write\_file} で修正し再実行
\end{enumerate}

リスト~\ref{lst:loop} にループの中核部分を示す。

\begin{lstlisting}[language=Python, caption={run\_coding\_agent() のツール呼び出しループ}, label={lst:loop}]
def run_coding_agent(export_files, user_prompt, ...):
    messages = [{"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user",   "content": task}]
    steps = 0
    while steps < max_steps:
        response = call_ollama(messages, model, tools=_TOOL_DEFS)
        tool_calls = response.get("tool_calls", [])

        if not tool_calls:
            break  # LLM が完了と判断

        for tc in tool_calls:
            fn   = tc["function"]
            name = fn["name"]
            args = fn["arguments"]   # dict or JSON 文字列
            if isinstance(args, str):
                args = json.loads(args)

            result, new_figs = _exec_tool(name, args, ...)
            figures.extend(new_figs)
            messages.append({"role": "tool",
                              "name": name,
                              "content": result[:4000]})
        steps += 1

    return CodeExecutionResult(success=bool(figures), figures=figures)
\end{lstlisting}

\subsection{小型モデル向けロバストネス機能}

7B 以下の小型 LLM は Ollama の \texttt{tool\_calls} フォーマットに非対応の場合があり、
ツール呼び出しをプレーンテキストの JSON として出力する。
seq2pipe はこれを \texttt{run\_coding\_agent()} 内の 4 層フォールバック機構で自動的に補う。

\begin{enumerate}[leftmargin=2em]
  \item \textbf{テキストベースツール呼び出しパーサ（\texttt{\_parse\_text\_tool\_calls})}:
    \texttt{tool\_calls} が空のとき、応答本文を 5 つのヒューリスティックパターンで検索し
    JSON ツール呼び出しを抽出する:
    (a) \texttt{```json} コードブロック、
    (b) 応答全体を JSON として解析、
    (c) \texttt{"name": "..."} パターンのインライン正規表現スキャン、
    (d) name キーなし JSON をキー名から \texttt{write\_file}/\texttt{list\_files} として推論、
    (e) 壊れた JSON を正規表現で抽出する寛容なパーサ。

  \item \textbf{Auto-inject \texttt{run\_python}}:
    \texttt{write\_file} が \texttt{.py} ファイルを書き込んだ直後、
    モデルが \texttt{run\_python} を呼ぶのを待たずに自動実行する。
    これにより「スクリプトは書いたが実行を忘れる」という小型モデルの典型的な失敗を回避する。

  \item \textbf{ステップ 6 フォールバック（1 ショット生成）}:
    \texttt{\_run\_python\_count} カウンタが 5 ステップ後もゼロのとき（ループが進まない場合）、
    \texttt{run\_coding\_agent()} は自動的に \texttt{run\_code\_agent()} にフォールバックし、
    最大 3 回のエラー修正リトライ付き 1 ショット生成を行う。

  \item \textbf{繰り返し検出（\texttt{call\_ollama()} 内）}:
    同じ 50 文字チャンクが 4 回連続して現れた場合、または応答が 20,000 文字を超えた場合に
    生成を強制終了し、無限ループを防ぐ。
\end{enumerate}

これらの機構により、7B モデルでも少なくとも 1 種類以上の図を確実に生成できる。
さらに \texttt{analysis.py} による決定論的解析が LLM の前に実行されるため、
LLM の性能に関わらず 29 種類の基本図は常に生成される。

\subsection{QIIME2 パイプラインエージェントループ}

\texttt{qiime2\_agent.py} の \texttt{run\_agent\_loop()} は
QIIME2 パイプライン生成の推論・行動サイクルを制御する。
LLM の応答にツール呼び出しが含まれる場合は順次実行して結果を会話履歴に追加し、
テキスト応答のみになるまで繰り返す。
空レスポンスのガード処理も実装している。

\subsection{SILVA 138 分類器の自動探索（\texttt{--classifier}）}

\texttt{cli.py} に \texttt{--classifier} オプションを追加し、
SILVA 138 Naive Bayes 分類器のパスを指定できるようにした。
パスが明示されない場合は \texttt{\_find\_classifier()} 関数が
以下の候補パスを順に探索する:
\texttt{~/seq2pipe/silva-138-99-nb-classifier.qza}、
\texttt{~/classifiers/} 配下、
\texttt{/usr/local/share/qiime2/} 配下。
分類器が見つかった場合、QIIME2 パイプラインで分類学的解析が実行され、
\texttt{analysis.py} が属・門レベルの組成図を自動生成する。

\subsection{Ollama API との通信と堅牢なエラー処理}

\texttt{call\_ollama()} 関数は Ollama の \texttt{/api/chat} エンドポイントに
JSON リクエストを送信し、ストリーミングレスポンスを行単位で受信する。
Python の \texttt{urllib.request} モジュールのみを使用しており、
\texttt{requests} 等の外部パッケージに依存しない。

エラー処理として以下を実装した。
\begin{itemize}
  \item \texttt{urllib.error.HTTPError}: Ollama サーバーの HTTP エラー（4xx/5xx）
  \item \texttt{urllib.error.URLError + socket.timeout}: タイムアウト（600 秒、
    環境変数 \texttt{SEQ2PIPE\_PYTHON\_TIMEOUT} で変更可）と
    サーバー未起動（\texttt{Connection refused}）を区別して表示
  \item \texttt{socket.timeout / TimeoutError}: ソケットレベルのタイムアウト
\end{itemize}

\subsection{図の自動 PNG 変換}

LLM が \texttt{plt.savefig()} に \texttt{.pdf} や \texttt{.svg} 拡張子を使ってしまう場合があった。
seq2pipe は \texttt{\_convert\_new\_figs()} ヘルパーにより、
コード実行直後に生成された PDF/SVG ファイルを macOS 内蔵の
\texttt{sips} コマンドで自動的に PNG へ変換し、元ファイルを削除する。
これにより macOS プレビュー等で問題なく図を確認できる。
また、プロンプトに「拡張子は必ず \texttt{.png}」という指示を追加し、
LLM による不適切な拡張子の生成頻度を低減した。

\subsection{メタデータなし多様性解析}

従来の \texttt{qiime diversity core-metrics-phylogenetic} コマンドは
\texttt{--m-metadata-file} が必須引数であるため、
メタデータファイルがない場合は STEP 7（多様性解析）が丸ごとスキップされていた。
これを修正し、メタデータが存在しない場合は
個別コマンド（\texttt{qiime diversity alpha}, \texttt{qiime diversity beta},
\texttt{qiime diversity alpha-phylogenetic}, \texttt{qiime diversity beta-phylogenetic}）を
Shannon・Faith PD・Bray--Curtis・UniFrac 等の各指標について順次実行するフォールバックを実装した。

\subsection{振り返り・修正モードと HTML / LaTeX レポート生成}

解析が完了すると \texttt{\_run\_refinement\_session()} が起動し、
ユーザーは生成された図に対して自然言語で修正指示を与えられる。
指示はそのまま \texttt{run\_refinement\_loop()} に渡され、
LLM が既存コードを修正して再実行する。
このループは空 Enter または \texttt{quit} で終了する。

\texttt{--auto} モードでは STEP 3 として HTML レポートが自動生成される。
また、修正セッション中に特定のキーワードが入力されるとレポートが生成される:

\begin{itemize}
  \item 「レポート」・\texttt{html} など $\to$ \texttt{generate\_html\_report()}:
    図を base64 で埋め込んだ自己完結型 HTML ファイルを生成する。
    LLM が各図の日本語解釈文と総合サマリーを生成し、
    解析パラメータ表・パイプラインステップを合わせて記録する。
  \item 「PDF」・\texttt{latex} など $\to$ \texttt{generate\_latex\_report()}:
    \texttt{lualatex}（優先）または \texttt{xelatex} を自動検出してコンパイルする。
    日本語対応には \texttt{luatexja-preset}（lualatex）または
    \texttt{xeCJK} + Hiragino フォント（xelatex）を使用する。
    LaTeX エンジンが見つからない場合は \texttt{report.tex} のみ保存し、
    手動コンパイル手順をユーザーに通知する。
\end{itemize}

\subsection{マニフェスト自動生成}

\texttt{tool\_generate\_manifest()} は FASTQ ファイルの命名規則
（\texttt{\_R1\_} / \texttt{\_R2\_} パターン）を正規表現（\texttt{re.sub(count=1)}）で解析し、
ペアエンド・シングルエンド双方の QIIME2 マニフェスト TSV を自動生成する。
R2 ファイルの探索は辞書ルックアップ（O(1)）で実装し大規模データセットにも対応する。
Docker コンテナ内パス（デフォルト: \texttt{/data/output}）への変換も自動で行う。
ペアが 1 組も見つからない場合はファイルを書かずにエラーを返す。

\subsection{クロスプラットフォーム対応}

macOS・Linux・Windows の差異を吸収するために以下の対策を実装した。

\begin{itemize}
  \item \textbf{Docker 検出}:
    macOS では Docker Desktop の固定パス
    (\texttt{/Applications/Docker.app/.../docker}) を優先し、
    その他の OS では \texttt{shutil.which("docker")} を使用する。
  \item \textbf{Windows ANSI カラー}:
    \texttt{os.system("")} を呼ぶことで Windows 10 以降における
    ANSI エスケープシーケンスを有効化する。
  \item \textbf{起動スクリプトの分離}:
    macOS/Linux 用（Bash）と Windows 用（PowerShell + バッチ）を別々に提供する。
\end{itemize}

% -------------------------------------------------------
\section{解析ワークフロー}
% -------------------------------------------------------

seq2pipe が生成する QIIME2 パイプラインは表~\ref{tab:workflow} の 8 ステップで構成される。

\begin{table}[h]
  \centering
  \caption{生成される QIIME2 解析パイプラインの概要}
  \label{tab:workflow}
  \begin{tabular}{clp{7cm}}
    \toprule
    \textbf{STEP} & \textbf{処理} & \textbf{主要コマンド} \\
    \midrule
    1 & データインポート &
      \texttt{qiime tools import} \\
    2 & クオリティ確認 &
      \texttt{qiime demux summarize} \\
    3 & デノイジング（ASV 生成） &
      \texttt{qiime dada2 denoise-paired} \\
    4 & フィーチャーテーブル確認 &
      \texttt{qiime feature-table summarize} \\
    5 & 系統樹構築 &
      \texttt{qiime phylogeny align-to-tree-mafft-fasttree} \\
    6 & 分類学的解析 &
      \texttt{qiime feature-classifier classify-sklearn} \\
    7 & 多様性解析 &
      \texttt{qiime diversity core-metrics-phylogenetic} \\
    8 & 差次解析（オプション） &
      \texttt{qiime composition ancombc} \\
    \bottomrule
  \end{tabular}
\end{table}

SILVA 138 参照データベース~\cite{silva} を用いた Naive Bayes 分類器により、
16S rRNA 増幅領域の分類学的同定を行う。
増幅領域（V1--V3: 27F/338R, V3--V4: 341F/806R, V4: 515F/806R）に応じて
プライマートリム長・トランケーション長が自動的に調整される。

QIIME2 解析後、\texttt{--auto} モードでは以下の 4 ステップ自動化パイプラインが実行される:

\begin{enumerate}[leftmargin=2em]
  \item \textbf{STEP 1}: QIIME2 パイプライン（上記 8 ステップ）+ 結果エクスポート
  \item \textbf{STEP 1.5}: 決定論的包括解析（\texttt{analysis.py}）$\to$ \textbf{29 種類の PNG 図}を生成:
    \begin{itemize}
      \item fig01: DADA2 デノイジング統計
      \item fig02: シーケンシング深度
      \item fig03: $\alpha$ 多様性（Shannon / Faith PD / Observed ASVs）
      \item fig04: Shannon 多様性（サンプル別）
      \item fig05--08: PCoA（Bray-Curtis / Jaccard / Unweighted UniFrac / Weighted UniFrac）
      \item fig09: $\beta$ 多様性距離ヒートマップ（2$\times$2）
      \item fig10: Top 30 ASV ヒートマップ
      \item fig11: $\alpha$ 多様性相関
      \item fig12: ASV リッチネス vs 深度
      \item fig13: 属レベル組成（分類器あり時）
      \item fig14: 門レベル組成（分類器あり時）
      \item fig15: 属レベルヒートマップ（分類器あり時）
      \item fig16: ラレファクションカーブ
      \item fig17: NMDS (Bray-Curtis)
      \item fig18: Rank-Abundance カーブ
      \item fig19: 分類学的 Alluvial プロット
      \item fig20: 属間共起ネットワーク
      \item fig21: 科レベル積み上げ棒グラフ（分類器あり時）
      \item fig22: コアマイクロバイオーム（分類器あり時）
      \item fig23: 差次的存在量ボルケーノプロット（分類器あり時）
      \item fig24: サンプルデンドログラム (UPGMA)
      \item fig25: 属間 Spearman 相関（分類器あり時）
      \item fig26: 綱レベル積み上げ棒グラフ（分類器あり時）
      \item fig27: 目レベル積み上げ棒グラフ（分類器あり時）
      \item fig28: Simpson 多様性 + Pielou 均等度
      \item fig29: サンプル間 ASV 共有パターン
    \end{itemize}
  \item \textbf{STEP 2}: 適応型自律エージェント $\to$ \texttt{generate\_analysis\_summary()} の
    構造化データをもとに LLM がデータ適応型の応用解析を自動実行
  \item \textbf{STEP 3}: HTML レポート自動生成（base64 図埋め込み）
\end{enumerate}

全ステップ完了後、振り返り・修正モードが起動し、
自然言語指示による図の修正と
\texttt{report\_generator.py} による追加レポート出力が行える。

% -------------------------------------------------------
\section{対応モデルと性能比較}
% -------------------------------------------------------

seq2pipe は Ollama で動作する任意の LLM と組み合わせて使用できる。
表~\ref{tab:models} に推奨モデルとその特性を示す。

\begin{table}[h]
  \centering
  \caption{対応モデル一覧}
  \label{tab:models}
  \begin{tabular}{llll}
    \toprule
    \textbf{モデル} & \textbf{必要 RAM} & \textbf{モデルサイズ} & \textbf{特徴} \\
    \midrule
    \texttt{qwen2.5-coder:7b} & 8 GB 以上 & 約 4.7 GB &
      コード生成特化（推奨） \\
    \texttt{qwen2.5-coder:3b} & 4 GB 以上 & 約 1.9 GB &
      軽量・高速 \\
    \texttt{llama3.2:3b}      & 4 GB 以上 & 約 2.0 GB &
      汎用・対話能力高め \\
    \texttt{qwen3:8b}         & 16 GB 以上 & 約 5.2 GB &
      最高品質・推論能力高い \\
    \bottomrule
  \end{tabular}
\end{table}

なお、\texttt{analysis.py} による決定論的解析（STEP 1.5）は
LLM を使用しないため、モデルの選択に関わらず同一の 29 図が生成される。
モデルの性能差は主にモード 1（指定解析）の柔軟性と
振り返り・修正モードの応答品質に影響する。

% -------------------------------------------------------
\section{実証結果}
% -------------------------------------------------------

seq2pipe のエンドツーエンド自動化能力を実証するため、
ヒト便検体 10 サンプル（TEST01〜TEST10、凍結乾燥便、Illumina MiSeq
ペアエンド V3-V4）を人手なしで解析した。
以下の単一コマンドで全パイプラインを実行した:

\begin{lstlisting}[language=bash, caption={seq2pipe による完全自律解析}]
./launch.sh --fastq-dir ~/input --auto --threads 1
\end{lstlisting}

STEP 1 で QIIME2 パイプライン（DADA2 デノイジング + 系統樹構築 + 多様性解析 +
SILVA 138 分類学的解析）が実行され、
STEP 1.5 で \texttt{analysis.py} が 29 種類の PNG 図を生成し、
STEP 3 で HTML レポートが自動生成された。
図はリポジトリの \texttt{Figure/} ディレクトリに格納されている。

\subsection{DADA2 デノイジング統計}

DADA2 の各ステージ（input $\rightarrow$ filtered $\rightarrow$ denoised $\rightarrow$
merged $\rightarrow$ non-chimeric）におけるリード数の変化を
図~\ref{fig:dada2} に示す。

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.92\textwidth]{../Figure/fig01_dada2_stats.png}
  \caption{10 便検体の DADA2 デノイジング統計。
    各サンプルの 5 つの処理ステージを区別して示す。
    フィルタリング効率がサンプル間で概ね均一であることが示された。}
  \label{fig:dada2}
\end{figure}

\subsection{$\alpha$ 多様性}

3 つの $\alpha$ 多様性指標（Shannon エントロピー、Faith's PD、Observed ASVs）を
サンプルごとに計算し、ボックスプロットで表示した（図~\ref{fig:alpha}）。
また、Shannon 多様性のサンプル別ストリッププロットを図~\ref{fig:shannon} に示す。

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.92\textwidth]{../Figure/fig03_alpha_diversity.png}
  \caption{ヒト便検体 10 サンプルの $\alpha$ 多様性。
    各パネルは DADA2 デノイジング済みフィーチャーテーブルから算出した
    異なる指標を示す。}
  \label{fig:alpha}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figure/fig04_shannon_per_sample.png}
  \caption{サンプルごとの Shannon $\alpha$ 多様性ストリッププロット。}
  \label{fig:shannon}
\end{figure}

\subsection{$\beta$ 多様性}

4 種類の非類似度指標で $\beta$ 多様性を評価した。
Bray--Curtis PCoA（図~\ref{fig:bc}）と
Unweighted UniFrac PCoA（図~\ref{fig:unifrac}）は
scikit-learn MDS（\texttt{n\_components=2, dissimilarity=`precomputed'}）で計算した。
4 つの距離行列をまとめたヒートマップを図~\ref{fig:beta_heatmaps} に示す。

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figure/fig05_pcoa_braycurtis.png}
  \caption{Bray--Curtis PCoA。サンプルはパレットでサンプル ID ごとに
    色分けし、プロット上に直接ラベルを付した。}
  \label{fig:bc}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figure/fig07_pcoa_unweighted_unifrac.png}
  \caption{Unweighted UniFrac PCoA。QIIME2 が計算した系統的距離を
    2 次元 MDS で射影した。}
  \label{fig:unifrac}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.92\textwidth]{../Figure/fig09_beta_distance_heatmaps.png}
  \caption{$\beta$ 多様性距離ヒートマップ（2$\times$2）。
    Bray-Curtis・Jaccard・Unweighted UniFrac・Weighted UniFrac の
    4 指標を一覧表示。}
  \label{fig:beta_heatmaps}
\end{figure}

\subsection{分類組成}

SILVA 138 分類器による分類結果をもとに、
属レベル積み上げ棒グラフ（図~\ref{fig:genus}）と
属レベルヒートマップ（図~\ref{fig:genus_heatmap}）を生成した。

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.92\textwidth]{../Figure/fig13_genus_composition.png}
  \caption{属レベルの分類組成（積み上げ棒グラフ）。
    上位属が色分けされ、各サンプルの微生物群集構造を示す。}
  \label{fig:genus}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.92\textwidth]{../Figure/fig15_genus_heatmap.png}
  \caption{属レベルヒートマップ。相対存在量を色の濃淡で表示し、
    サンプル間の微生物組成の類似性を可視化する。}
  \label{fig:genus_heatmap}
\end{figure}

全 29 図と HTML レポートは \texttt{analysis.py} と
\texttt{report\_generator.py} によって自動生成された。

\subsection{拡張解析}

\texttt{analysis.py} の拡張解析モジュールにより、
従来の 15 図に加えて 14 種類の追加図が自動生成された。
ラレファクションカーブ（fig16）はサンプリング深度に対する ASV 検出数の飽和を示し、
十分なシーケンシング深度が確保されていることを確認できる。
属間共起ネットワーク（fig20）は Spearman 相関に基づく微生物間の正・負の相互作用を可視化し、
群集構造の理解を深める。
Simpson 多様性と Pielou 均等度（fig28）はサンプル間の均等性を評価し、
Shannon 多様性とは異なる観点から群集の多様性構造を明らかにする。

% -------------------------------------------------------
\section{考察と今後の課題}
% -------------------------------------------------------

\subsection{達成された目標}

seq2pipe は以下の目標を達成した。

\begin{itemize}
  \item Python 標準ライブラリのみを用いたゼロ依存実装
  \item ローカル LLM による完全オフライン動作
  \item 3 OS（macOS / Linux / Windows）への完全対応
  \item FASTQ データ構造の自動認識と適応的パイプライン生成
  \item QIIME2 コマンドを conda 環境 / Docker 経由で安全に実行するコマンド確認機構
  \item \textbf{決定論的包括解析モジュール（\texttt{analysis.py}）}:
    LLM に依存せず 29 種類の出版品質 PNG 図を確実に生成
  \item \textbf{SILVA 138 分類器の自動探索（\texttt{--classifier}）}:
    分類学的解析と属・門レベル組成図の自動生成
  \item \textbf{4 ステップ自動化パイプライン}:
    STEP 1（QIIME2）$\to$ STEP 1.5（決定論的解析）$\to$ STEP 2（適応型自律エージェント）$\to$ STEP 3（HTML レポート）
  \item \textbf{適応型自律エージェント}: STEP 1.5 の解析サマリーをもとに LLM がデータ適応型の応用解析を自動実行
  \item \textbf{vibe-local 方式ツール呼び出し型コード生成エージェント}:
    LLM がファイルを先に読んでから Python コードを生成するため、
    盲目的な 1 ショット生成で頻発したフォーマット不一致エラーを根本解消
  \item \textbf{自動エラー修正（NEVER GIVE UP）}:
    \texttt{run\_python} が失敗するとエージェントがトレースバックを読んで
    コードを修正し、\texttt{EXIT CODE: 0} になるまで再実行
  \item \textbf{小型 LLM 向けロバストネス機能}: 4 層フォールバック機構
  \item 2 つの操作モード: 指定解析（モード 1）・完全自律（モード 2 / \texttt{--auto}）
  \item \textbf{解析後の振り返り・修正モード}:
    自然言語指示で図を対話的に修正・再実行
  \item \textbf{PDF/SVG $\to$ PNG 自動変換（\texttt{sips}）}:
    macOS 内蔵コマンドで追加依存なし
  \item \textbf{メタデータなし多様性解析}:
    \texttt{core-metrics-phylogenetic} 不可時に個別コマンドへフォールバック
  \item \textbf{HTML / LaTeX+PDF レポート自動生成}（\texttt{report\_generator.py}）
  \item 日本語 / 英語の起動時言語選択 UI
\end{itemize}

\subsection{現在の制限}

\begin{itemize}
  \item LLM の生成するコマンドの正確性はモデルに依存し、
    誤ったパラメータが生成される可能性がある。
  \item 大規模データセット（100 サンプル以上）に対するパフォーマンスは未検証である。
  \item PDF レポートのコンパイルには \texttt{lualatex} または \texttt{xelatex}
    （MacTeX / TeX Live）のインストールが必要である。
  \item PDF/SVG の自動 PNG 変換は macOS の \texttt{sips} に依存しており、
    Linux / Windows では変換は行われない（将来的に \texttt{Pillow} による代替を検討）。
\end{itemize}

\subsection{今後の課題}

\begin{itemize}
  \item ITS / 18S rRNA など他のマーカー遺伝子への対応
  \item \texttt{Pillow} を利用した Linux / Windows 向け PDF/SVG $\to$ PNG 変換の実装
  \item 差次存在量解析（volcano plot）・機械学習（Random Forest）の
    自律タスクへの追加
  \item 統計的検定結果の図への自動アノテーション
\end{itemize}

% -------------------------------------------------------
\section{おわりに}
% -------------------------------------------------------

本稿では、ローカル LLM と QIIME2 を統合した自動解析エージェント
seq2pipe の設計・実装を報告した。
本システムは 3 つの相補的なモジュールを組み合わせる:
\texttt{qiime2\_agent.py} が 11 ツールで QIIME2 パイプライン生成を担い、
\texttt{analysis.py} が LLM に依存せず 29 種類の出版品質 PNG 図を確実に生成し、
\texttt{code\_agent.py} が vibe-local 方式の 5 ツールで
追加の柔軟な解析を提供する。
解析完了後は振り返り・修正モードにより自然言語で図を対話的に改善でき、
\texttt{report\_generator.py} が HTML または LaTeX+PDF レポートを自動生成する。
これにより研究者は生 FASTQ データから 29 種類の出版品質の図と
HTML レポートまでを、完全オフラインかつクラウド不要の環境で自動化できる。
さらに適応型自律エージェント（STEP 2）により、
決定論的解析の結果をもとにデータ特性に応じた応用解析が自動的に実行される。

seq2pipe はオープンソース（MIT ライセンス）として公開されており、
\texttt{https://github.com/Rhizobium-gits/seq2pipe} からアクセスできる。

% -------------------------------------------------------
% 参考文献
% -------------------------------------------------------
\begin{thebibliography}{9}

\bibitem{qiime2}
  Bolyen, E., et al. (2019).
  \textit{Reproducible, interactive, scalable and extensible microbiome data science using QIIME 2}.
  Nature Biotechnology, 37, 852--857.

\bibitem{brown2020gpt3}
  Brown, T. B., et al. (2020).
  \textit{Language Models are Few-Shot Learners}.
  Advances in Neural Information Processing Systems, 33, 1877--1901.

\bibitem{yao2023react}
  Yao, S., et al. (2023).
  \textit{ReAct: Synergizing Reasoning and Acting in Language Models}.
  International Conference on Learning Representations (ICLR 2023).

\bibitem{ollama}
  Ollama (2023).
  \textit{Ollama: Get up and running with large language models locally}.
  \url{https://ollama.com/}

\bibitem{silva}
  Quast, C., et al. (2013).
  \textit{The SILVA ribosomal RNA gene database project: improved data processing and web-based tools}.
  Nucleic Acids Research, 41(D1), D590--D596.

\bibitem{dada2}
  Callahan, B. J., et al. (2016).
  \textit{DADA2: High-resolution sample inference from Illumina amplicon data}.
  Nature Methods, 13(7), 581--583.

\end{thebibliography}

\end{document}
